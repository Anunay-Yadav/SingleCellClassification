{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"610f28b5"},"source":["\n","# Rank ordered logFC*expression on Pancreas training Dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5103,"status":"ok","timestamp":1681840824613,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"VgH7DSyxtDIj"},"outputs":[],"source":["!pip install scanpy -q"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8394,"status":"ok","timestamp":1681840833004,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"ffa6ec78"},"outputs":[],"source":["import numpy as np\n","import pandas as  pd\n","import scanpy as sc\n","from sklearn.linear_model import LinearRegression\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26243,"status":"ok","timestamp":1681840859243,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"sXrtQ2Ygs51r","outputId":"59aaf1c2-c336-473c-e751-952d5e3e89f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7bbaf233-9a21-4d57-805a-85a4ddb43d6a"},"source":["# TRAINING DATA"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"110216a7"},"source":["## Read the Training data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2838,"status":"ok","timestamp":1681840862078,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"274b69eb","outputId":"848e46af-3087-4d52-93b9-cf22de210aea"},"outputs":[{"data":{"text/plain":["AnnData object with n_obs × n_vars = 8569 × 20125\n","    obs: 'celltype'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["## Read train data\n","# adata_train = sc.read('/content/gdrive/MyDrive/Shared resources/Bh.h5ad')\n","adata_train = sc.read('/content/gdrive/MyDrive/Shared resources/Baron_pancreatic_islet.h5ad')\n","adata_train"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"377248d6-f144-4212-a8fc-6a6365703cb9"},"source":["## Preprocess the train data"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5770,"status":"ok","timestamp":1681840867844,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"6735e088-4a53-4a2f-b966-ee799acab666","outputId":"8a3c7430-3a3e-45b2-e97c-b3758d7b5f27"},"outputs":[{"data":{"text/plain":["(8569, 16359)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["adata_train.obs_names_make_unique()\n","sc.pp.filter_cells(adata_train, min_genes=200)\n","sc.pp.filter_genes(adata_train, min_cells=3)\n","sc.pp.normalize_total(adata_train, target_sum=1e4)\n","sc.pp.log1p(adata_train)\n","#sc.pp.highly_variable_genes(adata_train, n_top_genes = 1000)\n","adata_train.raw = adata_train\n","#adata_train = adata_train[:, adata_train.var.highly_variable]\n","sc.pp.scale(adata_train, max_value=10)\n","adata_train.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2823c6a3-e0b9-4c69-a478-bb65271df36c"},"source":["# Return logFC*expression train matrix\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1681840867845,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"tMznT0Fbt4qA"},"outputs":[],"source":["def rank_mult_logFC_expr_train(adata_train, groupby_col, top_de_genes = 50):\n","  \"\"\"\n","  This function find the top n upregulated and downregulated genes and returns the ranked logFC*expression matrix\n","  - We can do this step before or after dropout induction\n","  - We will select both upregulated and downregulated genes\n","  INPUT:\n","      data: anndata containing cell-gene expression matrix\n","      groupby_col: key of the observations grouping\n","      top_de_genes: number of top upregulated and downregulated de genes\n","\n","  OUTPUT:\n","      adata: transformed anndata with rank ordered logFC*expression matrix\n","      adata.obs: transformed observations grouping\n","  \"\"\"\n","  sc.tl.rank_genes_groups(adata_train, groupby = groupby_col, method='wilcoxon', use_raw = True)\n","  result = adata_train.uns['rank_genes_groups']\n","  groups = result['names'].dtype.names\n","  # Matrix sorted by logfoldchange\n","  detrain_dict = {}\n","  for group in groups:\n","      gene_rank_df = sc.get.rank_genes_groups_df(adata_train, group=group, pval_cutoff=0.05)\n","      print(\"Number of DE genes in {} = {}\".format(group,len(gene_rank_df)))\n","      gene_rank_df.sort_values(by=['logfoldchanges'], inplace=True, ascending=False)\n","      if len(gene_rank_df) < 50:\n","          lfc_genes_df = gene_rank_df\n","      if len(gene_rank_df) >= 50:\n","          upregulated_genes = gene_rank_df.head(50)\n","          dnregulated_genes = gene_rank_df.tail(50)\n","          lfc_genes_df = pd.concat([upregulated_genes, dnregulated_genes], axis=0)\n","      detrain_dict[group] = dict(zip(lfc_genes_df['names'], lfc_genes_df['logfoldchanges']))\n","\n","  # Take all the DE genes to create subset of genes in the main matrix \n","  tot_gene_list = list(set([key for subdict in detrain_dict.values() for key in subdict.keys()]))\n","  print(\"Number of unique DE genes across all groups = {}\".format(len(tot_gene_list)))\n","  \n","  # select only the subset of columns in the obs dataframe\n","  adata_sub = adata_train[:,tot_gene_list]\n","\n","  # For each of the groups multiply the DE genes with the logFC with the expression\n","  sub_list = []\n","  for group in groups:\n","      gdata = adata_sub[adata_sub.obs[groupby_col] == group, :].to_df()\n","      for gene, factor in detrain_dict[group].items():\n","          gdata[gene] = gdata[gene]* abs(factor)\n","      gdata = gdata.assign(celltype=group)\n","      sub_list.append(gdata)\n","\n","  del adata_sub, detrain_dict\n","\n","  transformed_count  = pd.concat(sub_list, axis=0)\n","  transformed_group = transformed_count[[groupby_col]]\n","  # rank the values in each row\n","  df_ranked = transformed_count.drop(groupby_col, axis=1).rank(axis=1, method='min', ascending=False).astype(int)\n","\n","  # create anndata for ranked tranformed matrix\n","  adata = sc.AnnData(df_ranked)\n","  adata.obs[groupby_col] = transformed_group\n","  \n","  del transformed_count, df_ranked\n","  return adata"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23750,"status":"ok","timestamp":1681840891590,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"bd3SduE62gV_","outputId":"ce6ea33a-1c9b-4b11-bc27-9a832661e2ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of DE genes in acinar = 4897\n","Number of DE genes in activated_stellate = 3370\n","Number of DE genes in alpha = 4381\n","Number of DE genes in beta = 5051\n","Number of DE genes in delta = 2135\n","Number of DE genes in ductal = 5021\n","Number of DE genes in endothelial = 2561\n","Number of DE genes in epsilon = 34\n","Number of DE genes in gamma = 1118\n","Number of DE genes in macrophage = 1100\n","Number of DE genes in mast = 350\n","Number of DE genes in quiescent_stellate = 1635\n","Number of DE genes in schwann = 59\n","Number of DE genes in t_cell = 3\n","Number of unique DE genes across all groups = 983\n"]}],"source":["transform_adata_train = rank_mult_logFC_expr_train(adata_train, \"celltype\", 50)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1681840891591,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"mLN672OFCz8Z","outputId":"77a8ebe5-722b-4508-85e2-708bacf9c721"},"outputs":[{"data":{"text/plain":["AnnData object with n_obs × n_vars = 8569 × 983\n","    obs: 'celltype'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["transform_adata_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1681805237879,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"mAwQZ-RdKmXe","outputId":"3da79fb4-640f-4a0c-92be-8b7cc2d9f52a"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-eb6924b1-a2e3-4518-ba76-14112b1aeda9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>index</th>\n","      <th>LSAMP</th>\n","      <th>PCSK1</th>\n","      <th>ESAM</th>\n","      <th>KIAA0319</th>\n","      <th>RAMP2</th>\n","      <th>CAPG</th>\n","      <th>SLC45A3</th>\n","      <th>PPY2P</th>\n","      <th>REST</th>\n","      <th>S100A13</th>\n","      <th>...</th>\n","      <th>CD4</th>\n","      <th>MECOM</th>\n","      <th>ERBB3</th>\n","      <th>CALCB</th>\n","      <th>HSD17B2</th>\n","      <th>NEFM</th>\n","      <th>DUSP26</th>\n","      <th>CD300LB</th>\n","      <th>EPS8L3</th>\n","      <th>HSD11B1</th>\n","    </tr>\n","    <tr>\n","      <th>index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>human1_lib1.final_cell_0001</th>\n","      <td>750</td>\n","      <td>876</td>\n","      <td>544</td>\n","      <td>976</td>\n","      <td>595</td>\n","      <td>58</td>\n","      <td>642</td>\n","      <td>295</td>\n","      <td>641</td>\n","      <td>105</td>\n","      <td>...</td>\n","      <td>365</td>\n","      <td>494</td>\n","      <td>71</td>\n","      <td>410</td>\n","      <td>447</td>\n","      <td>652</td>\n","      <td>946</td>\n","      <td>181</td>\n","      <td>279</td>\n","      <td>348</td>\n","    </tr>\n","    <tr>\n","      <th>human1_lib1.final_cell_0002</th>\n","      <td>772</td>\n","      <td>883</td>\n","      <td>578</td>\n","      <td>976</td>\n","      <td>628</td>\n","      <td>730</td>\n","      <td>668</td>\n","      <td>329</td>\n","      <td>667</td>\n","      <td>71</td>\n","      <td>...</td>\n","      <td>397</td>\n","      <td>528</td>\n","      <td>718</td>\n","      <td>441</td>\n","      <td>479</td>\n","      <td>677</td>\n","      <td>946</td>\n","      <td>211</td>\n","      <td>312</td>\n","      <td>380</td>\n","    </tr>\n","    <tr>\n","      <th>human1_lib1.final_cell_0003</th>\n","      <td>708</td>\n","      <td>852</td>\n","      <td>486</td>\n","      <td>976</td>\n","      <td>540</td>\n","      <td>54</td>\n","      <td>585</td>\n","      <td>243</td>\n","      <td>584</td>\n","      <td>773</td>\n","      <td>...</td>\n","      <td>311</td>\n","      <td>439</td>\n","      <td>644</td>\n","      <td>355</td>\n","      <td>392</td>\n","      <td>595</td>\n","      <td>946</td>\n","      <td>127</td>\n","      <td>228</td>\n","      <td>294</td>\n","    </tr>\n","    <tr>\n","      <th>human1_lib1.final_cell_0004</th>\n","      <td>746</td>\n","      <td>859</td>\n","      <td>546</td>\n","      <td>976</td>\n","      <td>598</td>\n","      <td>700</td>\n","      <td>644</td>\n","      <td>301</td>\n","      <td>643</td>\n","      <td>800</td>\n","      <td>...</td>\n","      <td>369</td>\n","      <td>498</td>\n","      <td>688</td>\n","      <td>413</td>\n","      <td>451</td>\n","      <td>651</td>\n","      <td>946</td>\n","      <td>189</td>\n","      <td>286</td>\n","      <td>352</td>\n","    </tr>\n","    <tr>\n","      <th>human1_lib1.final_cell_0005</th>\n","      <td>732</td>\n","      <td>862</td>\n","      <td>526</td>\n","      <td>976</td>\n","      <td>578</td>\n","      <td>81</td>\n","      <td>621</td>\n","      <td>277</td>\n","      <td>52</td>\n","      <td>65</td>\n","      <td>...</td>\n","      <td>345</td>\n","      <td>476</td>\n","      <td>74</td>\n","      <td>390</td>\n","      <td>428</td>\n","      <td>632</td>\n","      <td>946</td>\n","      <td>163</td>\n","      <td>262</td>\n","      <td>328</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>human2_lib2.final_cell_0582</th>\n","      <td>702</td>\n","      <td>885</td>\n","      <td>426</td>\n","      <td>575</td>\n","      <td>491</td>\n","      <td>20</td>\n","      <td>554</td>\n","      <td>178</td>\n","      <td>553</td>\n","      <td>788</td>\n","      <td>...</td>\n","      <td>247</td>\n","      <td>375</td>\n","      <td>624</td>\n","      <td>290</td>\n","      <td>327</td>\n","      <td>567</td>\n","      <td>856</td>\n","      <td>65</td>\n","      <td>162</td>\n","      <td>229</td>\n","    </tr>\n","    <tr>\n","      <th>human2_lib2.final_cell_0590</th>\n","      <td>697</td>\n","      <td>881</td>\n","      <td>418</td>\n","      <td>568</td>\n","      <td>482</td>\n","      <td>17</td>\n","      <td>547</td>\n","      <td>172</td>\n","      <td>546</td>\n","      <td>784</td>\n","      <td>...</td>\n","      <td>242</td>\n","      <td>368</td>\n","      <td>617</td>\n","      <td>284</td>\n","      <td>319</td>\n","      <td>560</td>\n","      <td>854</td>\n","      <td>62</td>\n","      <td>157</td>\n","      <td>224</td>\n","    </tr>\n","    <tr>\n","      <th>human3_lib3.final_cell_0866</th>\n","      <td>694</td>\n","      <td>875</td>\n","      <td>419</td>\n","      <td>567</td>\n","      <td>483</td>\n","      <td>15</td>\n","      <td>546</td>\n","      <td>174</td>\n","      <td>545</td>\n","      <td>780</td>\n","      <td>...</td>\n","      <td>241</td>\n","      <td>370</td>\n","      <td>616</td>\n","      <td>284</td>\n","      <td>321</td>\n","      <td>559</td>\n","      <td>847</td>\n","      <td>62</td>\n","      <td>158</td>\n","      <td>223</td>\n","    </tr>\n","    <tr>\n","      <th>human3_lib3.final_cell_0896</th>\n","      <td>698</td>\n","      <td>879</td>\n","      <td>424</td>\n","      <td>570</td>\n","      <td>487</td>\n","      <td>639</td>\n","      <td>549</td>\n","      <td>174</td>\n","      <td>548</td>\n","      <td>785</td>\n","      <td>...</td>\n","      <td>243</td>\n","      <td>375</td>\n","      <td>619</td>\n","      <td>289</td>\n","      <td>325</td>\n","      <td>562</td>\n","      <td>849</td>\n","      <td>64</td>\n","      <td>158</td>\n","      <td>225</td>\n","    </tr>\n","    <tr>\n","      <th>human4_lib1.final_cell_0568</th>\n","      <td>708</td>\n","      <td>891</td>\n","      <td>431</td>\n","      <td>581</td>\n","      <td>497</td>\n","      <td>19</td>\n","      <td>21</td>\n","      <td>183</td>\n","      <td>560</td>\n","      <td>794</td>\n","      <td>...</td>\n","      <td>254</td>\n","      <td>383</td>\n","      <td>632</td>\n","      <td>298</td>\n","      <td>333</td>\n","      <td>573</td>\n","      <td>863</td>\n","      <td>72</td>\n","      <td>168</td>\n","      <td>236</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8569 rows × 983 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb6924b1-a2e3-4518-ba76-14112b1aeda9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-eb6924b1-a2e3-4518-ba76-14112b1aeda9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-eb6924b1-a2e3-4518-ba76-14112b1aeda9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["index                        LSAMP  PCSK1  ESAM  KIAA0319  RAMP2  CAPG  \\\n","index                                                                    \n","human1_lib1.final_cell_0001    750    876   544       976    595    58   \n","human1_lib1.final_cell_0002    772    883   578       976    628   730   \n","human1_lib1.final_cell_0003    708    852   486       976    540    54   \n","human1_lib1.final_cell_0004    746    859   546       976    598   700   \n","human1_lib1.final_cell_0005    732    862   526       976    578    81   \n","...                            ...    ...   ...       ...    ...   ...   \n","human2_lib2.final_cell_0582    702    885   426       575    491    20   \n","human2_lib2.final_cell_0590    697    881   418       568    482    17   \n","human3_lib3.final_cell_0866    694    875   419       567    483    15   \n","human3_lib3.final_cell_0896    698    879   424       570    487   639   \n","human4_lib1.final_cell_0568    708    891   431       581    497    19   \n","\n","index                        SLC45A3  PPY2P  REST  S100A13  ...  CD4  MECOM  \\\n","index                                                       ...               \n","human1_lib1.final_cell_0001      642    295   641      105  ...  365    494   \n","human1_lib1.final_cell_0002      668    329   667       71  ...  397    528   \n","human1_lib1.final_cell_0003      585    243   584      773  ...  311    439   \n","human1_lib1.final_cell_0004      644    301   643      800  ...  369    498   \n","human1_lib1.final_cell_0005      621    277    52       65  ...  345    476   \n","...                              ...    ...   ...      ...  ...  ...    ...   \n","human2_lib2.final_cell_0582      554    178   553      788  ...  247    375   \n","human2_lib2.final_cell_0590      547    172   546      784  ...  242    368   \n","human3_lib3.final_cell_0866      546    174   545      780  ...  241    370   \n","human3_lib3.final_cell_0896      549    174   548      785  ...  243    375   \n","human4_lib1.final_cell_0568       21    183   560      794  ...  254    383   \n","\n","index                        ERBB3  CALCB  HSD17B2  NEFM  DUSP26  CD300LB  \\\n","index                                                                       \n","human1_lib1.final_cell_0001     71    410      447   652     946      181   \n","human1_lib1.final_cell_0002    718    441      479   677     946      211   \n","human1_lib1.final_cell_0003    644    355      392   595     946      127   \n","human1_lib1.final_cell_0004    688    413      451   651     946      189   \n","human1_lib1.final_cell_0005     74    390      428   632     946      163   \n","...                            ...    ...      ...   ...     ...      ...   \n","human2_lib2.final_cell_0582    624    290      327   567     856       65   \n","human2_lib2.final_cell_0590    617    284      319   560     854       62   \n","human3_lib3.final_cell_0866    616    284      321   559     847       62   \n","human3_lib3.final_cell_0896    619    289      325   562     849       64   \n","human4_lib1.final_cell_0568    632    298      333   573     863       72   \n","\n","index                        EPS8L3  HSD11B1  \n","index                                         \n","human1_lib1.final_cell_0001     279      348  \n","human1_lib1.final_cell_0002     312      380  \n","human1_lib1.final_cell_0003     228      294  \n","human1_lib1.final_cell_0004     286      352  \n","human1_lib1.final_cell_0005     262      328  \n","...                             ...      ...  \n","human2_lib2.final_cell_0582     162      229  \n","human2_lib2.final_cell_0590     157      224  \n","human3_lib3.final_cell_0866     158      223  \n","human3_lib3.final_cell_0896     158      225  \n","human4_lib1.final_cell_0568     168      236  \n","\n","[8569 rows x 983 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["transform_adata_train.to_df()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vj3JlPuUFcXc"},"source":["# Read Test data"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3125,"status":"ok","timestamp":1681840896577,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"eWf8jByGE-HD","outputId":"5445575e-2a80-49bc-a844-fcd587e869e7"},"outputs":[{"data":{"text/plain":["AnnData object with n_obs × n_vars = 2394 × 34363\n","    obs: 'celltype', 'tech'\n","    var: 'genename'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["## Read test data\n","# adata_test = sc.read('/content/gdrive/MyDrive/Shared resources/smartseq2.h5ad')\n","adata_test = sc.read('/content/gdrive/MyDrive/Shared resources/Segerstolpe_pancreatic_islet.h5ad')\n","adata_test"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2362,"status":"ok","timestamp":1681840898934,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"e3C_eI-sFmUg","outputId":"0c33ba10-5f47-4f1c-d39a-abe4f4431e51"},"outputs":[{"data":{"text/plain":["(2394, 21117)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["adata_test.obs_names_make_unique()\n","sc.pp.filter_cells(adata_test, min_genes=200)\n","sc.pp.filter_genes(adata_test, min_cells=3)\n","sc.pp.normalize_total(adata_test, target_sum=1e4)\n","sc.pp.log1p(adata_test)\n","#sc.pp.highly_variable_genes(adata_train, n_top_genes = 1000)\n","adata_test.raw = adata_test\n","#adata_train = adata_train[:, adata_train.var.highly_variable]\n","sc.pp.scale(adata_test, max_value=10)\n","adata_test.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"pFs2l8ixOdVm"},"source":["# Return rank ordered test matrix"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1681840898936,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"jdb1OUm0KwrD"},"outputs":[],"source":["def rank_expr_test(adata_test, gene_list):\n","  \"\"\"\n","  This function find the common genes between train and test dataset. The output will be a rank ordered matrix.\n","  INPUT:\n","      data: anndata containing cell-gene expression matrix\n","      gene_list: gene sets from train data, adata_train.var_names\n","\n","  OUTPUT:\n","      adata: transformed anndata with rank ordered  matrix\n","      adata.obs: transformed observations from original test anndata\n","  \"\"\"\n","  # find the common genes between train and test dataset\n","  common_genes = gene_list.intersection(adata_test.var_names)\n","  print(\"Number of common genes of the reference and query sets = {}\".format(len(common_genes)))\n","  \n","  # slice the test data based on common genes\n","  adata_test_aligned = adata_test[:, common_genes].copy()\n","\n","  # rank order the test data\n","  df_ranked = adata_test_aligned.to_df().rank(axis=1, method='min', ascending=False).astype(int)\n","\n","  # create anndata for ranked tranformed matrix\n","  adata = sc.AnnData(df_ranked)\n","  adata.obs = adata_test_aligned.obs\n","\n","  del adata_test_aligned, df_ranked\n","  return adata\n","  \n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1681840898937,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"6hhZgN68NpGV","outputId":"68dcc48d-ef21-484b-ef97-44bd00f81b0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of common genes of the reference and query sets = 963\n"]}],"source":["transform_adata_test = rank_expr_test(adata_test, transform_adata_train.var_names)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1681840898938,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"ZFrnwrEFEMKZ","outputId":"bc703136-b99f-40b1-e514-440ff67d842d"},"outputs":[{"data":{"text/plain":["AnnData object with n_obs × n_vars = 2394 × 963\n","    obs: 'celltype', 'tech', 'n_genes'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["transform_adata_test"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1681840898938,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"mUJf85SbO1mZ","outputId":"df0e9a41-6f88-4436-c019-48867619257c"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-43e347bf-f717-4d08-9e24-dfe79e943c2a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>index</th>\n","      <th>SLC34A2</th>\n","      <th>C1orf106</th>\n","      <th>CLDN3</th>\n","      <th>RNF128</th>\n","      <th>CHRM3</th>\n","      <th>SMIM5</th>\n","      <th>DPP6</th>\n","      <th>MRC2</th>\n","      <th>ID1</th>\n","      <th>SYNDIG1</th>\n","      <th>...</th>\n","      <th>PODXL</th>\n","      <th>TMC6</th>\n","      <th>B3GNT8</th>\n","      <th>ITGB6</th>\n","      <th>BEX1</th>\n","      <th>RCAN1</th>\n","      <th>SPINK2</th>\n","      <th>SDC4</th>\n","      <th>TSLP</th>\n","      <th>LAD1</th>\n","    </tr>\n","    <tr>\n","      <th>index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>AZ_A2</th>\n","      <td>582</td>\n","      <td>636</td>\n","      <td>939</td>\n","      <td>46</td>\n","      <td>123</td>\n","      <td>2</td>\n","      <td>920</td>\n","      <td>383</td>\n","      <td>812</td>\n","      <td>706</td>\n","      <td>...</td>\n","      <td>495</td>\n","      <td>674</td>\n","      <td>751</td>\n","      <td>671</td>\n","      <td>102</td>\n","      <td>739</td>\n","      <td>384</td>\n","      <td>841</td>\n","      <td>202</td>\n","      <td>794</td>\n","    </tr>\n","    <tr>\n","      <th>AZ_H5</th>\n","      <td>564</td>\n","      <td>621</td>\n","      <td>931</td>\n","      <td>915</td>\n","      <td>560</td>\n","      <td>646</td>\n","      <td>40</td>\n","      <td>365</td>\n","      <td>790</td>\n","      <td>689</td>\n","      <td>...</td>\n","      <td>127</td>\n","      <td>658</td>\n","      <td>735</td>\n","      <td>656</td>\n","      <td>59</td>\n","      <td>721</td>\n","      <td>366</td>\n","      <td>823</td>\n","      <td>182</td>\n","      <td>770</td>\n","    </tr>\n","    <tr>\n","      <th>AZ_G5</th>\n","      <td>598</td>\n","      <td>647</td>\n","      <td>940</td>\n","      <td>137</td>\n","      <td>595</td>\n","      <td>6</td>\n","      <td>35</td>\n","      <td>399</td>\n","      <td>819</td>\n","      <td>717</td>\n","      <td>...</td>\n","      <td>221</td>\n","      <td>685</td>\n","      <td>764</td>\n","      <td>683</td>\n","      <td>91</td>\n","      <td>749</td>\n","      <td>400</td>\n","      <td>850</td>\n","      <td>215</td>\n","      <td>800</td>\n","    </tr>\n","    <tr>\n","      <th>AZ_D8</th>\n","      <td>631</td>\n","      <td>686</td>\n","      <td>611</td>\n","      <td>940</td>\n","      <td>78</td>\n","      <td>709</td>\n","      <td>118</td>\n","      <td>444</td>\n","      <td>845</td>\n","      <td>753</td>\n","      <td>...</td>\n","      <td>124</td>\n","      <td>722</td>\n","      <td>262</td>\n","      <td>720</td>\n","      <td>161</td>\n","      <td>784</td>\n","      <td>445</td>\n","      <td>876</td>\n","      <td>260</td>\n","      <td>827</td>\n","    </tr>\n","    <tr>\n","      <th>AZ_D12</th>\n","      <td>585</td>\n","      <td>642</td>\n","      <td>104</td>\n","      <td>933</td>\n","      <td>581</td>\n","      <td>669</td>\n","      <td>926</td>\n","      <td>387</td>\n","      <td>491</td>\n","      <td>711</td>\n","      <td>...</td>\n","      <td>499</td>\n","      <td>682</td>\n","      <td>42</td>\n","      <td>679</td>\n","      <td>115</td>\n","      <td>741</td>\n","      <td>388</td>\n","      <td>842</td>\n","      <td>200</td>\n","      <td>794</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>HP1504901_A22</th>\n","      <td>513</td>\n","      <td>567</td>\n","      <td>896</td>\n","      <td>878</td>\n","      <td>509</td>\n","      <td>595</td>\n","      <td>874</td>\n","      <td>345</td>\n","      <td>737</td>\n","      <td>636</td>\n","      <td>...</td>\n","      <td>435</td>\n","      <td>606</td>\n","      <td>678</td>\n","      <td>604</td>\n","      <td>943</td>\n","      <td>48</td>\n","      <td>346</td>\n","      <td>770</td>\n","      <td>174</td>\n","      <td>717</td>\n","    </tr>\n","    <tr>\n","      <th>HP1504901_M11</th>\n","      <td>501</td>\n","      <td>557</td>\n","      <td>890</td>\n","      <td>873</td>\n","      <td>497</td>\n","      <td>585</td>\n","      <td>870</td>\n","      <td>326</td>\n","      <td>728</td>\n","      <td>626</td>\n","      <td>...</td>\n","      <td>419</td>\n","      <td>596</td>\n","      <td>669</td>\n","      <td>594</td>\n","      <td>946</td>\n","      <td>656</td>\n","      <td>327</td>\n","      <td>762</td>\n","      <td>159</td>\n","      <td>707</td>\n","    </tr>\n","    <tr>\n","      <th>HP1504901_N21</th>\n","      <td>517</td>\n","      <td>572</td>\n","      <td>895</td>\n","      <td>877</td>\n","      <td>513</td>\n","      <td>598</td>\n","      <td>871</td>\n","      <td>355</td>\n","      <td>96</td>\n","      <td>641</td>\n","      <td>...</td>\n","      <td>443</td>\n","      <td>610</td>\n","      <td>688</td>\n","      <td>608</td>\n","      <td>948</td>\n","      <td>49</td>\n","      <td>356</td>\n","      <td>129</td>\n","      <td>202</td>\n","      <td>723</td>\n","    </tr>\n","    <tr>\n","      <th>HP1507101_P15</th>\n","      <td>555</td>\n","      <td>607</td>\n","      <td>908</td>\n","      <td>897</td>\n","      <td>552</td>\n","      <td>632</td>\n","      <td>891</td>\n","      <td>54</td>\n","      <td>198</td>\n","      <td>667</td>\n","      <td>...</td>\n","      <td>487</td>\n","      <td>642</td>\n","      <td>710</td>\n","      <td>639</td>\n","      <td>951</td>\n","      <td>696</td>\n","      <td>408</td>\n","      <td>799</td>\n","      <td>260</td>\n","      <td>746</td>\n","    </tr>\n","    <tr>\n","      <th>HP1508501T2D_M16</th>\n","      <td>554</td>\n","      <td>605</td>\n","      <td>852</td>\n","      <td>897</td>\n","      <td>550</td>\n","      <td>629</td>\n","      <td>891</td>\n","      <td>56</td>\n","      <td>760</td>\n","      <td>665</td>\n","      <td>...</td>\n","      <td>484</td>\n","      <td>639</td>\n","      <td>708</td>\n","      <td>637</td>\n","      <td>950</td>\n","      <td>48</td>\n","      <td>401</td>\n","      <td>793</td>\n","      <td>1</td>\n","      <td>743</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2394 rows × 963 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43e347bf-f717-4d08-9e24-dfe79e943c2a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-43e347bf-f717-4d08-9e24-dfe79e943c2a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-43e347bf-f717-4d08-9e24-dfe79e943c2a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["index             SLC34A2  C1orf106  CLDN3  RNF128  CHRM3  SMIM5  DPP6  MRC2  \\\n","index                                                                          \n","AZ_A2                 582       636    939      46    123      2   920   383   \n","AZ_H5                 564       621    931     915    560    646    40   365   \n","AZ_G5                 598       647    940     137    595      6    35   399   \n","AZ_D8                 631       686    611     940     78    709   118   444   \n","AZ_D12                585       642    104     933    581    669   926   387   \n","...                   ...       ...    ...     ...    ...    ...   ...   ...   \n","HP1504901_A22         513       567    896     878    509    595   874   345   \n","HP1504901_M11         501       557    890     873    497    585   870   326   \n","HP1504901_N21         517       572    895     877    513    598   871   355   \n","HP1507101_P15         555       607    908     897    552    632   891    54   \n","HP1508501T2D_M16      554       605    852     897    550    629   891    56   \n","\n","index             ID1  SYNDIG1  ...  PODXL  TMC6  B3GNT8  ITGB6  BEX1  RCAN1  \\\n","index                           ...                                            \n","AZ_A2             812      706  ...    495   674     751    671   102    739   \n","AZ_H5             790      689  ...    127   658     735    656    59    721   \n","AZ_G5             819      717  ...    221   685     764    683    91    749   \n","AZ_D8             845      753  ...    124   722     262    720   161    784   \n","AZ_D12            491      711  ...    499   682      42    679   115    741   \n","...               ...      ...  ...    ...   ...     ...    ...   ...    ...   \n","HP1504901_A22     737      636  ...    435   606     678    604   943     48   \n","HP1504901_M11     728      626  ...    419   596     669    594   946    656   \n","HP1504901_N21      96      641  ...    443   610     688    608   948     49   \n","HP1507101_P15     198      667  ...    487   642     710    639   951    696   \n","HP1508501T2D_M16  760      665  ...    484   639     708    637   950     48   \n","\n","index             SPINK2  SDC4  TSLP  LAD1  \n","index                                       \n","AZ_A2                384   841   202   794  \n","AZ_H5                366   823   182   770  \n","AZ_G5                400   850   215   800  \n","AZ_D8                445   876   260   827  \n","AZ_D12               388   842   200   794  \n","...                  ...   ...   ...   ...  \n","HP1504901_A22        346   770   174   717  \n","HP1504901_M11        327   762   159   707  \n","HP1504901_N21        356   129   202   723  \n","HP1507101_P15        408   799   260   746  \n","HP1508501T2D_M16     401   793     1   743  \n","\n","[2394 rows x 963 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["transform_adata_test.to_df()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"hJtahBADO5IV"},"source":["---\n","# **Implementation of DL classifier**\n","\n","---\n","\n","\n","**@anunay you may continue from here**\n","\n","train anndata = transform_adata_train\n","\n","test anndata = transform_adata_test"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1681840898939,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"wb7TywdLoqaG"},"outputs":[],"source":["train_df = transform_adata_train.to_df()\n","test_df = transform_adata_test.to_df()"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1681840898940,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"j4MhozdSozJM"},"outputs":[],"source":["y_train = transform_adata_train.obs.celltype.to_list()\n","y_test = transform_adata_test.obs.celltype.to_list()"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1681840898941,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"jnU-ued7pCR8"},"outputs":[],"source":["labels = set(y_train)\n","mapping = {}\n","cnt = 0\n","for lab in set(y_train):\n","  if lab in mapping:\n","    continue\n","  mapping[lab] = cnt\n","  cnt += 1\n"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1681840898941,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"6K_4slN7pIIz"},"outputs":[],"source":["y_test_lab = []\n","for i in y_test:\n","  if i in mapping:\n","    y_test_lab.append(mapping[i])\n","  else:\n","    y_test_lab.append(0)\n","y_test = np.array(y_test_lab)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":628,"status":"ok","timestamp":1681840899549,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"NBsq-HGopN97"},"outputs":[],"source":["y_train_lab = []\n","for i in y_train:\n","  if i in mapping:\n","    y_train_lab.append(mapping[i])\n","  else:\n","    y_train_lab.append(0)\n","y_train = np.array(y_train_lab)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1681840899550,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"3EktT0rNoRR4","outputId":"f98aed5c-c1a1-4ad5-ad85-730c990b76ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Taking common genes...\n","Common columns 963\n"]}],"source":["print(\"Taking common genes...\")\n","final_columns = list(set(train_df.columns).intersection(set(test_df.columns)))\n","print('Common columns', len(final_columns))\n","final_columns = [i for i in final_columns if i != 'celltype'] \n","train_df = train_df[final_columns]\n","test_df = test_df[final_columns]"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1681840899550,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"6Q9_90_DpiMl"},"outputs":[],"source":["X_train = train_df.to_numpy()\n","X_test = test_df.to_numpy()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"aqGoNUUq6hfI"},"source":["# Keras tuner"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4687,"status":"ok","timestamp":1681840904231,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"zWBjy-Ms7DUO","outputId":"d0796392-e501-470b-e16c-a9a78077dd1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras_tuner\n","  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (2.27.1)\n","Collecting kt-legacy\n","  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (23.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (3.4)\n","Installing collected packages: kt-legacy, keras_tuner\n","Successfully installed keras_tuner-1.3.5 kt-legacy-1.0.5\n"]}],"source":["!pip3 install keras_tuner"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1681840904232,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"2ckcRynf7OXE"},"outputs":[],"source":["y_test_cat = np.zeros((y_test.shape[0], 14))\n","y_train_cat = np.zeros((y_train.shape[0], 14))"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1681840904233,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"Vtpb3TiZ7QdF"},"outputs":[],"source":["def convert_to_cat(y_new, y):\n","  for i in range(y.shape[0]):\n","    y_new[i, y[i]] = 1\n","  return y_new\n","y_test_cat = convert_to_cat(y_test_cat, y_test)\n","y_train_cat = convert_to_cat(y_train_cat, y_train)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1681840904233,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"xh7EdPHY7SA0","outputId":"5ab1d8a5-4adb-4c4d-abc7-7d0825e2dece"},"outputs":[{"data":{"text/plain":["(8569, 963)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":805},"executionInfo":{"elapsed":381106,"status":"error","timestamp":1681841313803,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"rA0lz12d7F6f","outputId":"3a224ccd-8a4f-4246-a5e5-61d1111ddee5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Trial 64 Complete [00h 00m 05s]\n","val_loss: 2.627977132797241\n","\n","Best val_loss So Far: 2.6243536472320557\n","Total elapsed time: 00h 06m 21s\n","\n","Search: Running Trial #65\n","\n","Value             |Best Value So Far |Hyperparameter\n","4                 |4                 |layers\n","768               |768               |units_0\n","3e-05             |0.0001            |learning_rate\n","256               |768               |units_1\n","768               |768               |units_2\n","640               |384               |units_3\n","256               |640               |units_4\n","128               |None              |units_5\n","1                 |1                 |tuner/epochs\n","0                 |0                 |tuner/initial_epoch\n","4                 |4                 |tuner/bracket\n","0                 |0                 |tuner/round\n","\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-d272a2bedb46>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mstop_early\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstop_early\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mbest_hp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[1;32m    212\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         tuner_utils.validate_trial_results(\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_try_build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;31m# Stop if `build()` does not return a valid model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36m_build_hypermodel\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"tuner/trial_id\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mtrial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/trial_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_hypermodel\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmaybe_distribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_override_compile_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-28-d272a2bedb46>\u001b[0m in \u001b[0;36mmodel_builder\u001b[0;34m(hp)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     model.add(keras.layers.Dense(units=hp.Int('units_' + str(i),  \n\u001b[0m\u001b[1;32m     28\u001b[0m                                 \u001b[0mmin_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munits_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munits_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                 step=units_range[2]), activation='relu'))\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         ):\n\u001b[0;32m-> 1058\u001b[0;31m             return self._functional_construction_call(\n\u001b[0m\u001b[1;32m   1059\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   2587\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mask\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2588\u001b[0m             \u001b[0;31m# Node connectivity does not special-case the first argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2589\u001b[0;31m             outputs = self._set_connectivity_metadata(\n\u001b[0m\u001b[1;32m   2590\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2591\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_set_connectivity_metadata\u001b[0;34m(self, args, kwargs, outputs)\u001b[0m\n\u001b[1;32m   2943\u001b[0m         \u001b[0;31m# `_outbound_nodes` of the layers that produced the inputs to this layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2944\u001b[0m         \u001b[0;31m# call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2945\u001b[0;31m         node_module.Node(\n\u001b[0m\u001b[1;32m   2946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2947\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/node.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, call_args, call_kwargs, outputs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcall_args\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcall_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# These arguments are user-provided. Copy the structures here so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import pandas as pd\n","import keras_tuner as kt\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","tf.config.threading.set_inter_op_parallelism_threads(1)\n","tf.config.threading.set_intra_op_parallelism_threads(1)\n","np.random.seed(2)\n","\n","##loading 90% Training data\n","directory = '/content/gdrive/MyDrive/Shared resources/'\n","project_name = 'RO_dataset_hyperparameter_tuning'\n","\n","\n","##Definining hyper parameters \n","layers_range = (3, 6)\n","units_range = (128, 896, 128)\n","lr_values = [1e-4,3e-5,1e-5, 3e-6]\n","\n","##Define model\n","def model_builder(hp):\n","  model = keras.Sequential()\n","  model.add(keras.layers.Dense(units = 1024,input_dim = 963, activation = 'relu'))\n","\n","  for i in range(hp.Int('layers', layers_range[0], layers_range[1])):\n","    model.add(keras.layers.Dense(units=hp.Int('units_' + str(i),  \n","                                min_value=units_range[0], max_value=units_range[1], \n","                                step=units_range[2]), activation='relu'))\n","\n","    \n","    model.add(keras.layers.Dense(14, activation='softmax'))\n","    hp_learning_rate = hp.Choice('learning_rate', values=lr_values)\n","    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n","                loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()]) \n","  return model\n","\n","##Perform hyperparameter tuning\n","for i in range(5):\n","    offset = (X_train.shape[0]*9)//10\n","    tuner = kt.Hyperband(model_builder, # the hypermodel\n","                    objective='val_loss', # objective to optimize\n","                    max_epochs=256,\n","                    factor=4, \n","                    directory=directory, # directory to save logs \n","                    project_name=project_name+str(i+1))\n","    \n","    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","    tuner.search(X_train, y_train_cat, epochs=400, batch_size = 4096, validation_data = (X_test, y_test_cat), callbacks=[stop_early])\n","    best_hp=tuner.get_best_hyperparameters()[0]\n","    best_model = tuner.get_best_models()[0]\n","    \n","    # Build the model with the optimal hyperparameters\n","    h_model = tuner.hypermodel.build(best_hp)\n","    h_model.fit(X_train, y_train_cat, epochs=400, verbose = 1, batch_size = 4096, validation_data = (X_test, y_test_cat))\n","    h_model.save('precily_cv_'+str(i+1)+'.hdf5')\n","    h_model = None\n","    \n"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":568,"status":"ok","timestamp":1681842648604,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"xGT4LICdowUe"},"outputs":[],"source":["model = keras.Sequential()\n","model.add(keras.layers.Dense(units = 512,input_dim = 963, activation = 'relu'))\n","\n","# for i in range(4):\n","#   model.add(keras.layers.Dense(units=512, activation='relu'))\n","# model.add(keras.layers.Dense(units=512, activation='relu'))\n","model.add(keras.layers.Dense(units=256, activation='relu'))\n","model.add(keras.layers.Dense(units=128, activation='relu'))\n","model.add(keras.layers.Dense(14, activation='softmax'))\n","hp_learning_rate = 1e-5\n","\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n","            loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.AUC(), tf.keras.metrics.CategoricalAccuracy()]) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"YWjU2gP1oxyE"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n","3/3 [==============================] - 3s 557ms/step - loss: 920.1733 - auc_4: 0.4778 - categorical_accuracy: 0.0303 - val_loss: 736.7405 - val_auc_4: 0.5078 - val_categorical_accuracy: 0.0856\n","Epoch 2/1000\n","3/3 [==============================] - 1s 341ms/step - loss: 805.1699 - auc_4: 0.4782 - categorical_accuracy: 0.0315 - val_loss: 642.9548 - val_auc_4: 0.5038 - val_categorical_accuracy: 0.0789\n","Epoch 3/1000\n","3/3 [==============================] - 1s 321ms/step - loss: 695.7074 - auc_4: 0.4791 - categorical_accuracy: 0.0333 - val_loss: 557.7119 - val_auc_4: 0.5038 - val_categorical_accuracy: 0.0802\n","Epoch 4/1000\n","3/3 [==============================] - 1s 313ms/step - loss: 592.9579 - auc_4: 0.4810 - categorical_accuracy: 0.0368 - val_loss: 481.7903 - val_auc_4: 0.5049 - val_categorical_accuracy: 0.0806\n","Epoch 5/1000\n","3/3 [==============================] - 1s 297ms/step - loss: 497.6340 - auc_4: 0.4859 - categorical_accuracy: 0.0446 - val_loss: 415.2498 - val_auc_4: 0.5150 - val_categorical_accuracy: 0.0977\n","Epoch 6/1000\n","3/3 [==============================] - 1s 319ms/step - loss: 411.1317 - auc_4: 0.5054 - categorical_accuracy: 0.0802 - val_loss: 360.8484 - val_auc_4: 0.5337 - val_categorical_accuracy: 0.1337\n","Epoch 7/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 339.3492 - auc_4: 0.5422 - categorical_accuracy: 0.1445 - val_loss: 320.6940 - val_auc_4: 0.5582 - val_categorical_accuracy: 0.1759\n","Epoch 8/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 287.4803 - auc_4: 0.5787 - categorical_accuracy: 0.2143 - val_loss: 290.8854 - val_auc_4: 0.5742 - val_categorical_accuracy: 0.2093\n","Epoch 9/1000\n","3/3 [==============================] - 1s 198ms/step - loss: 251.7033 - auc_4: 0.6074 - categorical_accuracy: 0.2670 - val_loss: 264.3711 - val_auc_4: 0.5827 - val_categorical_accuracy: 0.2247\n","Epoch 10/1000\n","3/3 [==============================] - 1s 220ms/step - loss: 222.6956 - auc_4: 0.6256 - categorical_accuracy: 0.2993 - val_loss: 236.0968 - val_auc_4: 0.5865 - val_categorical_accuracy: 0.2302\n","Epoch 11/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 194.7245 - auc_4: 0.6360 - categorical_accuracy: 0.3193 - val_loss: 206.3661 - val_auc_4: 0.5877 - val_categorical_accuracy: 0.2327\n","Epoch 12/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 167.0363 - auc_4: 0.6487 - categorical_accuracy: 0.3406 - val_loss: 177.1851 - val_auc_4: 0.5944 - val_categorical_accuracy: 0.2427\n","Epoch 13/1000\n","3/3 [==============================] - 1s 220ms/step - loss: 141.1681 - auc_4: 0.6633 - categorical_accuracy: 0.3667 - val_loss: 150.7761 - val_auc_4: 0.6049 - val_categorical_accuracy: 0.2581\n","Epoch 14/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 118.4183 - auc_4: 0.6860 - categorical_accuracy: 0.4081 - val_loss: 129.6777 - val_auc_4: 0.6303 - val_categorical_accuracy: 0.3066\n","Epoch 15/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 100.4291 - auc_4: 0.7125 - categorical_accuracy: 0.4551 - val_loss: 115.4871 - val_auc_4: 0.6576 - val_categorical_accuracy: 0.3555\n","Epoch 16/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 87.8622 - auc_4: 0.7396 - categorical_accuracy: 0.5051 - val_loss: 107.7334 - val_auc_4: 0.6869 - val_categorical_accuracy: 0.4102\n","Epoch 17/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 80.1226 - auc_4: 0.7604 - categorical_accuracy: 0.5418 - val_loss: 104.1220 - val_auc_4: 0.7117 - val_categorical_accuracy: 0.4528\n","Epoch 18/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 75.2452 - auc_4: 0.7743 - categorical_accuracy: 0.5693 - val_loss: 102.2839 - val_auc_4: 0.7226 - val_categorical_accuracy: 0.4770\n","Epoch 19/1000\n","3/3 [==============================] - 1s 200ms/step - loss: 70.9537 - auc_4: 0.7850 - categorical_accuracy: 0.5903 - val_loss: 100.7241 - val_auc_4: 0.7232 - val_categorical_accuracy: 0.4766\n","Epoch 20/1000\n","3/3 [==============================] - 1s 189ms/step - loss: 66.1239 - auc_4: 0.7937 - categorical_accuracy: 0.6065 - val_loss: 99.2577 - val_auc_4: 0.7185 - val_categorical_accuracy: 0.4649\n","Epoch 21/1000\n","3/3 [==============================] - 1s 195ms/step - loss: 60.9878 - auc_4: 0.8046 - categorical_accuracy: 0.6285 - val_loss: 98.3274 - val_auc_4: 0.7113 - val_categorical_accuracy: 0.4557\n","Epoch 22/1000\n","3/3 [==============================] - 1s 310ms/step - loss: 56.0909 - auc_4: 0.8124 - categorical_accuracy: 0.6413 - val_loss: 98.3021 - val_auc_4: 0.7024 - val_categorical_accuracy: 0.4386\n","Epoch 23/1000\n","3/3 [==============================] - 1s 323ms/step - loss: 51.7752 - auc_4: 0.8171 - categorical_accuracy: 0.6510 - val_loss: 99.5146 - val_auc_4: 0.6913 - val_categorical_accuracy: 0.4156\n","Epoch 24/1000\n","3/3 [==============================] - 1s 307ms/step - loss: 48.2100 - auc_4: 0.8223 - categorical_accuracy: 0.6610 - val_loss: 101.5065 - val_auc_4: 0.6811 - val_categorical_accuracy: 0.3977\n","Epoch 25/1000\n","3/3 [==============================] - 1s 309ms/step - loss: 45.3915 - auc_4: 0.8253 - categorical_accuracy: 0.6644 - val_loss: 103.5778 - val_auc_4: 0.6728 - val_categorical_accuracy: 0.3860\n","Epoch 26/1000\n","3/3 [==============================] - 1s 337ms/step - loss: 43.1176 - auc_4: 0.8263 - categorical_accuracy: 0.6672 - val_loss: 105.1664 - val_auc_4: 0.6695 - val_categorical_accuracy: 0.3772\n","Epoch 27/1000\n","3/3 [==============================] - 1s 210ms/step - loss: 41.1400 - auc_4: 0.8296 - categorical_accuracy: 0.6704 - val_loss: 105.8238 - val_auc_4: 0.6668 - val_categorical_accuracy: 0.3718\n","Epoch 28/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 39.3350 - auc_4: 0.8336 - categorical_accuracy: 0.6797 - val_loss: 105.5122 - val_auc_4: 0.6673 - val_categorical_accuracy: 0.3722\n","Epoch 29/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 37.6008 - auc_4: 0.8379 - categorical_accuracy: 0.6884 - val_loss: 104.3963 - val_auc_4: 0.6693 - val_categorical_accuracy: 0.3751\n","Epoch 30/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 35.8970 - auc_4: 0.8426 - categorical_accuracy: 0.6975 - val_loss: 102.6998 - val_auc_4: 0.6716 - val_categorical_accuracy: 0.3822\n","Epoch 31/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 34.2507 - auc_4: 0.8474 - categorical_accuracy: 0.7074 - val_loss: 100.8562 - val_auc_4: 0.6760 - val_categorical_accuracy: 0.3881\n","Epoch 32/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 32.7504 - auc_4: 0.8529 - categorical_accuracy: 0.7176 - val_loss: 99.2681 - val_auc_4: 0.6800 - val_categorical_accuracy: 0.3952\n","Epoch 33/1000\n","3/3 [==============================] - 1s 195ms/step - loss: 31.3807 - auc_4: 0.8586 - categorical_accuracy: 0.7253 - val_loss: 97.8298 - val_auc_4: 0.6844 - val_categorical_accuracy: 0.4060\n","Epoch 34/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 30.1075 - auc_4: 0.8632 - categorical_accuracy: 0.7361 - val_loss: 96.4908 - val_auc_4: 0.6875 - val_categorical_accuracy: 0.4114\n","Epoch 35/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 28.9443 - auc_4: 0.8673 - categorical_accuracy: 0.7444 - val_loss: 95.2348 - val_auc_4: 0.6909 - val_categorical_accuracy: 0.4160\n","Epoch 36/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 27.8407 - auc_4: 0.8725 - categorical_accuracy: 0.7526 - val_loss: 94.1923 - val_auc_4: 0.6942 - val_categorical_accuracy: 0.4206\n","Epoch 37/1000\n","3/3 [==============================] - 1s 216ms/step - loss: 26.8218 - auc_4: 0.8767 - categorical_accuracy: 0.7599 - val_loss: 93.3221 - val_auc_4: 0.6957 - val_categorical_accuracy: 0.4244\n","Epoch 38/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 25.8490 - auc_4: 0.8803 - categorical_accuracy: 0.7673 - val_loss: 92.7528 - val_auc_4: 0.6955 - val_categorical_accuracy: 0.4256\n","Epoch 39/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 24.9354 - auc_4: 0.8836 - categorical_accuracy: 0.7747 - val_loss: 92.3827 - val_auc_4: 0.6966 - val_categorical_accuracy: 0.4236\n","Epoch 40/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 24.0794 - auc_4: 0.8867 - categorical_accuracy: 0.7803 - val_loss: 92.0340 - val_auc_4: 0.6972 - val_categorical_accuracy: 0.4236\n","Epoch 41/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 23.2753 - auc_4: 0.8896 - categorical_accuracy: 0.7857 - val_loss: 91.7764 - val_auc_4: 0.6976 - val_categorical_accuracy: 0.4261\n","Epoch 42/1000\n","3/3 [==============================] - 1s 315ms/step - loss: 22.5243 - auc_4: 0.8932 - categorical_accuracy: 0.7903 - val_loss: 91.4588 - val_auc_4: 0.6979 - val_categorical_accuracy: 0.4273\n","Epoch 43/1000\n","3/3 [==============================] - 1s 317ms/step - loss: 21.8123 - auc_4: 0.8956 - categorical_accuracy: 0.7971 - val_loss: 91.1570 - val_auc_4: 0.6981 - val_categorical_accuracy: 0.4269\n","Epoch 44/1000\n","3/3 [==============================] - 1s 330ms/step - loss: 21.1416 - auc_4: 0.8985 - categorical_accuracy: 0.8015 - val_loss: 90.7583 - val_auc_4: 0.6993 - val_categorical_accuracy: 0.4286\n","Epoch 45/1000\n","3/3 [==============================] - 1s 310ms/step - loss: 20.5137 - auc_4: 0.9010 - categorical_accuracy: 0.8077 - val_loss: 90.3596 - val_auc_4: 0.6991 - val_categorical_accuracy: 0.4302\n","Epoch 46/1000\n","3/3 [==============================] - 1s 333ms/step - loss: 19.9153 - auc_4: 0.9034 - categorical_accuracy: 0.8114 - val_loss: 89.8468 - val_auc_4: 0.7000 - val_categorical_accuracy: 0.4327\n","Epoch 47/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 19.3290 - auc_4: 0.9056 - categorical_accuracy: 0.8165 - val_loss: 89.2270 - val_auc_4: 0.7015 - val_categorical_accuracy: 0.4344\n","Epoch 48/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 18.7780 - auc_4: 0.9075 - categorical_accuracy: 0.8200 - val_loss: 88.7609 - val_auc_4: 0.7018 - val_categorical_accuracy: 0.4365\n","Epoch 49/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 18.2480 - auc_4: 0.9098 - categorical_accuracy: 0.8247 - val_loss: 88.3622 - val_auc_4: 0.7027 - val_categorical_accuracy: 0.4390\n","Epoch 50/1000\n","3/3 [==============================] - 1s 201ms/step - loss: 17.7448 - auc_4: 0.9121 - categorical_accuracy: 0.8285 - val_loss: 87.9215 - val_auc_4: 0.7036 - val_categorical_accuracy: 0.4411\n","Epoch 51/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 17.2660 - auc_4: 0.9143 - categorical_accuracy: 0.8328 - val_loss: 87.3134 - val_auc_4: 0.7053 - val_categorical_accuracy: 0.4424\n","Epoch 52/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 16.8100 - auc_4: 0.9164 - categorical_accuracy: 0.8363 - val_loss: 86.4936 - val_auc_4: 0.7078 - val_categorical_accuracy: 0.4457\n","Epoch 53/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 16.3684 - auc_4: 0.9180 - categorical_accuracy: 0.8402 - val_loss: 85.5322 - val_auc_4: 0.7099 - val_categorical_accuracy: 0.4503\n","Epoch 54/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 15.9350 - auc_4: 0.9201 - categorical_accuracy: 0.8435 - val_loss: 84.6781 - val_auc_4: 0.7122 - val_categorical_accuracy: 0.4553\n","Epoch 55/1000\n","3/3 [==============================] - 1s 245ms/step - loss: 15.5274 - auc_4: 0.9219 - categorical_accuracy: 0.8468 - val_loss: 83.9569 - val_auc_4: 0.7125 - val_categorical_accuracy: 0.4557\n","Epoch 56/1000\n","3/3 [==============================] - 1s 205ms/step - loss: 15.1329 - auc_4: 0.9238 - categorical_accuracy: 0.8492 - val_loss: 83.4111 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4553\n","Epoch 57/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 14.7500 - auc_4: 0.9259 - categorical_accuracy: 0.8526 - val_loss: 83.0408 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4561\n","Epoch 58/1000\n","3/3 [==============================] - 1s 241ms/step - loss: 14.3796 - auc_4: 0.9276 - categorical_accuracy: 0.8570 - val_loss: 82.8293 - val_auc_4: 0.7125 - val_categorical_accuracy: 0.4553\n","Epoch 59/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 14.0313 - auc_4: 0.9290 - categorical_accuracy: 0.8607 - val_loss: 82.6811 - val_auc_4: 0.7128 - val_categorical_accuracy: 0.4545\n","Epoch 60/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 13.6910 - auc_4: 0.9305 - categorical_accuracy: 0.8635 - val_loss: 82.3796 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4549\n","Epoch 61/1000\n","3/3 [==============================] - 1s 317ms/step - loss: 13.3693 - auc_4: 0.9323 - categorical_accuracy: 0.8659 - val_loss: 82.1514 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4536\n","Epoch 62/1000\n","3/3 [==============================] - 1s 348ms/step - loss: 13.0658 - auc_4: 0.9335 - categorical_accuracy: 0.8689 - val_loss: 81.8957 - val_auc_4: 0.7120 - val_categorical_accuracy: 0.4549\n","Epoch 63/1000\n","3/3 [==============================] - 1s 343ms/step - loss: 12.7649 - auc_4: 0.9348 - categorical_accuracy: 0.8720 - val_loss: 81.6579 - val_auc_4: 0.7122 - val_categorical_accuracy: 0.4520\n","Epoch 64/1000\n","3/3 [==============================] - 1s 345ms/step - loss: 12.4792 - auc_4: 0.9364 - categorical_accuracy: 0.8745 - val_loss: 81.4774 - val_auc_4: 0.7112 - val_categorical_accuracy: 0.4524\n","Epoch 65/1000\n","3/3 [==============================] - 1s 246ms/step - loss: 12.2023 - auc_4: 0.9379 - categorical_accuracy: 0.8777 - val_loss: 81.2132 - val_auc_4: 0.7125 - val_categorical_accuracy: 0.4536\n","Epoch 66/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 11.9406 - auc_4: 0.9388 - categorical_accuracy: 0.8806 - val_loss: 80.8697 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4553\n","Epoch 67/1000\n","3/3 [==============================] - 1s 185ms/step - loss: 11.6890 - auc_4: 0.9406 - categorical_accuracy: 0.8828 - val_loss: 80.5164 - val_auc_4: 0.7152 - val_categorical_accuracy: 0.4586\n","Epoch 68/1000\n","3/3 [==============================] - 1s 179ms/step - loss: 11.4514 - auc_4: 0.9423 - categorical_accuracy: 0.8849 - val_loss: 80.2882 - val_auc_4: 0.7155 - val_categorical_accuracy: 0.4637\n","Epoch 69/1000\n","3/3 [==============================] - 1s 221ms/step - loss: 11.2204 - auc_4: 0.9434 - categorical_accuracy: 0.8870 - val_loss: 80.0231 - val_auc_4: 0.7162 - val_categorical_accuracy: 0.4645\n","Epoch 70/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 10.9942 - auc_4: 0.9442 - categorical_accuracy: 0.8900 - val_loss: 79.7505 - val_auc_4: 0.7177 - val_categorical_accuracy: 0.4678\n","Epoch 71/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 10.7868 - auc_4: 0.9452 - categorical_accuracy: 0.8928 - val_loss: 79.5429 - val_auc_4: 0.7195 - val_categorical_accuracy: 0.4695\n","Epoch 72/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 10.5851 - auc_4: 0.9464 - categorical_accuracy: 0.8945 - val_loss: 79.2984 - val_auc_4: 0.7210 - val_categorical_accuracy: 0.4712\n","Epoch 73/1000\n","3/3 [==============================] - 1s 180ms/step - loss: 10.3817 - auc_4: 0.9475 - categorical_accuracy: 0.8960 - val_loss: 79.0202 - val_auc_4: 0.7216 - val_categorical_accuracy: 0.4749\n","Epoch 74/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 10.1912 - auc_4: 0.9484 - categorical_accuracy: 0.8972 - val_loss: 78.7925 - val_auc_4: 0.7223 - val_categorical_accuracy: 0.4770\n","Epoch 75/1000\n","3/3 [==============================] - 1s 185ms/step - loss: 10.0068 - auc_4: 0.9491 - categorical_accuracy: 0.8992 - val_loss: 78.6292 - val_auc_4: 0.7232 - val_categorical_accuracy: 0.4766\n","Epoch 76/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 9.8237 - auc_4: 0.9503 - categorical_accuracy: 0.9008 - val_loss: 78.4513 - val_auc_4: 0.7228 - val_categorical_accuracy: 0.4783\n","Epoch 77/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 9.6495 - auc_4: 0.9510 - categorical_accuracy: 0.9020 - val_loss: 78.2639 - val_auc_4: 0.7233 - val_categorical_accuracy: 0.4808\n","Epoch 78/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 9.4881 - auc_4: 0.9524 - categorical_accuracy: 0.9044 - val_loss: 78.0098 - val_auc_4: 0.7242 - val_categorical_accuracy: 0.4808\n","Epoch 79/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 9.3264 - auc_4: 0.9534 - categorical_accuracy: 0.9062 - val_loss: 77.7918 - val_auc_4: 0.7246 - val_categorical_accuracy: 0.4812\n","Epoch 80/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 9.1730 - auc_4: 0.9541 - categorical_accuracy: 0.9092 - val_loss: 77.6452 - val_auc_4: 0.7253 - val_categorical_accuracy: 0.4808\n","Epoch 81/1000\n","3/3 [==============================] - 1s 285ms/step - loss: 9.0198 - auc_4: 0.9552 - categorical_accuracy: 0.9106 - val_loss: 77.5253 - val_auc_4: 0.7255 - val_categorical_accuracy: 0.4812\n","Epoch 82/1000\n","3/3 [==============================] - 1s 290ms/step - loss: 8.8736 - auc_4: 0.9560 - categorical_accuracy: 0.9115 - val_loss: 77.3617 - val_auc_4: 0.7259 - val_categorical_accuracy: 0.4799\n","Epoch 83/1000\n","3/3 [==============================] - 1s 295ms/step - loss: 8.7311 - auc_4: 0.9567 - categorical_accuracy: 0.9135 - val_loss: 77.0887 - val_auc_4: 0.7264 - val_categorical_accuracy: 0.4808\n","Epoch 84/1000\n","3/3 [==============================] - 1s 313ms/step - loss: 8.5935 - auc_4: 0.9577 - categorical_accuracy: 0.9150 - val_loss: 76.8022 - val_auc_4: 0.7272 - val_categorical_accuracy: 0.4808\n","Epoch 85/1000\n","3/3 [==============================] - 1s 309ms/step - loss: 8.4605 - auc_4: 0.9583 - categorical_accuracy: 0.9164 - val_loss: 76.5322 - val_auc_4: 0.7281 - val_categorical_accuracy: 0.4833\n","Epoch 86/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 8.3306 - auc_4: 0.9592 - categorical_accuracy: 0.9181 - val_loss: 76.1823 - val_auc_4: 0.7275 - val_categorical_accuracy: 0.4845\n","Epoch 87/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 8.2069 - auc_4: 0.9597 - categorical_accuracy: 0.9192 - val_loss: 75.7747 - val_auc_4: 0.7273 - val_categorical_accuracy: 0.4862\n","Epoch 88/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 8.0820 - auc_4: 0.9604 - categorical_accuracy: 0.9204 - val_loss: 75.2861 - val_auc_4: 0.7287 - val_categorical_accuracy: 0.4858\n","Epoch 89/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 7.9677 - auc_4: 0.9606 - categorical_accuracy: 0.9216 - val_loss: 74.7328 - val_auc_4: 0.7302 - val_categorical_accuracy: 0.4862\n","Epoch 90/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 7.8610 - auc_4: 0.9610 - categorical_accuracy: 0.9223 - val_loss: 74.3257 - val_auc_4: 0.7308 - val_categorical_accuracy: 0.4875\n","Epoch 91/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 7.7578 - auc_4: 0.9613 - categorical_accuracy: 0.9229 - val_loss: 74.0272 - val_auc_4: 0.7319 - val_categorical_accuracy: 0.4900\n","Epoch 92/1000\n","3/3 [==============================] - 1s 218ms/step - loss: 7.6511 - auc_4: 0.9623 - categorical_accuracy: 0.9238 - val_loss: 73.7756 - val_auc_4: 0.7339 - val_categorical_accuracy: 0.4916\n","Epoch 93/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 7.5382 - auc_4: 0.9629 - categorical_accuracy: 0.9248 - val_loss: 73.5408 - val_auc_4: 0.7354 - val_categorical_accuracy: 0.4942\n","Epoch 94/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 7.4370 - auc_4: 0.9635 - categorical_accuracy: 0.9260 - val_loss: 73.4386 - val_auc_4: 0.7351 - val_categorical_accuracy: 0.4942\n","Epoch 95/1000\n","3/3 [==============================] - 1s 220ms/step - loss: 7.3378 - auc_4: 0.9637 - categorical_accuracy: 0.9274 - val_loss: 73.4775 - val_auc_4: 0.7356 - val_categorical_accuracy: 0.4987\n","Epoch 96/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 7.2415 - auc_4: 0.9639 - categorical_accuracy: 0.9289 - val_loss: 73.5840 - val_auc_4: 0.7342 - val_categorical_accuracy: 0.4971\n","Epoch 97/1000\n","3/3 [==============================] - 1s 221ms/step - loss: 7.1387 - auc_4: 0.9642 - categorical_accuracy: 0.9294 - val_loss: 73.5752 - val_auc_4: 0.7346 - val_categorical_accuracy: 0.4946\n","Epoch 98/1000\n","3/3 [==============================] - 1s 219ms/step - loss: 7.0425 - auc_4: 0.9648 - categorical_accuracy: 0.9301 - val_loss: 73.5287 - val_auc_4: 0.7333 - val_categorical_accuracy: 0.4916\n","Epoch 99/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 6.9474 - auc_4: 0.9655 - categorical_accuracy: 0.9303 - val_loss: 73.5254 - val_auc_4: 0.7313 - val_categorical_accuracy: 0.4908\n","Epoch 100/1000\n","3/3 [==============================] - 1s 219ms/step - loss: 6.8559 - auc_4: 0.9659 - categorical_accuracy: 0.9307 - val_loss: 73.5530 - val_auc_4: 0.7304 - val_categorical_accuracy: 0.4904\n","Epoch 101/1000\n","3/3 [==============================] - 1s 314ms/step - loss: 6.7741 - auc_4: 0.9658 - categorical_accuracy: 0.9316 - val_loss: 73.5191 - val_auc_4: 0.7315 - val_categorical_accuracy: 0.4900\n","Epoch 102/1000\n","3/3 [==============================] - 1s 316ms/step - loss: 6.6902 - auc_4: 0.9659 - categorical_accuracy: 0.9318 - val_loss: 73.4602 - val_auc_4: 0.7324 - val_categorical_accuracy: 0.4908\n","Epoch 103/1000\n","3/3 [==============================] - 1s 297ms/step - loss: 6.6053 - auc_4: 0.9666 - categorical_accuracy: 0.9325 - val_loss: 73.4355 - val_auc_4: 0.7329 - val_categorical_accuracy: 0.4925\n","Epoch 104/1000\n","3/3 [==============================] - 1s 312ms/step - loss: 6.5188 - auc_4: 0.9670 - categorical_accuracy: 0.9338 - val_loss: 73.4496 - val_auc_4: 0.7339 - val_categorical_accuracy: 0.4942\n","Epoch 105/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 6.4369 - auc_4: 0.9673 - categorical_accuracy: 0.9351 - val_loss: 73.3748 - val_auc_4: 0.7345 - val_categorical_accuracy: 0.4942\n","Epoch 106/1000\n","3/3 [==============================] - 1s 219ms/step - loss: 6.3535 - auc_4: 0.9680 - categorical_accuracy: 0.9359 - val_loss: 73.1012 - val_auc_4: 0.7346 - val_categorical_accuracy: 0.4958\n","Epoch 107/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 6.2748 - auc_4: 0.9682 - categorical_accuracy: 0.9366 - val_loss: 72.8433 - val_auc_4: 0.7351 - val_categorical_accuracy: 0.4962\n","Epoch 108/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 6.1950 - auc_4: 0.9683 - categorical_accuracy: 0.9377 - val_loss: 72.7299 - val_auc_4: 0.7356 - val_categorical_accuracy: 0.4979\n","Epoch 109/1000\n","3/3 [==============================] - 1s 183ms/step - loss: 6.1205 - auc_4: 0.9687 - categorical_accuracy: 0.9378 - val_loss: 72.6176 - val_auc_4: 0.7354 - val_categorical_accuracy: 0.4983\n","Epoch 110/1000\n","3/3 [==============================] - 1s 221ms/step - loss: 6.0474 - auc_4: 0.9691 - categorical_accuracy: 0.9378 - val_loss: 72.5340 - val_auc_4: 0.7358 - val_categorical_accuracy: 0.4983\n","Epoch 111/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 5.9748 - auc_4: 0.9696 - categorical_accuracy: 0.9384 - val_loss: 72.6159 - val_auc_4: 0.7345 - val_categorical_accuracy: 0.4971\n","Epoch 112/1000\n","3/3 [==============================] - 1s 219ms/step - loss: 5.9021 - auc_4: 0.9698 - categorical_accuracy: 0.9395 - val_loss: 72.7235 - val_auc_4: 0.7347 - val_categorical_accuracy: 0.4967\n","Epoch 113/1000\n","3/3 [==============================] - 1s 218ms/step - loss: 5.8332 - auc_4: 0.9702 - categorical_accuracy: 0.9401 - val_loss: 72.7423 - val_auc_4: 0.7349 - val_categorical_accuracy: 0.4967\n","Epoch 114/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 5.7633 - auc_4: 0.9705 - categorical_accuracy: 0.9406 - val_loss: 72.6042 - val_auc_4: 0.7355 - val_categorical_accuracy: 0.4983\n","Epoch 115/1000\n","3/3 [==============================] - 1s 220ms/step - loss: 5.6929 - auc_4: 0.9710 - categorical_accuracy: 0.9411 - val_loss: 72.4151 - val_auc_4: 0.7356 - val_categorical_accuracy: 0.4987\n","Epoch 116/1000\n","3/3 [==============================] - 1s 182ms/step - loss: 5.6245 - auc_4: 0.9713 - categorical_accuracy: 0.9419 - val_loss: 72.2930 - val_auc_4: 0.7363 - val_categorical_accuracy: 0.5000\n","Epoch 117/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 5.5565 - auc_4: 0.9714 - categorical_accuracy: 0.9429 - val_loss: 72.1483 - val_auc_4: 0.7362 - val_categorical_accuracy: 0.5021\n","Epoch 118/1000\n","3/3 [==============================] - 1s 218ms/step - loss: 5.4935 - auc_4: 0.9716 - categorical_accuracy: 0.9438 - val_loss: 72.0960 - val_auc_4: 0.7366 - val_categorical_accuracy: 0.5025\n","Epoch 119/1000\n","3/3 [==============================] - 1s 178ms/step - loss: 5.4312 - auc_4: 0.9720 - categorical_accuracy: 0.9443 - val_loss: 72.2094 - val_auc_4: 0.7368 - val_categorical_accuracy: 0.5025\n","Epoch 120/1000\n","3/3 [==============================] - 1s 255ms/step - loss: 5.3682 - auc_4: 0.9726 - categorical_accuracy: 0.9445 - val_loss: 72.3245 - val_auc_4: 0.7365 - val_categorical_accuracy: 0.5013\n","Epoch 121/1000\n","3/3 [==============================] - 1s 309ms/step - loss: 5.3057 - auc_4: 0.9732 - categorical_accuracy: 0.9449 - val_loss: 72.3195 - val_auc_4: 0.7357 - val_categorical_accuracy: 0.4996\n","Epoch 122/1000\n","3/3 [==============================] - 1s 312ms/step - loss: 5.2475 - auc_4: 0.9733 - categorical_accuracy: 0.9456 - val_loss: 72.2130 - val_auc_4: 0.7356 - val_categorical_accuracy: 0.4987\n","Epoch 123/1000\n","3/3 [==============================] - 1s 430ms/step - loss: 5.1888 - auc_4: 0.9735 - categorical_accuracy: 0.9463 - val_loss: 72.0092 - val_auc_4: 0.7358 - val_categorical_accuracy: 0.4975\n","Epoch 124/1000\n","3/3 [==============================] - 1s 344ms/step - loss: 5.1306 - auc_4: 0.9738 - categorical_accuracy: 0.9471 - val_loss: 71.8888 - val_auc_4: 0.7360 - val_categorical_accuracy: 0.4975\n","Epoch 125/1000\n","3/3 [==============================] - 1s 330ms/step - loss: 5.0723 - auc_4: 0.9745 - categorical_accuracy: 0.9478 - val_loss: 71.7768 - val_auc_4: 0.7365 - val_categorical_accuracy: 0.4983\n","Epoch 126/1000\n","3/3 [==============================] - 1s 316ms/step - loss: 5.0126 - auc_4: 0.9748 - categorical_accuracy: 0.9484 - val_loss: 71.7333 - val_auc_4: 0.7369 - val_categorical_accuracy: 0.4992\n","Epoch 127/1000\n","3/3 [==============================] - 1s 312ms/step - loss: 4.9552 - auc_4: 0.9750 - categorical_accuracy: 0.9498 - val_loss: 71.7174 - val_auc_4: 0.7369 - val_categorical_accuracy: 0.5008\n","Epoch 128/1000\n","3/3 [==============================] - 1s 310ms/step - loss: 4.9022 - auc_4: 0.9756 - categorical_accuracy: 0.9504 - val_loss: 71.7433 - val_auc_4: 0.7370 - val_categorical_accuracy: 0.5021\n","Epoch 129/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 4.8498 - auc_4: 0.9758 - categorical_accuracy: 0.9511 - val_loss: 71.7784 - val_auc_4: 0.7361 - val_categorical_accuracy: 0.5008\n","Epoch 130/1000\n","3/3 [==============================] - 1s 220ms/step - loss: 4.7975 - auc_4: 0.9761 - categorical_accuracy: 0.9515 - val_loss: 71.7894 - val_auc_4: 0.7356 - val_categorical_accuracy: 0.5000\n","Epoch 131/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 4.7460 - auc_4: 0.9765 - categorical_accuracy: 0.9516 - val_loss: 71.7483 - val_auc_4: 0.7354 - val_categorical_accuracy: 0.4992\n","Epoch 132/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 4.6963 - auc_4: 0.9768 - categorical_accuracy: 0.9524 - val_loss: 71.6742 - val_auc_4: 0.7350 - val_categorical_accuracy: 0.4979\n","Epoch 133/1000\n","3/3 [==============================] - 1s 183ms/step - loss: 4.6492 - auc_4: 0.9768 - categorical_accuracy: 0.9534 - val_loss: 71.6204 - val_auc_4: 0.7354 - val_categorical_accuracy: 0.4975\n","Epoch 134/1000\n","3/3 [==============================] - 1s 221ms/step - loss: 4.6020 - auc_4: 0.9768 - categorical_accuracy: 0.9536 - val_loss: 71.5175 - val_auc_4: 0.7356 - val_categorical_accuracy: 0.4975\n","Epoch 135/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 4.5540 - auc_4: 0.9770 - categorical_accuracy: 0.9537 - val_loss: 71.3396 - val_auc_4: 0.7349 - val_categorical_accuracy: 0.4962\n","Epoch 136/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 4.5068 - auc_4: 0.9772 - categorical_accuracy: 0.9538 - val_loss: 71.1031 - val_auc_4: 0.7360 - val_categorical_accuracy: 0.4946\n","Epoch 137/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 4.4561 - auc_4: 0.9775 - categorical_accuracy: 0.9548 - val_loss: 71.0255 - val_auc_4: 0.7364 - val_categorical_accuracy: 0.4958\n","Epoch 138/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 4.4041 - auc_4: 0.9779 - categorical_accuracy: 0.9555 - val_loss: 71.0972 - val_auc_4: 0.7364 - val_categorical_accuracy: 0.4967\n","Epoch 139/1000\n","3/3 [==============================] - 1s 237ms/step - loss: 4.3550 - auc_4: 0.9778 - categorical_accuracy: 0.9560 - val_loss: 71.2406 - val_auc_4: 0.7365 - val_categorical_accuracy: 0.4962\n","Epoch 140/1000\n","3/3 [==============================] - 1s 289ms/step - loss: 4.3047 - auc_4: 0.9782 - categorical_accuracy: 0.9555 - val_loss: 71.4040 - val_auc_4: 0.7353 - val_categorical_accuracy: 0.4954\n","Epoch 141/1000\n","3/3 [==============================] - 1s 309ms/step - loss: 4.2602 - auc_4: 0.9785 - categorical_accuracy: 0.9554 - val_loss: 71.5459 - val_auc_4: 0.7355 - val_categorical_accuracy: 0.4979\n","Epoch 142/1000\n","3/3 [==============================] - 1s 324ms/step - loss: 4.2177 - auc_4: 0.9785 - categorical_accuracy: 0.9555 - val_loss: 71.6763 - val_auc_4: 0.7354 - val_categorical_accuracy: 0.4958\n","Epoch 143/1000\n","3/3 [==============================] - 1s 323ms/step - loss: 4.1762 - auc_4: 0.9786 - categorical_accuracy: 0.9557 - val_loss: 71.7993 - val_auc_4: 0.7347 - val_categorical_accuracy: 0.4946\n","Epoch 144/1000\n","3/3 [==============================] - 1s 312ms/step - loss: 4.1314 - auc_4: 0.9789 - categorical_accuracy: 0.9561 - val_loss: 71.8592 - val_auc_4: 0.7334 - val_categorical_accuracy: 0.4929\n","Epoch 145/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 4.0869 - auc_4: 0.9791 - categorical_accuracy: 0.9567 - val_loss: 71.8330 - val_auc_4: 0.7331 - val_categorical_accuracy: 0.4900\n","Epoch 146/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 4.0411 - auc_4: 0.9793 - categorical_accuracy: 0.9574 - val_loss: 71.8940 - val_auc_4: 0.7320 - val_categorical_accuracy: 0.4900\n","Epoch 147/1000\n","3/3 [==============================] - 1s 182ms/step - loss: 3.9953 - auc_4: 0.9794 - categorical_accuracy: 0.9582 - val_loss: 72.0976 - val_auc_4: 0.7313 - val_categorical_accuracy: 0.4879\n","Epoch 148/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 3.9489 - auc_4: 0.9797 - categorical_accuracy: 0.9592 - val_loss: 72.3327 - val_auc_4: 0.7309 - val_categorical_accuracy: 0.4866\n","Epoch 149/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 3.9013 - auc_4: 0.9803 - categorical_accuracy: 0.9593 - val_loss: 72.6168 - val_auc_4: 0.7320 - val_categorical_accuracy: 0.4858\n","Epoch 150/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 3.8622 - auc_4: 0.9804 - categorical_accuracy: 0.9596 - val_loss: 72.7610 - val_auc_4: 0.7310 - val_categorical_accuracy: 0.4854\n","Epoch 151/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 3.8188 - auc_4: 0.9807 - categorical_accuracy: 0.9600 - val_loss: 72.7695 - val_auc_4: 0.7300 - val_categorical_accuracy: 0.4850\n","Epoch 152/1000\n","3/3 [==============================] - 1s 195ms/step - loss: 3.7768 - auc_4: 0.9809 - categorical_accuracy: 0.9607 - val_loss: 72.7236 - val_auc_4: 0.7289 - val_categorical_accuracy: 0.4833\n","Epoch 153/1000\n","3/3 [==============================] - 1s 183ms/step - loss: 3.7373 - auc_4: 0.9814 - categorical_accuracy: 0.9606 - val_loss: 72.6212 - val_auc_4: 0.7285 - val_categorical_accuracy: 0.4808\n","Epoch 154/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 3.6972 - auc_4: 0.9813 - categorical_accuracy: 0.9611 - val_loss: 72.5661 - val_auc_4: 0.7287 - val_categorical_accuracy: 0.4825\n","Epoch 155/1000\n","3/3 [==============================] - 1s 219ms/step - loss: 3.6609 - auc_4: 0.9817 - categorical_accuracy: 0.9616 - val_loss: 72.5701 - val_auc_4: 0.7288 - val_categorical_accuracy: 0.4816\n","Epoch 156/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 3.6233 - auc_4: 0.9818 - categorical_accuracy: 0.9624 - val_loss: 72.5229 - val_auc_4: 0.7286 - val_categorical_accuracy: 0.4816\n","Epoch 157/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 3.5872 - auc_4: 0.9820 - categorical_accuracy: 0.9625 - val_loss: 72.4393 - val_auc_4: 0.7295 - val_categorical_accuracy: 0.4812\n","Epoch 158/1000\n","3/3 [==============================] - 1s 221ms/step - loss: 3.5500 - auc_4: 0.9822 - categorical_accuracy: 0.9631 - val_loss: 72.4350 - val_auc_4: 0.7279 - val_categorical_accuracy: 0.4825\n","Epoch 159/1000\n","3/3 [==============================] - 1s 221ms/step - loss: 3.5129 - auc_4: 0.9822 - categorical_accuracy: 0.9631 - val_loss: 72.5343 - val_auc_4: 0.7275 - val_categorical_accuracy: 0.4833\n","Epoch 160/1000\n","3/3 [==============================] - 1s 303ms/step - loss: 3.4735 - auc_4: 0.9824 - categorical_accuracy: 0.9637 - val_loss: 72.6915 - val_auc_4: 0.7277 - val_categorical_accuracy: 0.4820\n","Epoch 161/1000\n","3/3 [==============================] - 1s 302ms/step - loss: 3.4354 - auc_4: 0.9826 - categorical_accuracy: 0.9639 - val_loss: 72.9237 - val_auc_4: 0.7274 - val_categorical_accuracy: 0.4808\n","Epoch 162/1000\n","3/3 [==============================] - 1s 326ms/step - loss: 3.3996 - auc_4: 0.9831 - categorical_accuracy: 0.9644 - val_loss: 73.1347 - val_auc_4: 0.7271 - val_categorical_accuracy: 0.4812\n","Epoch 163/1000\n","3/3 [==============================] - 1s 341ms/step - loss: 3.3652 - auc_4: 0.9831 - categorical_accuracy: 0.9649 - val_loss: 73.2356 - val_auc_4: 0.7275 - val_categorical_accuracy: 0.4812\n","Epoch 164/1000\n","3/3 [==============================] - 1s 291ms/step - loss: 3.3281 - auc_4: 0.9836 - categorical_accuracy: 0.9656 - val_loss: 73.2224 - val_auc_4: 0.7271 - val_categorical_accuracy: 0.4820\n","Epoch 165/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 3.2914 - auc_4: 0.9836 - categorical_accuracy: 0.9660 - val_loss: 73.1824 - val_auc_4: 0.7268 - val_categorical_accuracy: 0.4808\n","Epoch 166/1000\n","3/3 [==============================] - 1s 219ms/step - loss: 3.2585 - auc_4: 0.9836 - categorical_accuracy: 0.9664 - val_loss: 73.1877 - val_auc_4: 0.7273 - val_categorical_accuracy: 0.4829\n","Epoch 167/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 3.2256 - auc_4: 0.9837 - categorical_accuracy: 0.9669 - val_loss: 73.1145 - val_auc_4: 0.7275 - val_categorical_accuracy: 0.4829\n","Epoch 168/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 3.1933 - auc_4: 0.9839 - categorical_accuracy: 0.9672 - val_loss: 73.0616 - val_auc_4: 0.7273 - val_categorical_accuracy: 0.4825\n","Epoch 169/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 3.1620 - auc_4: 0.9841 - categorical_accuracy: 0.9669 - val_loss: 73.0644 - val_auc_4: 0.7266 - val_categorical_accuracy: 0.4804\n","Epoch 170/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 3.1257 - auc_4: 0.9845 - categorical_accuracy: 0.9673 - val_loss: 73.0919 - val_auc_4: 0.7257 - val_categorical_accuracy: 0.4795\n","Epoch 171/1000\n","3/3 [==============================] - 1s 182ms/step - loss: 3.0955 - auc_4: 0.9846 - categorical_accuracy: 0.9667 - val_loss: 73.2150 - val_auc_4: 0.7246 - val_categorical_accuracy: 0.4770\n","Epoch 172/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 3.0656 - auc_4: 0.9846 - categorical_accuracy: 0.9672 - val_loss: 73.2867 - val_auc_4: 0.7248 - val_categorical_accuracy: 0.4762\n","Epoch 173/1000\n","3/3 [==============================] - 1s 181ms/step - loss: 3.0368 - auc_4: 0.9848 - categorical_accuracy: 0.9674 - val_loss: 73.2807 - val_auc_4: 0.7253 - val_categorical_accuracy: 0.4770\n","Epoch 174/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 3.0067 - auc_4: 0.9849 - categorical_accuracy: 0.9683 - val_loss: 73.2720 - val_auc_4: 0.7262 - val_categorical_accuracy: 0.4799\n","Epoch 175/1000\n","3/3 [==============================] - 1s 198ms/step - loss: 2.9786 - auc_4: 0.9850 - categorical_accuracy: 0.9691 - val_loss: 73.2487 - val_auc_4: 0.7265 - val_categorical_accuracy: 0.4808\n","Epoch 176/1000\n","3/3 [==============================] - 1s 185ms/step - loss: 2.9509 - auc_4: 0.9851 - categorical_accuracy: 0.9695 - val_loss: 73.2076 - val_auc_4: 0.7269 - val_categorical_accuracy: 0.4841\n","Epoch 177/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 2.9249 - auc_4: 0.9854 - categorical_accuracy: 0.9697 - val_loss: 73.1882 - val_auc_4: 0.7274 - val_categorical_accuracy: 0.4833\n","Epoch 178/1000\n","3/3 [==============================] - 1s 221ms/step - loss: 2.8965 - auc_4: 0.9854 - categorical_accuracy: 0.9698 - val_loss: 73.2545 - val_auc_4: 0.7268 - val_categorical_accuracy: 0.4820\n","Epoch 179/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 2.8685 - auc_4: 0.9856 - categorical_accuracy: 0.9701 - val_loss: 73.3189 - val_auc_4: 0.7262 - val_categorical_accuracy: 0.4799\n","Epoch 180/1000\n","3/3 [==============================] - 1s 299ms/step - loss: 2.8403 - auc_4: 0.9857 - categorical_accuracy: 0.9705 - val_loss: 73.2809 - val_auc_4: 0.7262 - val_categorical_accuracy: 0.4799\n","Epoch 181/1000\n","3/3 [==============================] - 1s 310ms/step - loss: 2.8155 - auc_4: 0.9858 - categorical_accuracy: 0.9711 - val_loss: 73.2401 - val_auc_4: 0.7261 - val_categorical_accuracy: 0.4804\n","Epoch 182/1000\n","3/3 [==============================] - 1s 294ms/step - loss: 2.7875 - auc_4: 0.9859 - categorical_accuracy: 0.9707 - val_loss: 73.3033 - val_auc_4: 0.7260 - val_categorical_accuracy: 0.4795\n","Epoch 183/1000\n","3/3 [==============================] - 1s 310ms/step - loss: 2.7610 - auc_4: 0.9859 - categorical_accuracy: 0.9707 - val_loss: 73.3308 - val_auc_4: 0.7257 - val_categorical_accuracy: 0.4799\n","Epoch 184/1000\n","3/3 [==============================] - 1s 277ms/step - loss: 2.7331 - auc_4: 0.9860 - categorical_accuracy: 0.9711 - val_loss: 73.4411 - val_auc_4: 0.7255 - val_categorical_accuracy: 0.4795\n","Epoch 185/1000\n","3/3 [==============================] - 1s 181ms/step - loss: 2.7062 - auc_4: 0.9863 - categorical_accuracy: 0.9712 - val_loss: 73.6721 - val_auc_4: 0.7249 - val_categorical_accuracy: 0.4808\n","Epoch 186/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 2.6797 - auc_4: 0.9865 - categorical_accuracy: 0.9716 - val_loss: 73.9307 - val_auc_4: 0.7240 - val_categorical_accuracy: 0.4787\n","Epoch 187/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 2.6547 - auc_4: 0.9866 - categorical_accuracy: 0.9722 - val_loss: 74.1085 - val_auc_4: 0.7234 - val_categorical_accuracy: 0.4791\n","Epoch 188/1000\n","3/3 [==============================] - 1s 189ms/step - loss: 2.6308 - auc_4: 0.9865 - categorical_accuracy: 0.9723 - val_loss: 74.1666 - val_auc_4: 0.7240 - val_categorical_accuracy: 0.4791\n","Epoch 189/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 2.6066 - auc_4: 0.9867 - categorical_accuracy: 0.9725 - val_loss: 74.1699 - val_auc_4: 0.7247 - val_categorical_accuracy: 0.4795\n","Epoch 190/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 2.5828 - auc_4: 0.9868 - categorical_accuracy: 0.9725 - val_loss: 74.0758 - val_auc_4: 0.7249 - val_categorical_accuracy: 0.4812\n","Epoch 191/1000\n","3/3 [==============================] - 1s 221ms/step - loss: 2.5580 - auc_4: 0.9870 - categorical_accuracy: 0.9725 - val_loss: 74.0585 - val_auc_4: 0.7253 - val_categorical_accuracy: 0.4816\n","Epoch 192/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 2.5333 - auc_4: 0.9874 - categorical_accuracy: 0.9730 - val_loss: 74.1246 - val_auc_4: 0.7251 - val_categorical_accuracy: 0.4820\n","Epoch 193/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 2.5086 - auc_4: 0.9876 - categorical_accuracy: 0.9729 - val_loss: 74.2501 - val_auc_4: 0.7251 - val_categorical_accuracy: 0.4787\n","Epoch 194/1000\n","3/3 [==============================] - 1s 220ms/step - loss: 2.4863 - auc_4: 0.9878 - categorical_accuracy: 0.9734 - val_loss: 74.4132 - val_auc_4: 0.7251 - val_categorical_accuracy: 0.4758\n","Epoch 195/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 2.4642 - auc_4: 0.9878 - categorical_accuracy: 0.9735 - val_loss: 74.4401 - val_auc_4: 0.7244 - val_categorical_accuracy: 0.4754\n","Epoch 196/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 2.4435 - auc_4: 0.9878 - categorical_accuracy: 0.9740 - val_loss: 74.3725 - val_auc_4: 0.7247 - val_categorical_accuracy: 0.4745\n","Epoch 197/1000\n","3/3 [==============================] - 1s 185ms/step - loss: 2.4230 - auc_4: 0.9879 - categorical_accuracy: 0.9741 - val_loss: 74.2471 - val_auc_4: 0.7243 - val_categorical_accuracy: 0.4745\n","Epoch 198/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 2.4000 - auc_4: 0.9882 - categorical_accuracy: 0.9747 - val_loss: 74.1112 - val_auc_4: 0.7232 - val_categorical_accuracy: 0.4733\n","Epoch 199/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 2.3777 - auc_4: 0.9883 - categorical_accuracy: 0.9746 - val_loss: 73.9419 - val_auc_4: 0.7232 - val_categorical_accuracy: 0.4733\n","Epoch 200/1000\n","3/3 [==============================] - 1s 293ms/step - loss: 2.3544 - auc_4: 0.9885 - categorical_accuracy: 0.9748 - val_loss: 73.8618 - val_auc_4: 0.7236 - val_categorical_accuracy: 0.4733\n","Epoch 201/1000\n","3/3 [==============================] - 1s 308ms/step - loss: 2.3323 - auc_4: 0.9886 - categorical_accuracy: 0.9753 - val_loss: 73.8998 - val_auc_4: 0.7221 - val_categorical_accuracy: 0.4720\n","Epoch 202/1000\n","3/3 [==============================] - 1s 320ms/step - loss: 2.3098 - auc_4: 0.9886 - categorical_accuracy: 0.9763 - val_loss: 74.0596 - val_auc_4: 0.7218 - val_categorical_accuracy: 0.4708\n","Epoch 203/1000\n","3/3 [==============================] - 1s 318ms/step - loss: 2.2891 - auc_4: 0.9884 - categorical_accuracy: 0.9764 - val_loss: 74.3306 - val_auc_4: 0.7218 - val_categorical_accuracy: 0.4708\n","Epoch 204/1000\n","3/3 [==============================] - 1s 290ms/step - loss: 2.2715 - auc_4: 0.9885 - categorical_accuracy: 0.9762 - val_loss: 74.5845 - val_auc_4: 0.7222 - val_categorical_accuracy: 0.4699\n","Epoch 205/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 2.2549 - auc_4: 0.9887 - categorical_accuracy: 0.9762 - val_loss: 74.6514 - val_auc_4: 0.7220 - val_categorical_accuracy: 0.4712\n","Epoch 206/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 2.2376 - auc_4: 0.9886 - categorical_accuracy: 0.9760 - val_loss: 74.8019 - val_auc_4: 0.7220 - val_categorical_accuracy: 0.4699\n","Epoch 207/1000\n","3/3 [==============================] - 1s 219ms/step - loss: 2.2170 - auc_4: 0.9890 - categorical_accuracy: 0.9763 - val_loss: 75.0060 - val_auc_4: 0.7222 - val_categorical_accuracy: 0.4699\n","Epoch 208/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 2.1974 - auc_4: 0.9889 - categorical_accuracy: 0.9763 - val_loss: 75.1142 - val_auc_4: 0.7224 - val_categorical_accuracy: 0.4699\n","Epoch 209/1000\n","3/3 [==============================] - 1s 219ms/step - loss: 2.1767 - auc_4: 0.9892 - categorical_accuracy: 0.9768 - val_loss: 75.1194 - val_auc_4: 0.7229 - val_categorical_accuracy: 0.4708\n","Epoch 210/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 2.1552 - auc_4: 0.9894 - categorical_accuracy: 0.9775 - val_loss: 75.0679 - val_auc_4: 0.7229 - val_categorical_accuracy: 0.4703\n","Epoch 211/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 2.1332 - auc_4: 0.9895 - categorical_accuracy: 0.9778 - val_loss: 74.9506 - val_auc_4: 0.7227 - val_categorical_accuracy: 0.4712\n","Epoch 212/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 2.1139 - auc_4: 0.9894 - categorical_accuracy: 0.9783 - val_loss: 74.9560 - val_auc_4: 0.7227 - val_categorical_accuracy: 0.4703\n","Epoch 213/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 2.0947 - auc_4: 0.9896 - categorical_accuracy: 0.9778 - val_loss: 75.0890 - val_auc_4: 0.7218 - val_categorical_accuracy: 0.4695\n","Epoch 214/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 2.0770 - auc_4: 0.9898 - categorical_accuracy: 0.9776 - val_loss: 75.1592 - val_auc_4: 0.7211 - val_categorical_accuracy: 0.4695\n","Epoch 215/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 2.0577 - auc_4: 0.9899 - categorical_accuracy: 0.9769 - val_loss: 75.3447 - val_auc_4: 0.7200 - val_categorical_accuracy: 0.4678\n","Epoch 216/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 2.0393 - auc_4: 0.9899 - categorical_accuracy: 0.9768 - val_loss: 75.6387 - val_auc_4: 0.7197 - val_categorical_accuracy: 0.4674\n","Epoch 217/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 2.0219 - auc_4: 0.9897 - categorical_accuracy: 0.9770 - val_loss: 75.7678 - val_auc_4: 0.7199 - val_categorical_accuracy: 0.4662\n","Epoch 218/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 2.0039 - auc_4: 0.9898 - categorical_accuracy: 0.9768 - val_loss: 75.8309 - val_auc_4: 0.7196 - val_categorical_accuracy: 0.4662\n","Epoch 219/1000\n","3/3 [==============================] - 1s 291ms/step - loss: 1.9866 - auc_4: 0.9900 - categorical_accuracy: 0.9772 - val_loss: 75.8630 - val_auc_4: 0.7182 - val_categorical_accuracy: 0.4666\n","Epoch 220/1000\n","3/3 [==============================] - 1s 297ms/step - loss: 1.9666 - auc_4: 0.9900 - categorical_accuracy: 0.9782 - val_loss: 75.7202 - val_auc_4: 0.7181 - val_categorical_accuracy: 0.4662\n","Epoch 221/1000\n","3/3 [==============================] - 1s 324ms/step - loss: 1.9504 - auc_4: 0.9901 - categorical_accuracy: 0.9781 - val_loss: 75.6731 - val_auc_4: 0.7183 - val_categorical_accuracy: 0.4670\n","Epoch 222/1000\n","3/3 [==============================] - 1s 325ms/step - loss: 1.9332 - auc_4: 0.9901 - categorical_accuracy: 0.9778 - val_loss: 75.6430 - val_auc_4: 0.7183 - val_categorical_accuracy: 0.4657\n","Epoch 223/1000\n","3/3 [==============================] - 1s 307ms/step - loss: 1.9128 - auc_4: 0.9902 - categorical_accuracy: 0.9783 - val_loss: 75.5925 - val_auc_4: 0.7192 - val_categorical_accuracy: 0.4649\n","Epoch 224/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 1.8948 - auc_4: 0.9904 - categorical_accuracy: 0.9790 - val_loss: 75.5251 - val_auc_4: 0.7192 - val_categorical_accuracy: 0.4662\n","Epoch 225/1000\n","3/3 [==============================] - 1s 185ms/step - loss: 1.8799 - auc_4: 0.9905 - categorical_accuracy: 0.9793 - val_loss: 75.4819 - val_auc_4: 0.7198 - val_categorical_accuracy: 0.4687\n","Epoch 226/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 1.8648 - auc_4: 0.9905 - categorical_accuracy: 0.9797 - val_loss: 75.5031 - val_auc_4: 0.7192 - val_categorical_accuracy: 0.4670\n","Epoch 227/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 1.8483 - auc_4: 0.9907 - categorical_accuracy: 0.9798 - val_loss: 75.5663 - val_auc_4: 0.7191 - val_categorical_accuracy: 0.4670\n","Epoch 228/1000\n","3/3 [==============================] - 1s 221ms/step - loss: 1.8328 - auc_4: 0.9908 - categorical_accuracy: 0.9800 - val_loss: 75.5338 - val_auc_4: 0.7188 - val_categorical_accuracy: 0.4666\n","Epoch 229/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 1.8172 - auc_4: 0.9908 - categorical_accuracy: 0.9805 - val_loss: 75.4246 - val_auc_4: 0.7189 - val_categorical_accuracy: 0.4657\n","Epoch 230/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 1.8021 - auc_4: 0.9909 - categorical_accuracy: 0.9809 - val_loss: 75.2816 - val_auc_4: 0.7187 - val_categorical_accuracy: 0.4653\n","Epoch 231/1000\n","3/3 [==============================] - 1s 180ms/step - loss: 1.7876 - auc_4: 0.9911 - categorical_accuracy: 0.9812 - val_loss: 75.0784 - val_auc_4: 0.7195 - val_categorical_accuracy: 0.4657\n","Epoch 232/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 1.7746 - auc_4: 0.9914 - categorical_accuracy: 0.9812 - val_loss: 74.8496 - val_auc_4: 0.7196 - val_categorical_accuracy: 0.4670\n","Epoch 233/1000\n","3/3 [==============================] - 1s 182ms/step - loss: 1.7633 - auc_4: 0.9914 - categorical_accuracy: 0.9807 - val_loss: 74.7265 - val_auc_4: 0.7198 - val_categorical_accuracy: 0.4666\n","Epoch 234/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 1.7499 - auc_4: 0.9914 - categorical_accuracy: 0.9806 - val_loss: 74.7044 - val_auc_4: 0.7207 - val_categorical_accuracy: 0.4687\n","Epoch 235/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 1.7354 - auc_4: 0.9912 - categorical_accuracy: 0.9810 - val_loss: 74.7780 - val_auc_4: 0.7207 - val_categorical_accuracy: 0.4699\n","Epoch 236/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 1.7215 - auc_4: 0.9912 - categorical_accuracy: 0.9812 - val_loss: 74.9066 - val_auc_4: 0.7214 - val_categorical_accuracy: 0.4703\n","Epoch 237/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 1.7073 - auc_4: 0.9916 - categorical_accuracy: 0.9812 - val_loss: 75.0641 - val_auc_4: 0.7209 - val_categorical_accuracy: 0.4695\n","Epoch 238/1000\n","3/3 [==============================] - 1s 234ms/step - loss: 1.6938 - auc_4: 0.9917 - categorical_accuracy: 0.9811 - val_loss: 75.2406 - val_auc_4: 0.7197 - val_categorical_accuracy: 0.4666\n","Epoch 239/1000\n","3/3 [==============================] - 1s 258ms/step - loss: 1.6789 - auc_4: 0.9917 - categorical_accuracy: 0.9816 - val_loss: 75.3494 - val_auc_4: 0.7175 - val_categorical_accuracy: 0.4662\n","Epoch 240/1000\n","3/3 [==============================] - 1s 299ms/step - loss: 1.6651 - auc_4: 0.9918 - categorical_accuracy: 0.9821 - val_loss: 75.3800 - val_auc_4: 0.7176 - val_categorical_accuracy: 0.4645\n","Epoch 241/1000\n","3/3 [==============================] - 1s 352ms/step - loss: 1.6535 - auc_4: 0.9918 - categorical_accuracy: 0.9817 - val_loss: 75.4063 - val_auc_4: 0.7171 - val_categorical_accuracy: 0.4632\n","Epoch 242/1000\n","3/3 [==============================] - 1s 472ms/step - loss: 1.6438 - auc_4: 0.9919 - categorical_accuracy: 0.9813 - val_loss: 75.4636 - val_auc_4: 0.7165 - val_categorical_accuracy: 0.4628\n","Epoch 243/1000\n","3/3 [==============================] - 1s 454ms/step - loss: 1.6305 - auc_4: 0.9920 - categorical_accuracy: 0.9811 - val_loss: 75.5624 - val_auc_4: 0.7159 - val_categorical_accuracy: 0.4641\n","Epoch 244/1000\n","3/3 [==============================] - 1s 378ms/step - loss: 1.6169 - auc_4: 0.9919 - categorical_accuracy: 0.9810 - val_loss: 75.6512 - val_auc_4: 0.7163 - val_categorical_accuracy: 0.4657\n","Epoch 245/1000\n","3/3 [==============================] - 1s 304ms/step - loss: 1.6045 - auc_4: 0.9921 - categorical_accuracy: 0.9816 - val_loss: 75.8067 - val_auc_4: 0.7171 - val_categorical_accuracy: 0.4649\n","Epoch 246/1000\n","3/3 [==============================] - 1s 318ms/step - loss: 1.5899 - auc_4: 0.9923 - categorical_accuracy: 0.9819 - val_loss: 75.8801 - val_auc_4: 0.7164 - val_categorical_accuracy: 0.4645\n","Epoch 247/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 1.5765 - auc_4: 0.9925 - categorical_accuracy: 0.9828 - val_loss: 75.8701 - val_auc_4: 0.7161 - val_categorical_accuracy: 0.4624\n","Epoch 248/1000\n","3/3 [==============================] - 1s 205ms/step - loss: 1.5627 - auc_4: 0.9925 - categorical_accuracy: 0.9834 - val_loss: 75.8585 - val_auc_4: 0.7161 - val_categorical_accuracy: 0.4616\n","Epoch 249/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 1.5500 - auc_4: 0.9926 - categorical_accuracy: 0.9832 - val_loss: 75.9143 - val_auc_4: 0.7157 - val_categorical_accuracy: 0.4595\n","Epoch 250/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 1.5374 - auc_4: 0.9927 - categorical_accuracy: 0.9833 - val_loss: 75.8837 - val_auc_4: 0.7154 - val_categorical_accuracy: 0.4591\n","Epoch 251/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 1.5248 - auc_4: 0.9927 - categorical_accuracy: 0.9835 - val_loss: 75.8407 - val_auc_4: 0.7148 - val_categorical_accuracy: 0.4591\n","Epoch 252/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 1.5127 - auc_4: 0.9929 - categorical_accuracy: 0.9838 - val_loss: 75.8575 - val_auc_4: 0.7147 - val_categorical_accuracy: 0.4574\n","Epoch 253/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 1.5003 - auc_4: 0.9930 - categorical_accuracy: 0.9839 - val_loss: 75.9069 - val_auc_4: 0.7140 - val_categorical_accuracy: 0.4553\n","Epoch 254/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 1.4885 - auc_4: 0.9929 - categorical_accuracy: 0.9838 - val_loss: 75.9395 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 255/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 1.4787 - auc_4: 0.9929 - categorical_accuracy: 0.9840 - val_loss: 76.0103 - val_auc_4: 0.7125 - val_categorical_accuracy: 0.4545\n","Epoch 256/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 1.4666 - auc_4: 0.9929 - categorical_accuracy: 0.9842 - val_loss: 76.1422 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4520\n","Epoch 257/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 1.4531 - auc_4: 0.9931 - categorical_accuracy: 0.9844 - val_loss: 76.3240 - val_auc_4: 0.7126 - val_categorical_accuracy: 0.4532\n","Epoch 258/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 1.4401 - auc_4: 0.9932 - categorical_accuracy: 0.9837 - val_loss: 76.3966 - val_auc_4: 0.7128 - val_categorical_accuracy: 0.4536\n","Epoch 259/1000\n","3/3 [==============================] - 1s 323ms/step - loss: 1.4286 - auc_4: 0.9932 - categorical_accuracy: 0.9837 - val_loss: 76.4717 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4541\n","Epoch 260/1000\n","3/3 [==============================] - 1s 307ms/step - loss: 1.4174 - auc_4: 0.9932 - categorical_accuracy: 0.9840 - val_loss: 76.4708 - val_auc_4: 0.7135 - val_categorical_accuracy: 0.4553\n","Epoch 261/1000\n","3/3 [==============================] - 1s 320ms/step - loss: 1.4033 - auc_4: 0.9933 - categorical_accuracy: 0.9844 - val_loss: 76.2295 - val_auc_4: 0.7140 - val_categorical_accuracy: 0.4553\n","Epoch 262/1000\n","3/3 [==============================] - 1s 316ms/step - loss: 1.3926 - auc_4: 0.9932 - categorical_accuracy: 0.9841 - val_loss: 75.9584 - val_auc_4: 0.7141 - val_categorical_accuracy: 0.4553\n","Epoch 263/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 1.3848 - auc_4: 0.9932 - categorical_accuracy: 0.9835 - val_loss: 75.6730 - val_auc_4: 0.7144 - val_categorical_accuracy: 0.4566\n","Epoch 264/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 1.3736 - auc_4: 0.9932 - categorical_accuracy: 0.9839 - val_loss: 75.5279 - val_auc_4: 0.7148 - val_categorical_accuracy: 0.4591\n","Epoch 265/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 1.3603 - auc_4: 0.9935 - categorical_accuracy: 0.9848 - val_loss: 75.5841 - val_auc_4: 0.7147 - val_categorical_accuracy: 0.4591\n","Epoch 266/1000\n","3/3 [==============================] - 1s 180ms/step - loss: 1.3481 - auc_4: 0.9936 - categorical_accuracy: 0.9856 - val_loss: 75.7923 - val_auc_4: 0.7135 - val_categorical_accuracy: 0.4578\n","Epoch 267/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 1.3354 - auc_4: 0.9937 - categorical_accuracy: 0.9862 - val_loss: 75.8827 - val_auc_4: 0.7130 - val_categorical_accuracy: 0.4570\n","Epoch 268/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 1.3250 - auc_4: 0.9939 - categorical_accuracy: 0.9860 - val_loss: 75.9552 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4557\n","Epoch 269/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 1.3173 - auc_4: 0.9938 - categorical_accuracy: 0.9855 - val_loss: 75.9141 - val_auc_4: 0.7130 - val_categorical_accuracy: 0.4561\n","Epoch 270/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 1.3082 - auc_4: 0.9940 - categorical_accuracy: 0.9859 - val_loss: 75.7867 - val_auc_4: 0.7126 - val_categorical_accuracy: 0.4566\n","Epoch 271/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 1.2962 - auc_4: 0.9940 - categorical_accuracy: 0.9862 - val_loss: 75.6262 - val_auc_4: 0.7130 - val_categorical_accuracy: 0.4566\n","Epoch 272/1000\n","3/3 [==============================] - 1s 179ms/step - loss: 1.2838 - auc_4: 0.9941 - categorical_accuracy: 0.9866 - val_loss: 75.5460 - val_auc_4: 0.7135 - val_categorical_accuracy: 0.4570\n","Epoch 273/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 1.2709 - auc_4: 0.9941 - categorical_accuracy: 0.9867 - val_loss: 75.4152 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4561\n","Epoch 274/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 1.2584 - auc_4: 0.9941 - categorical_accuracy: 0.9862 - val_loss: 75.5051 - val_auc_4: 0.7137 - val_categorical_accuracy: 0.4557\n","Epoch 275/1000\n","3/3 [==============================] - 1s 189ms/step - loss: 1.2466 - auc_4: 0.9940 - categorical_accuracy: 0.9859 - val_loss: 75.8371 - val_auc_4: 0.7121 - val_categorical_accuracy: 0.4541\n","Epoch 276/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 1.2358 - auc_4: 0.9939 - categorical_accuracy: 0.9859 - val_loss: 76.1333 - val_auc_4: 0.7112 - val_categorical_accuracy: 0.4541\n","Epoch 277/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 1.2260 - auc_4: 0.9940 - categorical_accuracy: 0.9856 - val_loss: 76.3937 - val_auc_4: 0.7096 - val_categorical_accuracy: 0.4520\n","Epoch 278/1000\n","3/3 [==============================] - 1s 189ms/step - loss: 1.2153 - auc_4: 0.9940 - categorical_accuracy: 0.9858 - val_loss: 76.5731 - val_auc_4: 0.7090 - val_categorical_accuracy: 0.4507\n","Epoch 279/1000\n","3/3 [==============================] - 1s 309ms/step - loss: 1.2048 - auc_4: 0.9942 - categorical_accuracy: 0.9860 - val_loss: 76.4712 - val_auc_4: 0.7094 - val_categorical_accuracy: 0.4507\n","Epoch 280/1000\n","3/3 [==============================] - 1s 336ms/step - loss: 1.1947 - auc_4: 0.9942 - categorical_accuracy: 0.9863 - val_loss: 76.2109 - val_auc_4: 0.7101 - val_categorical_accuracy: 0.4524\n","Epoch 281/1000\n","3/3 [==============================] - 1s 328ms/step - loss: 1.1835 - auc_4: 0.9945 - categorical_accuracy: 0.9862 - val_loss: 76.0059 - val_auc_4: 0.7108 - val_categorical_accuracy: 0.4511\n","Epoch 282/1000\n","3/3 [==============================] - 1s 316ms/step - loss: 1.1734 - auc_4: 0.9946 - categorical_accuracy: 0.9860 - val_loss: 75.8283 - val_auc_4: 0.7108 - val_categorical_accuracy: 0.4520\n","Epoch 283/1000\n","3/3 [==============================] - 1s 256ms/step - loss: 1.1648 - auc_4: 0.9944 - categorical_accuracy: 0.9861 - val_loss: 75.6348 - val_auc_4: 0.7123 - val_categorical_accuracy: 0.4528\n","Epoch 284/1000\n","3/3 [==============================] - 1s 221ms/step - loss: 1.1561 - auc_4: 0.9944 - categorical_accuracy: 0.9859 - val_loss: 75.5411 - val_auc_4: 0.7130 - val_categorical_accuracy: 0.4532\n","Epoch 285/1000\n","3/3 [==============================] - 1s 240ms/step - loss: 1.1455 - auc_4: 0.9946 - categorical_accuracy: 0.9859 - val_loss: 75.5295 - val_auc_4: 0.7128 - val_categorical_accuracy: 0.4528\n","Epoch 286/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 1.1348 - auc_4: 0.9945 - categorical_accuracy: 0.9862 - val_loss: 75.5685 - val_auc_4: 0.7125 - val_categorical_accuracy: 0.4528\n","Epoch 287/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 1.1249 - auc_4: 0.9947 - categorical_accuracy: 0.9862 - val_loss: 75.6187 - val_auc_4: 0.7120 - val_categorical_accuracy: 0.4532\n","Epoch 288/1000\n","3/3 [==============================] - 1s 220ms/step - loss: 1.1134 - auc_4: 0.9947 - categorical_accuracy: 0.9867 - val_loss: 75.6836 - val_auc_4: 0.7115 - val_categorical_accuracy: 0.4528\n","Epoch 289/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 1.1022 - auc_4: 0.9947 - categorical_accuracy: 0.9874 - val_loss: 75.8225 - val_auc_4: 0.7113 - val_categorical_accuracy: 0.4520\n","Epoch 290/1000\n","3/3 [==============================] - 1s 220ms/step - loss: 1.0915 - auc_4: 0.9947 - categorical_accuracy: 0.9880 - val_loss: 75.8652 - val_auc_4: 0.7113 - val_categorical_accuracy: 0.4507\n","Epoch 291/1000\n","3/3 [==============================] - 1s 189ms/step - loss: 1.0818 - auc_4: 0.9947 - categorical_accuracy: 0.9880 - val_loss: 75.8308 - val_auc_4: 0.7115 - val_categorical_accuracy: 0.4503\n","Epoch 292/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 1.0728 - auc_4: 0.9947 - categorical_accuracy: 0.9877 - val_loss: 75.8534 - val_auc_4: 0.7117 - val_categorical_accuracy: 0.4507\n","Epoch 293/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 1.0656 - auc_4: 0.9949 - categorical_accuracy: 0.9874 - val_loss: 75.8611 - val_auc_4: 0.7117 - val_categorical_accuracy: 0.4503\n","Epoch 294/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 1.0560 - auc_4: 0.9950 - categorical_accuracy: 0.9870 - val_loss: 75.7898 - val_auc_4: 0.7119 - val_categorical_accuracy: 0.4515\n","Epoch 295/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 1.0444 - auc_4: 0.9952 - categorical_accuracy: 0.9870 - val_loss: 75.7027 - val_auc_4: 0.7122 - val_categorical_accuracy: 0.4541\n","Epoch 296/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 1.0351 - auc_4: 0.9949 - categorical_accuracy: 0.9870 - val_loss: 75.5788 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4561\n","Epoch 297/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 1.0303 - auc_4: 0.9949 - categorical_accuracy: 0.9867 - val_loss: 75.5455 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4566\n","Epoch 298/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 1.0212 - auc_4: 0.9949 - categorical_accuracy: 0.9869 - val_loss: 75.5587 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 299/1000\n","3/3 [==============================] - 1s 308ms/step - loss: 1.0086 - auc_4: 0.9953 - categorical_accuracy: 0.9879 - val_loss: 75.5771 - val_auc_4: 0.7119 - val_categorical_accuracy: 0.4536\n","Epoch 300/1000\n","3/3 [==============================] - 1s 320ms/step - loss: 0.9965 - auc_4: 0.9953 - categorical_accuracy: 0.9888 - val_loss: 75.5869 - val_auc_4: 0.7113 - val_categorical_accuracy: 0.4511\n","Epoch 301/1000\n","3/3 [==============================] - 1s 305ms/step - loss: 0.9859 - auc_4: 0.9954 - categorical_accuracy: 0.9894 - val_loss: 75.5727 - val_auc_4: 0.7111 - val_categorical_accuracy: 0.4495\n","Epoch 302/1000\n","3/3 [==============================] - 1s 328ms/step - loss: 0.9764 - auc_4: 0.9955 - categorical_accuracy: 0.9882 - val_loss: 75.5626 - val_auc_4: 0.7114 - val_categorical_accuracy: 0.4503\n","Epoch 303/1000\n","3/3 [==============================] - 1s 185ms/step - loss: 0.9675 - auc_4: 0.9955 - categorical_accuracy: 0.9877 - val_loss: 75.5867 - val_auc_4: 0.7114 - val_categorical_accuracy: 0.4495\n","Epoch 304/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 0.9583 - auc_4: 0.9955 - categorical_accuracy: 0.9875 - val_loss: 75.6036 - val_auc_4: 0.7116 - val_categorical_accuracy: 0.4495\n","Epoch 305/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 0.9509 - auc_4: 0.9954 - categorical_accuracy: 0.9874 - val_loss: 75.5901 - val_auc_4: 0.7116 - val_categorical_accuracy: 0.4490\n","Epoch 306/1000\n","3/3 [==============================] - 1s 185ms/step - loss: 0.9417 - auc_4: 0.9953 - categorical_accuracy: 0.9874 - val_loss: 75.6039 - val_auc_4: 0.7112 - val_categorical_accuracy: 0.4515\n","Epoch 307/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 0.9329 - auc_4: 0.9956 - categorical_accuracy: 0.9870 - val_loss: 75.6702 - val_auc_4: 0.7118 - val_categorical_accuracy: 0.4524\n","Epoch 308/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 0.9219 - auc_4: 0.9956 - categorical_accuracy: 0.9873 - val_loss: 75.6476 - val_auc_4: 0.7125 - val_categorical_accuracy: 0.4536\n","Epoch 309/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.9112 - auc_4: 0.9954 - categorical_accuracy: 0.9870 - val_loss: 75.6575 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4520\n","Epoch 310/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 0.9014 - auc_4: 0.9955 - categorical_accuracy: 0.9872 - val_loss: 75.5995 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4520\n","Epoch 311/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 0.8883 - auc_4: 0.9956 - categorical_accuracy: 0.9883 - val_loss: 75.4532 - val_auc_4: 0.7120 - val_categorical_accuracy: 0.4520\n","Epoch 312/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 0.8803 - auc_4: 0.9956 - categorical_accuracy: 0.9877 - val_loss: 75.4555 - val_auc_4: 0.7115 - val_categorical_accuracy: 0.4503\n","Epoch 313/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 0.8722 - auc_4: 0.9955 - categorical_accuracy: 0.9872 - val_loss: 75.4781 - val_auc_4: 0.7110 - val_categorical_accuracy: 0.4486\n","Epoch 314/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 0.8626 - auc_4: 0.9954 - categorical_accuracy: 0.9875 - val_loss: 75.5054 - val_auc_4: 0.7116 - val_categorical_accuracy: 0.4499\n","Epoch 315/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 0.8523 - auc_4: 0.9954 - categorical_accuracy: 0.9881 - val_loss: 75.4846 - val_auc_4: 0.7121 - val_categorical_accuracy: 0.4507\n","Epoch 316/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 0.8433 - auc_4: 0.9956 - categorical_accuracy: 0.9881 - val_loss: 75.3809 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4524\n","Epoch 317/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 0.8342 - auc_4: 0.9956 - categorical_accuracy: 0.9882 - val_loss: 75.1279 - val_auc_4: 0.7142 - val_categorical_accuracy: 0.4536\n","Epoch 318/1000\n","3/3 [==============================] - 1s 281ms/step - loss: 0.8214 - auc_4: 0.9957 - categorical_accuracy: 0.9886 - val_loss: 74.9203 - val_auc_4: 0.7153 - val_categorical_accuracy: 0.4566\n","Epoch 319/1000\n","3/3 [==============================] - 1s 320ms/step - loss: 0.8100 - auc_4: 0.9960 - categorical_accuracy: 0.9882 - val_loss: 74.6766 - val_auc_4: 0.7162 - val_categorical_accuracy: 0.4582\n","Epoch 320/1000\n","3/3 [==============================] - 1s 321ms/step - loss: 0.8016 - auc_4: 0.9960 - categorical_accuracy: 0.9884 - val_loss: 74.4795 - val_auc_4: 0.7163 - val_categorical_accuracy: 0.4616\n","Epoch 321/1000\n","3/3 [==============================] - 1s 322ms/step - loss: 0.7941 - auc_4: 0.9960 - categorical_accuracy: 0.9881 - val_loss: 74.4533 - val_auc_4: 0.7169 - val_categorical_accuracy: 0.4624\n","Epoch 322/1000\n","3/3 [==============================] - 1s 330ms/step - loss: 0.7859 - auc_4: 0.9959 - categorical_accuracy: 0.9887 - val_loss: 74.5974 - val_auc_4: 0.7163 - val_categorical_accuracy: 0.4620\n","Epoch 323/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 0.7749 - auc_4: 0.9961 - categorical_accuracy: 0.9894 - val_loss: 74.8563 - val_auc_4: 0.7146 - val_categorical_accuracy: 0.4595\n","Epoch 324/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 0.7670 - auc_4: 0.9961 - categorical_accuracy: 0.9896 - val_loss: 75.1438 - val_auc_4: 0.7145 - val_categorical_accuracy: 0.4578\n","Epoch 325/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 0.7606 - auc_4: 0.9962 - categorical_accuracy: 0.9898 - val_loss: 75.3627 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4557\n","Epoch 326/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 0.7539 - auc_4: 0.9963 - categorical_accuracy: 0.9894 - val_loss: 75.4730 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 327/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 0.7436 - auc_4: 0.9963 - categorical_accuracy: 0.9893 - val_loss: 75.5550 - val_auc_4: 0.7124 - val_categorical_accuracy: 0.4545\n","Epoch 328/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 0.7340 - auc_4: 0.9963 - categorical_accuracy: 0.9891 - val_loss: 75.5671 - val_auc_4: 0.7121 - val_categorical_accuracy: 0.4557\n","Epoch 329/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 0.7240 - auc_4: 0.9964 - categorical_accuracy: 0.9888 - val_loss: 75.4496 - val_auc_4: 0.7125 - val_categorical_accuracy: 0.4566\n","Epoch 330/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 0.7175 - auc_4: 0.9965 - categorical_accuracy: 0.9887 - val_loss: 75.2093 - val_auc_4: 0.7137 - val_categorical_accuracy: 0.4566\n","Epoch 331/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 0.7105 - auc_4: 0.9965 - categorical_accuracy: 0.9888 - val_loss: 74.9482 - val_auc_4: 0.7142 - val_categorical_accuracy: 0.4578\n","Epoch 332/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 0.7036 - auc_4: 0.9964 - categorical_accuracy: 0.9894 - val_loss: 74.7188 - val_auc_4: 0.7158 - val_categorical_accuracy: 0.4599\n","Epoch 333/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 0.6978 - auc_4: 0.9963 - categorical_accuracy: 0.9902 - val_loss: 74.6571 - val_auc_4: 0.7165 - val_categorical_accuracy: 0.4612\n","Epoch 334/1000\n","3/3 [==============================] - 1s 189ms/step - loss: 0.6892 - auc_4: 0.9964 - categorical_accuracy: 0.9909 - val_loss: 74.7897 - val_auc_4: 0.7167 - val_categorical_accuracy: 0.4616\n","Epoch 335/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 0.6802 - auc_4: 0.9964 - categorical_accuracy: 0.9905 - val_loss: 74.9474 - val_auc_4: 0.7158 - val_categorical_accuracy: 0.4591\n","Epoch 336/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 0.6716 - auc_4: 0.9965 - categorical_accuracy: 0.9907 - val_loss: 75.0732 - val_auc_4: 0.7147 - val_categorical_accuracy: 0.4566\n","Epoch 337/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 0.6627 - auc_4: 0.9966 - categorical_accuracy: 0.9911 - val_loss: 75.1623 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4574\n","Epoch 338/1000\n","3/3 [==============================] - 1s 327ms/step - loss: 0.6537 - auc_4: 0.9966 - categorical_accuracy: 0.9911 - val_loss: 75.2020 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4574\n","Epoch 339/1000\n","3/3 [==============================] - 1s 298ms/step - loss: 0.6446 - auc_4: 0.9966 - categorical_accuracy: 0.9909 - val_loss: 75.2255 - val_auc_4: 0.7141 - val_categorical_accuracy: 0.4595\n","Epoch 340/1000\n","3/3 [==============================] - 1s 293ms/step - loss: 0.6362 - auc_4: 0.9966 - categorical_accuracy: 0.9907 - val_loss: 75.1217 - val_auc_4: 0.7152 - val_categorical_accuracy: 0.4591\n","Epoch 341/1000\n","3/3 [==============================] - 1s 320ms/step - loss: 0.6285 - auc_4: 0.9966 - categorical_accuracy: 0.9902 - val_loss: 74.9599 - val_auc_4: 0.7162 - val_categorical_accuracy: 0.4591\n","Epoch 342/1000\n","3/3 [==============================] - 1s 286ms/step - loss: 0.6192 - auc_4: 0.9966 - categorical_accuracy: 0.9909 - val_loss: 74.8168 - val_auc_4: 0.7165 - val_categorical_accuracy: 0.4599\n","Epoch 343/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 0.6116 - auc_4: 0.9966 - categorical_accuracy: 0.9915 - val_loss: 74.7265 - val_auc_4: 0.7152 - val_categorical_accuracy: 0.4595\n","Epoch 344/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 0.6028 - auc_4: 0.9966 - categorical_accuracy: 0.9911 - val_loss: 74.7159 - val_auc_4: 0.7152 - val_categorical_accuracy: 0.4599\n","Epoch 345/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 0.5954 - auc_4: 0.9966 - categorical_accuracy: 0.9916 - val_loss: 74.7795 - val_auc_4: 0.7148 - val_categorical_accuracy: 0.4586\n","Epoch 346/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 0.5879 - auc_4: 0.9968 - categorical_accuracy: 0.9918 - val_loss: 74.7539 - val_auc_4: 0.7147 - val_categorical_accuracy: 0.4603\n","Epoch 347/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 0.5799 - auc_4: 0.9968 - categorical_accuracy: 0.9919 - val_loss: 74.6247 - val_auc_4: 0.7156 - val_categorical_accuracy: 0.4624\n","Epoch 348/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 0.5727 - auc_4: 0.9968 - categorical_accuracy: 0.9923 - val_loss: 74.4676 - val_auc_4: 0.7174 - val_categorical_accuracy: 0.4649\n","Epoch 349/1000\n","3/3 [==============================] - 1s 200ms/step - loss: 0.5665 - auc_4: 0.9968 - categorical_accuracy: 0.9916 - val_loss: 74.4040 - val_auc_4: 0.7169 - val_categorical_accuracy: 0.4637\n","Epoch 350/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.5590 - auc_4: 0.9968 - categorical_accuracy: 0.9915 - val_loss: 74.4934 - val_auc_4: 0.7169 - val_categorical_accuracy: 0.4612\n","Epoch 351/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 0.5506 - auc_4: 0.9969 - categorical_accuracy: 0.9916 - val_loss: 74.6547 - val_auc_4: 0.7168 - val_categorical_accuracy: 0.4603\n","Epoch 352/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 0.5427 - auc_4: 0.9970 - categorical_accuracy: 0.9925 - val_loss: 74.8309 - val_auc_4: 0.7161 - val_categorical_accuracy: 0.4586\n","Epoch 353/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.5355 - auc_4: 0.9969 - categorical_accuracy: 0.9921 - val_loss: 75.0144 - val_auc_4: 0.7151 - val_categorical_accuracy: 0.4570\n","Epoch 354/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 0.5276 - auc_4: 0.9970 - categorical_accuracy: 0.9915 - val_loss: 75.0498 - val_auc_4: 0.7147 - val_categorical_accuracy: 0.4557\n","Epoch 355/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 0.5205 - auc_4: 0.9970 - categorical_accuracy: 0.9912 - val_loss: 75.0075 - val_auc_4: 0.7151 - val_categorical_accuracy: 0.4553\n","Epoch 356/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 0.5136 - auc_4: 0.9971 - categorical_accuracy: 0.9910 - val_loss: 74.8408 - val_auc_4: 0.7165 - val_categorical_accuracy: 0.4570\n","Epoch 357/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.5079 - auc_4: 0.9970 - categorical_accuracy: 0.9908 - val_loss: 74.7314 - val_auc_4: 0.7168 - val_categorical_accuracy: 0.4578\n","Epoch 358/1000\n","3/3 [==============================] - 1s 337ms/step - loss: 0.5013 - auc_4: 0.9971 - categorical_accuracy: 0.9912 - val_loss: 74.7507 - val_auc_4: 0.7164 - val_categorical_accuracy: 0.4582\n","Epoch 359/1000\n","3/3 [==============================] - 1s 332ms/step - loss: 0.4936 - auc_4: 0.9971 - categorical_accuracy: 0.9922 - val_loss: 74.8781 - val_auc_4: 0.7160 - val_categorical_accuracy: 0.4574\n","Epoch 360/1000\n","3/3 [==============================] - 1s 315ms/step - loss: 0.4875 - auc_4: 0.9971 - categorical_accuracy: 0.9929 - val_loss: 74.9940 - val_auc_4: 0.7155 - val_categorical_accuracy: 0.4570\n","Epoch 361/1000\n","3/3 [==============================] - 1s 326ms/step - loss: 0.4813 - auc_4: 0.9971 - categorical_accuracy: 0.9929 - val_loss: 75.1149 - val_auc_4: 0.7149 - val_categorical_accuracy: 0.4561\n","Epoch 362/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 0.4743 - auc_4: 0.9972 - categorical_accuracy: 0.9925 - val_loss: 75.2723 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4536\n","Epoch 363/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 0.4650 - auc_4: 0.9971 - categorical_accuracy: 0.9921 - val_loss: 75.2837 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4553\n","Epoch 364/1000\n","3/3 [==============================] - 1s 184ms/step - loss: 0.4586 - auc_4: 0.9969 - categorical_accuracy: 0.9916 - val_loss: 75.2425 - val_auc_4: 0.7144 - val_categorical_accuracy: 0.4561\n","Epoch 365/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 0.4505 - auc_4: 0.9969 - categorical_accuracy: 0.9915 - val_loss: 75.1123 - val_auc_4: 0.7157 - val_categorical_accuracy: 0.4578\n","Epoch 366/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 0.4416 - auc_4: 0.9971 - categorical_accuracy: 0.9918 - val_loss: 75.0130 - val_auc_4: 0.7160 - val_categorical_accuracy: 0.4595\n","Epoch 367/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 0.4339 - auc_4: 0.9971 - categorical_accuracy: 0.9922 - val_loss: 74.9359 - val_auc_4: 0.7159 - val_categorical_accuracy: 0.4595\n","Epoch 368/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.4270 - auc_4: 0.9971 - categorical_accuracy: 0.9924 - val_loss: 74.9642 - val_auc_4: 0.7158 - val_categorical_accuracy: 0.4599\n","Epoch 369/1000\n","3/3 [==============================] - 1s 239ms/step - loss: 0.4210 - auc_4: 0.9972 - categorical_accuracy: 0.9925 - val_loss: 75.0300 - val_auc_4: 0.7152 - val_categorical_accuracy: 0.4595\n","Epoch 370/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 0.4141 - auc_4: 0.9972 - categorical_accuracy: 0.9926 - val_loss: 75.0234 - val_auc_4: 0.7154 - val_categorical_accuracy: 0.4582\n","Epoch 371/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 0.4062 - auc_4: 0.9972 - categorical_accuracy: 0.9935 - val_loss: 75.0021 - val_auc_4: 0.7163 - val_categorical_accuracy: 0.4591\n","Epoch 372/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 0.4003 - auc_4: 0.9972 - categorical_accuracy: 0.9930 - val_loss: 75.0758 - val_auc_4: 0.7158 - val_categorical_accuracy: 0.4570\n","Epoch 373/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 0.3934 - auc_4: 0.9972 - categorical_accuracy: 0.9926 - val_loss: 75.0607 - val_auc_4: 0.7161 - val_categorical_accuracy: 0.4570\n","Epoch 374/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.3867 - auc_4: 0.9972 - categorical_accuracy: 0.9923 - val_loss: 75.0928 - val_auc_4: 0.7161 - val_categorical_accuracy: 0.4574\n","Epoch 375/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 0.3817 - auc_4: 0.9972 - categorical_accuracy: 0.9923 - val_loss: 75.1858 - val_auc_4: 0.7161 - val_categorical_accuracy: 0.4570\n","Epoch 376/1000\n","3/3 [==============================] - 1s 238ms/step - loss: 0.3735 - auc_4: 0.9972 - categorical_accuracy: 0.9923 - val_loss: 75.2461 - val_auc_4: 0.7159 - val_categorical_accuracy: 0.4574\n","Epoch 377/1000\n","3/3 [==============================] - 1s 314ms/step - loss: 0.3632 - auc_4: 0.9973 - categorical_accuracy: 0.9929 - val_loss: 75.3380 - val_auc_4: 0.7152 - val_categorical_accuracy: 0.4566\n","Epoch 378/1000\n","3/3 [==============================] - 1s 351ms/step - loss: 0.3553 - auc_4: 0.9974 - categorical_accuracy: 0.9917 - val_loss: 75.4536 - val_auc_4: 0.7141 - val_categorical_accuracy: 0.4557\n","Epoch 379/1000\n","3/3 [==============================] - 1s 314ms/step - loss: 0.3506 - auc_4: 0.9975 - categorical_accuracy: 0.9909 - val_loss: 75.5579 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4549\n","Epoch 380/1000\n","3/3 [==============================] - 1s 313ms/step - loss: 0.3471 - auc_4: 0.9974 - categorical_accuracy: 0.9907 - val_loss: 75.6146 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4549\n","Epoch 381/1000\n","3/3 [==============================] - 1s 243ms/step - loss: 0.3393 - auc_4: 0.9975 - categorical_accuracy: 0.9917 - val_loss: 75.6358 - val_auc_4: 0.7137 - val_categorical_accuracy: 0.4553\n","Epoch 382/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 0.3317 - auc_4: 0.9975 - categorical_accuracy: 0.9925 - val_loss: 75.6358 - val_auc_4: 0.7137 - val_categorical_accuracy: 0.4557\n","Epoch 383/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.3226 - auc_4: 0.9975 - categorical_accuracy: 0.9935 - val_loss: 75.5632 - val_auc_4: 0.7142 - val_categorical_accuracy: 0.4561\n","Epoch 384/1000\n","3/3 [==============================] - 1s 201ms/step - loss: 0.3157 - auc_4: 0.9975 - categorical_accuracy: 0.9938 - val_loss: 75.4895 - val_auc_4: 0.7151 - val_categorical_accuracy: 0.4570\n","Epoch 385/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 0.3100 - auc_4: 0.9976 - categorical_accuracy: 0.9938 - val_loss: 75.4163 - val_auc_4: 0.7149 - val_categorical_accuracy: 0.4586\n","Epoch 386/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 0.3043 - auc_4: 0.9976 - categorical_accuracy: 0.9936 - val_loss: 75.3761 - val_auc_4: 0.7149 - val_categorical_accuracy: 0.4599\n","Epoch 387/1000\n","3/3 [==============================] - 1s 205ms/step - loss: 0.2997 - auc_4: 0.9975 - categorical_accuracy: 0.9933 - val_loss: 75.4462 - val_auc_4: 0.7149 - val_categorical_accuracy: 0.4599\n","Epoch 388/1000\n","3/3 [==============================] - 1s 183ms/step - loss: 0.2944 - auc_4: 0.9976 - categorical_accuracy: 0.9930 - val_loss: 75.5567 - val_auc_4: 0.7142 - val_categorical_accuracy: 0.4591\n","Epoch 389/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 0.2875 - auc_4: 0.9977 - categorical_accuracy: 0.9933 - val_loss: 75.6122 - val_auc_4: 0.7137 - val_categorical_accuracy: 0.4578\n","Epoch 390/1000\n","3/3 [==============================] - 1s 221ms/step - loss: 0.2821 - auc_4: 0.9977 - categorical_accuracy: 0.9930 - val_loss: 75.5268 - val_auc_4: 0.7137 - val_categorical_accuracy: 0.4578\n","Epoch 391/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 0.2761 - auc_4: 0.9978 - categorical_accuracy: 0.9924 - val_loss: 75.4109 - val_auc_4: 0.7141 - val_categorical_accuracy: 0.4591\n","Epoch 392/1000\n","3/3 [==============================] - 1s 238ms/step - loss: 0.2708 - auc_4: 0.9978 - categorical_accuracy: 0.9931 - val_loss: 75.4424 - val_auc_4: 0.7140 - val_categorical_accuracy: 0.4586\n","Epoch 393/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 0.2668 - auc_4: 0.9979 - categorical_accuracy: 0.9935 - val_loss: 75.4439 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4582\n","Epoch 394/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 0.2624 - auc_4: 0.9979 - categorical_accuracy: 0.9937 - val_loss: 75.3965 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4582\n","Epoch 395/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 0.2582 - auc_4: 0.9979 - categorical_accuracy: 0.9936 - val_loss: 75.3633 - val_auc_4: 0.7146 - val_categorical_accuracy: 0.4574\n","Epoch 396/1000\n","3/3 [==============================] - 1s 275ms/step - loss: 0.2533 - auc_4: 0.9979 - categorical_accuracy: 0.9940 - val_loss: 75.4173 - val_auc_4: 0.7146 - val_categorical_accuracy: 0.4578\n","Epoch 397/1000\n","3/3 [==============================] - 1s 299ms/step - loss: 0.2491 - auc_4: 0.9980 - categorical_accuracy: 0.9947 - val_loss: 75.5250 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4566\n","Epoch 398/1000\n","3/3 [==============================] - 1s 291ms/step - loss: 0.2465 - auc_4: 0.9979 - categorical_accuracy: 0.9946 - val_loss: 75.5798 - val_auc_4: 0.7128 - val_categorical_accuracy: 0.4557\n","Epoch 399/1000\n","3/3 [==============================] - 1s 324ms/step - loss: 0.2430 - auc_4: 0.9979 - categorical_accuracy: 0.9940 - val_loss: 75.5280 - val_auc_4: 0.7130 - val_categorical_accuracy: 0.4557\n","Epoch 400/1000\n","3/3 [==============================] - 1s 323ms/step - loss: 0.2400 - auc_4: 0.9979 - categorical_accuracy: 0.9942 - val_loss: 75.4724 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4561\n","Epoch 401/1000\n","3/3 [==============================] - 1s 203ms/step - loss: 0.2375 - auc_4: 0.9979 - categorical_accuracy: 0.9935 - val_loss: 75.3527 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4561\n","Epoch 402/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 0.2331 - auc_4: 0.9980 - categorical_accuracy: 0.9933 - val_loss: 75.1556 - val_auc_4: 0.7149 - val_categorical_accuracy: 0.4586\n","Epoch 403/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 0.2278 - auc_4: 0.9979 - categorical_accuracy: 0.9936 - val_loss: 74.9825 - val_auc_4: 0.7151 - val_categorical_accuracy: 0.4607\n","Epoch 404/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 0.2247 - auc_4: 0.9980 - categorical_accuracy: 0.9939 - val_loss: 74.9441 - val_auc_4: 0.7154 - val_categorical_accuracy: 0.4616\n","Epoch 405/1000\n","3/3 [==============================] - 1s 189ms/step - loss: 0.2210 - auc_4: 0.9980 - categorical_accuracy: 0.9942 - val_loss: 75.0316 - val_auc_4: 0.7151 - val_categorical_accuracy: 0.4595\n","Epoch 406/1000\n","3/3 [==============================] - 1s 195ms/step - loss: 0.2165 - auc_4: 0.9981 - categorical_accuracy: 0.9943 - val_loss: 75.1745 - val_auc_4: 0.7152 - val_categorical_accuracy: 0.4582\n","Epoch 407/1000\n","3/3 [==============================] - 1s 180ms/step - loss: 0.2115 - auc_4: 0.9981 - categorical_accuracy: 0.9945 - val_loss: 75.3271 - val_auc_4: 0.7150 - val_categorical_accuracy: 0.4566\n","Epoch 408/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.2080 - auc_4: 0.9980 - categorical_accuracy: 0.9951 - val_loss: 75.4698 - val_auc_4: 0.7141 - val_categorical_accuracy: 0.4553\n","Epoch 409/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 0.2066 - auc_4: 0.9980 - categorical_accuracy: 0.9947 - val_loss: 75.4957 - val_auc_4: 0.7141 - val_categorical_accuracy: 0.4536\n","Epoch 410/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 0.2033 - auc_4: 0.9980 - categorical_accuracy: 0.9950 - val_loss: 75.2932 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4545\n","Epoch 411/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 0.1992 - auc_4: 0.9980 - categorical_accuracy: 0.9949 - val_loss: 75.0777 - val_auc_4: 0.7146 - val_categorical_accuracy: 0.4566\n","Epoch 412/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 0.1962 - auc_4: 0.9981 - categorical_accuracy: 0.9953 - val_loss: 74.9357 - val_auc_4: 0.7151 - val_categorical_accuracy: 0.4591\n","Epoch 413/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 0.1932 - auc_4: 0.9981 - categorical_accuracy: 0.9954 - val_loss: 74.8661 - val_auc_4: 0.7152 - val_categorical_accuracy: 0.4612\n","Epoch 414/1000\n","3/3 [==============================] - 1s 239ms/step - loss: 0.1901 - auc_4: 0.9981 - categorical_accuracy: 0.9953 - val_loss: 74.8767 - val_auc_4: 0.7163 - val_categorical_accuracy: 0.4616\n","Epoch 415/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 0.1872 - auc_4: 0.9982 - categorical_accuracy: 0.9952 - val_loss: 74.8905 - val_auc_4: 0.7163 - val_categorical_accuracy: 0.4612\n","Epoch 416/1000\n","3/3 [==============================] - 1s 300ms/step - loss: 0.1847 - auc_4: 0.9982 - categorical_accuracy: 0.9951 - val_loss: 74.9237 - val_auc_4: 0.7166 - val_categorical_accuracy: 0.4612\n","Epoch 417/1000\n","3/3 [==============================] - 1s 324ms/step - loss: 0.1822 - auc_4: 0.9983 - categorical_accuracy: 0.9953 - val_loss: 75.0167 - val_auc_4: 0.7164 - val_categorical_accuracy: 0.4599\n","Epoch 418/1000\n","3/3 [==============================] - 1s 335ms/step - loss: 0.1791 - auc_4: 0.9984 - categorical_accuracy: 0.9947 - val_loss: 75.1422 - val_auc_4: 0.7163 - val_categorical_accuracy: 0.4591\n","Epoch 419/1000\n","3/3 [==============================] - 1s 330ms/step - loss: 0.1761 - auc_4: 0.9984 - categorical_accuracy: 0.9943 - val_loss: 75.2753 - val_auc_4: 0.7150 - val_categorical_accuracy: 0.4578\n","Epoch 420/1000\n","3/3 [==============================] - 1s 290ms/step - loss: 0.1728 - auc_4: 0.9984 - categorical_accuracy: 0.9943 - val_loss: 75.3502 - val_auc_4: 0.7141 - val_categorical_accuracy: 0.4570\n","Epoch 421/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 0.1685 - auc_4: 0.9982 - categorical_accuracy: 0.9947 - val_loss: 75.3917 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 422/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 0.1647 - auc_4: 0.9983 - categorical_accuracy: 0.9953 - val_loss: 75.5447 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4528\n","Epoch 423/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 0.1610 - auc_4: 0.9982 - categorical_accuracy: 0.9952 - val_loss: 75.7483 - val_auc_4: 0.7121 - val_categorical_accuracy: 0.4520\n","Epoch 424/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 0.1589 - auc_4: 0.9982 - categorical_accuracy: 0.9949 - val_loss: 75.8520 - val_auc_4: 0.7121 - val_categorical_accuracy: 0.4511\n","Epoch 425/1000\n","3/3 [==============================] - 1s 240ms/step - loss: 0.1557 - auc_4: 0.9983 - categorical_accuracy: 0.9949 - val_loss: 75.8358 - val_auc_4: 0.7121 - val_categorical_accuracy: 0.4528\n","Epoch 426/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 0.1523 - auc_4: 0.9983 - categorical_accuracy: 0.9949 - val_loss: 75.7657 - val_auc_4: 0.7126 - val_categorical_accuracy: 0.4541\n","Epoch 427/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 0.1491 - auc_4: 0.9983 - categorical_accuracy: 0.9954 - val_loss: 75.6630 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 428/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 0.1464 - auc_4: 0.9984 - categorical_accuracy: 0.9957 - val_loss: 75.5873 - val_auc_4: 0.7130 - val_categorical_accuracy: 0.4553\n","Epoch 429/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 0.1436 - auc_4: 0.9984 - categorical_accuracy: 0.9960 - val_loss: 75.5378 - val_auc_4: 0.7126 - val_categorical_accuracy: 0.4561\n","Epoch 430/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 0.1405 - auc_4: 0.9984 - categorical_accuracy: 0.9960 - val_loss: 75.5045 - val_auc_4: 0.7128 - val_categorical_accuracy: 0.4574\n","Epoch 431/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 0.1384 - auc_4: 0.9984 - categorical_accuracy: 0.9958 - val_loss: 75.4839 - val_auc_4: 0.7130 - val_categorical_accuracy: 0.4570\n","Epoch 432/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 0.1371 - auc_4: 0.9983 - categorical_accuracy: 0.9950 - val_loss: 75.5323 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4561\n","Epoch 433/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.1348 - auc_4: 0.9983 - categorical_accuracy: 0.9947 - val_loss: 75.5667 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 434/1000\n","3/3 [==============================] - 1s 223ms/step - loss: 0.1319 - auc_4: 0.9984 - categorical_accuracy: 0.9950 - val_loss: 75.5024 - val_auc_4: 0.7126 - val_categorical_accuracy: 0.4545\n","Epoch 435/1000\n","3/3 [==============================] - 1s 291ms/step - loss: 0.1286 - auc_4: 0.9984 - categorical_accuracy: 0.9953 - val_loss: 75.5111 - val_auc_4: 0.7119 - val_categorical_accuracy: 0.4536\n","Epoch 436/1000\n","3/3 [==============================] - 1s 313ms/step - loss: 0.1260 - auc_4: 0.9984 - categorical_accuracy: 0.9960 - val_loss: 75.5124 - val_auc_4: 0.7119 - val_categorical_accuracy: 0.4528\n","Epoch 437/1000\n","3/3 [==============================] - 1s 301ms/step - loss: 0.1242 - auc_4: 0.9985 - categorical_accuracy: 0.9958 - val_loss: 75.4416 - val_auc_4: 0.7122 - val_categorical_accuracy: 0.4532\n","Epoch 438/1000\n","3/3 [==============================] - 1s 334ms/step - loss: 0.1224 - auc_4: 0.9985 - categorical_accuracy: 0.9954 - val_loss: 75.3712 - val_auc_4: 0.7114 - val_categorical_accuracy: 0.4532\n","Epoch 439/1000\n","3/3 [==============================] - 1s 334ms/step - loss: 0.1200 - auc_4: 0.9985 - categorical_accuracy: 0.9958 - val_loss: 75.2548 - val_auc_4: 0.7119 - val_categorical_accuracy: 0.4541\n","Epoch 440/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 0.1184 - auc_4: 0.9984 - categorical_accuracy: 0.9958 - val_loss: 75.1898 - val_auc_4: 0.7123 - val_categorical_accuracy: 0.4541\n","Epoch 441/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 0.1152 - auc_4: 0.9985 - categorical_accuracy: 0.9953 - val_loss: 75.1529 - val_auc_4: 0.7128 - val_categorical_accuracy: 0.4541\n","Epoch 442/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 0.1116 - auc_4: 0.9985 - categorical_accuracy: 0.9958 - val_loss: 75.2259 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4553\n","Epoch 443/1000\n","3/3 [==============================] - 1s 189ms/step - loss: 0.1083 - auc_4: 0.9985 - categorical_accuracy: 0.9960 - val_loss: 75.3198 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4545\n","Epoch 444/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 0.1055 - auc_4: 0.9985 - categorical_accuracy: 0.9963 - val_loss: 75.3671 - val_auc_4: 0.7130 - val_categorical_accuracy: 0.4553\n","Epoch 445/1000\n","3/3 [==============================] - 1s 240ms/step - loss: 0.1033 - auc_4: 0.9985 - categorical_accuracy: 0.9963 - val_loss: 75.4123 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 446/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 0.1018 - auc_4: 0.9985 - categorical_accuracy: 0.9961 - val_loss: 75.4368 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4541\n","Epoch 447/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 0.0989 - auc_4: 0.9987 - categorical_accuracy: 0.9961 - val_loss: 75.4062 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4532\n","Epoch 448/1000\n","3/3 [==============================] - 1s 185ms/step - loss: 0.0967 - auc_4: 0.9986 - categorical_accuracy: 0.9964 - val_loss: 75.2708 - val_auc_4: 0.7124 - val_categorical_accuracy: 0.4515\n","Epoch 449/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 0.0946 - auc_4: 0.9987 - categorical_accuracy: 0.9965 - val_loss: 75.1059 - val_auc_4: 0.7130 - val_categorical_accuracy: 0.4545\n","Epoch 450/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 0.0928 - auc_4: 0.9987 - categorical_accuracy: 0.9968 - val_loss: 75.0446 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4557\n","Epoch 451/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 0.0904 - auc_4: 0.9987 - categorical_accuracy: 0.9966 - val_loss: 74.9888 - val_auc_4: 0.7141 - val_categorical_accuracy: 0.4561\n","Epoch 452/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.0887 - auc_4: 0.9988 - categorical_accuracy: 0.9964 - val_loss: 74.9159 - val_auc_4: 0.7147 - val_categorical_accuracy: 0.4574\n","Epoch 453/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 0.0870 - auc_4: 0.9988 - categorical_accuracy: 0.9965 - val_loss: 74.9141 - val_auc_4: 0.7144 - val_categorical_accuracy: 0.4574\n","Epoch 454/1000\n","3/3 [==============================] - 1s 201ms/step - loss: 0.0853 - auc_4: 0.9988 - categorical_accuracy: 0.9965 - val_loss: 74.9790 - val_auc_4: 0.7145 - val_categorical_accuracy: 0.4578\n","Epoch 455/1000\n","3/3 [==============================] - 1s 339ms/step - loss: 0.0830 - auc_4: 0.9988 - categorical_accuracy: 0.9967 - val_loss: 75.0936 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4566\n","Epoch 456/1000\n","3/3 [==============================] - 1s 286ms/step - loss: 0.0803 - auc_4: 0.9988 - categorical_accuracy: 0.9968 - val_loss: 75.2284 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4557\n","Epoch 457/1000\n","3/3 [==============================] - 1s 318ms/step - loss: 0.0776 - auc_4: 0.9989 - categorical_accuracy: 0.9967 - val_loss: 75.2959 - val_auc_4: 0.7128 - val_categorical_accuracy: 0.4553\n","Epoch 458/1000\n","3/3 [==============================] - 1s 316ms/step - loss: 0.0754 - auc_4: 0.9989 - categorical_accuracy: 0.9972 - val_loss: 75.2453 - val_auc_4: 0.7124 - val_categorical_accuracy: 0.4561\n","Epoch 459/1000\n","3/3 [==============================] - 1s 287ms/step - loss: 0.0737 - auc_4: 0.9989 - categorical_accuracy: 0.9973 - val_loss: 75.2585 - val_auc_4: 0.7121 - val_categorical_accuracy: 0.4553\n","Epoch 460/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 0.0719 - auc_4: 0.9989 - categorical_accuracy: 0.9968 - val_loss: 75.2931 - val_auc_4: 0.7124 - val_categorical_accuracy: 0.4549\n","Epoch 461/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 0.0699 - auc_4: 0.9989 - categorical_accuracy: 0.9972 - val_loss: 75.2888 - val_auc_4: 0.7119 - val_categorical_accuracy: 0.4545\n","Epoch 462/1000\n","3/3 [==============================] - 1s 200ms/step - loss: 0.0678 - auc_4: 0.9989 - categorical_accuracy: 0.9972 - val_loss: 75.3212 - val_auc_4: 0.7119 - val_categorical_accuracy: 0.4528\n","Epoch 463/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 0.0657 - auc_4: 0.9989 - categorical_accuracy: 0.9972 - val_loss: 75.3792 - val_auc_4: 0.7115 - val_categorical_accuracy: 0.4524\n","Epoch 464/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 0.0639 - auc_4: 0.9990 - categorical_accuracy: 0.9973 - val_loss: 75.4524 - val_auc_4: 0.7112 - val_categorical_accuracy: 0.4515\n","Epoch 465/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 0.0617 - auc_4: 0.9990 - categorical_accuracy: 0.9972 - val_loss: 75.5394 - val_auc_4: 0.7114 - val_categorical_accuracy: 0.4507\n","Epoch 466/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 0.0602 - auc_4: 0.9990 - categorical_accuracy: 0.9970 - val_loss: 75.5608 - val_auc_4: 0.7112 - val_categorical_accuracy: 0.4511\n","Epoch 467/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 0.0581 - auc_4: 0.9990 - categorical_accuracy: 0.9973 - val_loss: 75.5210 - val_auc_4: 0.7117 - val_categorical_accuracy: 0.4520\n","Epoch 468/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 0.0574 - auc_4: 0.9990 - categorical_accuracy: 0.9973 - val_loss: 75.4928 - val_auc_4: 0.7113 - val_categorical_accuracy: 0.4511\n","Epoch 469/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 0.0559 - auc_4: 0.9990 - categorical_accuracy: 0.9977 - val_loss: 75.4882 - val_auc_4: 0.7113 - val_categorical_accuracy: 0.4524\n","Epoch 470/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 0.0551 - auc_4: 0.9990 - categorical_accuracy: 0.9972 - val_loss: 75.4189 - val_auc_4: 0.7117 - val_categorical_accuracy: 0.4520\n","Epoch 471/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.0542 - auc_4: 0.9990 - categorical_accuracy: 0.9970 - val_loss: 75.3882 - val_auc_4: 0.7115 - val_categorical_accuracy: 0.4520\n","Epoch 472/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 0.0524 - auc_4: 0.9992 - categorical_accuracy: 0.9973 - val_loss: 75.4375 - val_auc_4: 0.7115 - val_categorical_accuracy: 0.4528\n","Epoch 473/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 0.0501 - auc_4: 0.9992 - categorical_accuracy: 0.9975 - val_loss: 75.6072 - val_auc_4: 0.7104 - val_categorical_accuracy: 0.4515\n","Epoch 474/1000\n","3/3 [==============================] - 1s 301ms/step - loss: 0.0479 - auc_4: 0.9992 - categorical_accuracy: 0.9975 - val_loss: 75.7479 - val_auc_4: 0.7097 - val_categorical_accuracy: 0.4503\n","Epoch 475/1000\n","3/3 [==============================] - 1s 311ms/step - loss: 0.0471 - auc_4: 0.9992 - categorical_accuracy: 0.9973 - val_loss: 75.8469 - val_auc_4: 0.7089 - val_categorical_accuracy: 0.4507\n","Epoch 476/1000\n","3/3 [==============================] - 1s 312ms/step - loss: 0.0464 - auc_4: 0.9992 - categorical_accuracy: 0.9970 - val_loss: 75.8624 - val_auc_4: 0.7089 - val_categorical_accuracy: 0.4490\n","Epoch 477/1000\n","3/3 [==============================] - 1s 333ms/step - loss: 0.0455 - auc_4: 0.9992 - categorical_accuracy: 0.9966 - val_loss: 75.6818 - val_auc_4: 0.7105 - val_categorical_accuracy: 0.4490\n","Epoch 478/1000\n","3/3 [==============================] - 1s 323ms/step - loss: 0.0437 - auc_4: 0.9992 - categorical_accuracy: 0.9971 - val_loss: 75.3239 - val_auc_4: 0.7126 - val_categorical_accuracy: 0.4545\n","Epoch 479/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.0433 - auc_4: 0.9992 - categorical_accuracy: 0.9971 - val_loss: 75.0676 - val_auc_4: 0.7143 - val_categorical_accuracy: 0.4578\n","Epoch 480/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 0.0418 - auc_4: 0.9992 - categorical_accuracy: 0.9971 - val_loss: 74.9638 - val_auc_4: 0.7148 - val_categorical_accuracy: 0.4591\n","Epoch 481/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 0.0396 - auc_4: 0.9992 - categorical_accuracy: 0.9970 - val_loss: 74.9167 - val_auc_4: 0.7152 - val_categorical_accuracy: 0.4591\n","Epoch 482/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 0.0383 - auc_4: 0.9992 - categorical_accuracy: 0.9967 - val_loss: 74.9238 - val_auc_4: 0.7146 - val_categorical_accuracy: 0.4586\n","Epoch 483/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.0370 - auc_4: 0.9993 - categorical_accuracy: 0.9966 - val_loss: 74.9338 - val_auc_4: 0.7146 - val_categorical_accuracy: 0.4586\n","Epoch 484/1000\n","3/3 [==============================] - 1s 287ms/step - loss: 0.0345 - auc_4: 0.9993 - categorical_accuracy: 0.9973 - val_loss: 74.9108 - val_auc_4: 0.7144 - val_categorical_accuracy: 0.4582\n","Epoch 485/1000\n","3/3 [==============================] - 1s 325ms/step - loss: 0.0325 - auc_4: 0.9993 - categorical_accuracy: 0.9979 - val_loss: 74.8807 - val_auc_4: 0.7156 - val_categorical_accuracy: 0.4582\n","Epoch 486/1000\n","3/3 [==============================] - 1s 338ms/step - loss: 0.0321 - auc_4: 0.9993 - categorical_accuracy: 0.9979 - val_loss: 74.9333 - val_auc_4: 0.7154 - val_categorical_accuracy: 0.4574\n","Epoch 487/1000\n","3/3 [==============================] - 1s 313ms/step - loss: 0.0313 - auc_4: 0.9993 - categorical_accuracy: 0.9978 - val_loss: 75.0600 - val_auc_4: 0.7145 - val_categorical_accuracy: 0.4561\n","Epoch 488/1000\n","3/3 [==============================] - 1s 326ms/step - loss: 0.0296 - auc_4: 0.9994 - categorical_accuracy: 0.9982 - val_loss: 75.2517 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4536\n","Epoch 489/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 0.0287 - auc_4: 0.9994 - categorical_accuracy: 0.9984 - val_loss: 75.3942 - val_auc_4: 0.7119 - val_categorical_accuracy: 0.4524\n","Epoch 490/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 0.0282 - auc_4: 0.9995 - categorical_accuracy: 0.9984 - val_loss: 75.4835 - val_auc_4: 0.7116 - val_categorical_accuracy: 0.4515\n","Epoch 491/1000\n","3/3 [==============================] - 1s 261ms/step - loss: 0.0277 - auc_4: 0.9995 - categorical_accuracy: 0.9985 - val_loss: 75.5607 - val_auc_4: 0.7112 - val_categorical_accuracy: 0.4511\n","Epoch 492/1000\n","3/3 [==============================] - 1s 328ms/step - loss: 0.0266 - auc_4: 0.9995 - categorical_accuracy: 0.9985 - val_loss: 75.5667 - val_auc_4: 0.7111 - val_categorical_accuracy: 0.4511\n","Epoch 493/1000\n","3/3 [==============================] - 1s 326ms/step - loss: 0.0251 - auc_4: 0.9995 - categorical_accuracy: 0.9986 - val_loss: 75.5673 - val_auc_4: 0.7114 - val_categorical_accuracy: 0.4511\n","Epoch 494/1000\n","3/3 [==============================] - 1s 322ms/step - loss: 0.0242 - auc_4: 0.9995 - categorical_accuracy: 0.9987 - val_loss: 75.5655 - val_auc_4: 0.7112 - val_categorical_accuracy: 0.4511\n","Epoch 495/1000\n","3/3 [==============================] - 1s 328ms/step - loss: 0.0235 - auc_4: 0.9995 - categorical_accuracy: 0.9988 - val_loss: 75.5492 - val_auc_4: 0.7110 - val_categorical_accuracy: 0.4507\n","Epoch 496/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 0.0226 - auc_4: 0.9996 - categorical_accuracy: 0.9988 - val_loss: 75.5306 - val_auc_4: 0.7112 - val_categorical_accuracy: 0.4507\n","Epoch 497/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 0.0220 - auc_4: 0.9996 - categorical_accuracy: 0.9989 - val_loss: 75.5175 - val_auc_4: 0.7114 - val_categorical_accuracy: 0.4515\n","Epoch 498/1000\n","3/3 [==============================] - 1s 199ms/step - loss: 0.0213 - auc_4: 0.9996 - categorical_accuracy: 0.9989 - val_loss: 75.5066 - val_auc_4: 0.7118 - val_categorical_accuracy: 0.4524\n","Epoch 499/1000\n","3/3 [==============================] - 1s 307ms/step - loss: 0.0207 - auc_4: 0.9996 - categorical_accuracy: 0.9991 - val_loss: 75.5019 - val_auc_4: 0.7123 - val_categorical_accuracy: 0.4524\n","Epoch 500/1000\n","3/3 [==============================] - 1s 296ms/step - loss: 0.0201 - auc_4: 0.9996 - categorical_accuracy: 0.9989 - val_loss: 75.4985 - val_auc_4: 0.7123 - val_categorical_accuracy: 0.4524\n","Epoch 501/1000\n","3/3 [==============================] - 1s 313ms/step - loss: 0.0195 - auc_4: 0.9996 - categorical_accuracy: 0.9989 - val_loss: 75.4965 - val_auc_4: 0.7121 - val_categorical_accuracy: 0.4524\n","Epoch 502/1000\n","3/3 [==============================] - 1s 317ms/step - loss: 0.0189 - auc_4: 0.9996 - categorical_accuracy: 0.9988 - val_loss: 75.4951 - val_auc_4: 0.7116 - val_categorical_accuracy: 0.4524\n","Epoch 503/1000\n","3/3 [==============================] - 1s 328ms/step - loss: 0.0184 - auc_4: 0.9996 - categorical_accuracy: 0.9991 - val_loss: 75.5006 - val_auc_4: 0.7121 - val_categorical_accuracy: 0.4528\n","Epoch 504/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 0.0180 - auc_4: 0.9996 - categorical_accuracy: 0.9991 - val_loss: 75.5063 - val_auc_4: 0.7121 - val_categorical_accuracy: 0.4528\n","Epoch 505/1000\n","3/3 [==============================] - 1s 238ms/step - loss: 0.0175 - auc_4: 0.9996 - categorical_accuracy: 0.9991 - val_loss: 75.5122 - val_auc_4: 0.7121 - val_categorical_accuracy: 0.4524\n","Epoch 506/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 0.0170 - auc_4: 0.9996 - categorical_accuracy: 0.9991 - val_loss: 75.5025 - val_auc_4: 0.7123 - val_categorical_accuracy: 0.4528\n","Epoch 507/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 0.0164 - auc_4: 0.9996 - categorical_accuracy: 0.9992 - val_loss: 75.4570 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4532\n","Epoch 508/1000\n","3/3 [==============================] - 1s 273ms/step - loss: 0.0157 - auc_4: 0.9998 - categorical_accuracy: 0.9992 - val_loss: 75.4261 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4536\n","Epoch 509/1000\n","3/3 [==============================] - 1s 327ms/step - loss: 0.0153 - auc_4: 0.9998 - categorical_accuracy: 0.9992 - val_loss: 75.4052 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4553\n","Epoch 510/1000\n","3/3 [==============================] - 1s 292ms/step - loss: 0.0149 - auc_4: 0.9998 - categorical_accuracy: 0.9992 - val_loss: 75.3967 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 511/1000\n","3/3 [==============================] - 1s 313ms/step - loss: 0.0144 - auc_4: 0.9998 - categorical_accuracy: 0.9994 - val_loss: 75.4062 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 512/1000\n","3/3 [==============================] - 1s 342ms/step - loss: 0.0137 - auc_4: 0.9998 - categorical_accuracy: 0.9995 - val_loss: 75.3572 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4549\n","Epoch 513/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 0.0134 - auc_4: 0.9998 - categorical_accuracy: 0.9995 - val_loss: 75.2173 - val_auc_4: 0.7144 - val_categorical_accuracy: 0.4557\n","Epoch 514/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 0.0130 - auc_4: 0.9998 - categorical_accuracy: 0.9993 - val_loss: 75.1134 - val_auc_4: 0.7149 - val_categorical_accuracy: 0.4561\n","Epoch 515/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 0.0128 - auc_4: 0.9998 - categorical_accuracy: 0.9994 - val_loss: 75.0413 - val_auc_4: 0.7151 - val_categorical_accuracy: 0.4566\n","Epoch 516/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 0.0125 - auc_4: 0.9998 - categorical_accuracy: 0.9994 - val_loss: 74.9958 - val_auc_4: 0.7154 - val_categorical_accuracy: 0.4570\n","Epoch 517/1000\n","3/3 [==============================] - 1s 202ms/step - loss: 0.0122 - auc_4: 0.9998 - categorical_accuracy: 0.9994 - val_loss: 74.9614 - val_auc_4: 0.7156 - val_categorical_accuracy: 0.4570\n","Epoch 518/1000\n","3/3 [==============================] - 1s 195ms/step - loss: 0.0120 - auc_4: 0.9998 - categorical_accuracy: 0.9995 - val_loss: 74.9508 - val_auc_4: 0.7154 - val_categorical_accuracy: 0.4570\n","Epoch 519/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 0.0118 - auc_4: 0.9998 - categorical_accuracy: 0.9994 - val_loss: 74.9668 - val_auc_4: 0.7154 - val_categorical_accuracy: 0.4570\n","Epoch 520/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 0.0115 - auc_4: 0.9998 - categorical_accuracy: 0.9994 - val_loss: 75.0134 - val_auc_4: 0.7151 - val_categorical_accuracy: 0.4566\n","Epoch 521/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 0.0112 - auc_4: 0.9998 - categorical_accuracy: 0.9995 - val_loss: 75.0933 - val_auc_4: 0.7151 - val_categorical_accuracy: 0.4561\n","Epoch 522/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 0.0106 - auc_4: 0.9998 - categorical_accuracy: 0.9995 - val_loss: 75.2149 - val_auc_4: 0.7146 - val_categorical_accuracy: 0.4549\n","Epoch 523/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 0.0106 - auc_4: 0.9998 - categorical_accuracy: 0.9993 - val_loss: 75.4204 - val_auc_4: 0.7135 - val_categorical_accuracy: 0.4532\n","Epoch 524/1000\n","3/3 [==============================] - 1s 185ms/step - loss: 0.0103 - auc_4: 0.9998 - categorical_accuracy: 0.9991 - val_loss: 75.5383 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4541\n","Epoch 525/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 0.0100 - auc_4: 0.9998 - categorical_accuracy: 0.9993 - val_loss: 75.5730 - val_auc_4: 0.7123 - val_categorical_accuracy: 0.4532\n","Epoch 526/1000\n","3/3 [==============================] - 1s 200ms/step - loss: 0.0095 - auc_4: 0.9998 - categorical_accuracy: 0.9992 - val_loss: 75.5402 - val_auc_4: 0.7123 - val_categorical_accuracy: 0.4532\n","Epoch 527/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 0.0091 - auc_4: 0.9998 - categorical_accuracy: 0.9991 - val_loss: 75.4654 - val_auc_4: 0.7125 - val_categorical_accuracy: 0.4536\n","Epoch 528/1000\n","3/3 [==============================] - 1s 294ms/step - loss: 0.0087 - auc_4: 0.9998 - categorical_accuracy: 0.9993 - val_loss: 75.3671 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4536\n","Epoch 529/1000\n","3/3 [==============================] - 1s 332ms/step - loss: 0.0084 - auc_4: 0.9998 - categorical_accuracy: 0.9992 - val_loss: 75.3095 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4541\n","Epoch 530/1000\n","3/3 [==============================] - 1s 322ms/step - loss: 0.0080 - auc_4: 0.9998 - categorical_accuracy: 0.9993 - val_loss: 75.2861 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4536\n","Epoch 531/1000\n","3/3 [==============================] - 1s 298ms/step - loss: 0.0079 - auc_4: 0.9998 - categorical_accuracy: 0.9993 - val_loss: 75.3079 - val_auc_4: 0.7137 - val_categorical_accuracy: 0.4536\n","Epoch 532/1000\n","3/3 [==============================] - 1s 317ms/step - loss: 0.0077 - auc_4: 0.9998 - categorical_accuracy: 0.9993 - val_loss: 75.3943 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4536\n","Epoch 533/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 0.0073 - auc_4: 0.9998 - categorical_accuracy: 0.9991 - val_loss: 75.4431 - val_auc_4: 0.7124 - val_categorical_accuracy: 0.4541\n","Epoch 534/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 0.0067 - auc_4: 0.9998 - categorical_accuracy: 0.9993 - val_loss: 75.4628 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4532\n","Epoch 535/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 0.0060 - auc_4: 0.9998 - categorical_accuracy: 0.9993 - val_loss: 75.4530 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4536\n","Epoch 536/1000\n","3/3 [==============================] - 1s 199ms/step - loss: 0.0057 - auc_4: 0.9998 - categorical_accuracy: 0.9995 - val_loss: 75.4185 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4532\n","Epoch 537/1000\n","3/3 [==============================] - 1s 198ms/step - loss: 0.0058 - auc_4: 0.9998 - categorical_accuracy: 0.9993 - val_loss: 75.3760 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4541\n","Epoch 538/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 0.0055 - auc_4: 0.9998 - categorical_accuracy: 0.9995 - val_loss: 75.3327 - val_auc_4: 0.7140 - val_categorical_accuracy: 0.4541\n","Epoch 539/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 0.0051 - auc_4: 0.9998 - categorical_accuracy: 0.9996 - val_loss: 75.3335 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4536\n","Epoch 540/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 0.0047 - auc_4: 0.9998 - categorical_accuracy: 0.9996 - val_loss: 75.3968 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4528\n","Epoch 541/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 0.0044 - auc_4: 0.9998 - categorical_accuracy: 0.9996 - val_loss: 75.4417 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4532\n","Epoch 542/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 0.0043 - auc_4: 0.9999 - categorical_accuracy: 0.9995 - val_loss: 75.4459 - val_auc_4: 0.7135 - val_categorical_accuracy: 0.4532\n","Epoch 543/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 0.0039 - auc_4: 0.9999 - categorical_accuracy: 0.9995 - val_loss: 75.4189 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4532\n","Epoch 544/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 0.0038 - auc_4: 0.9999 - categorical_accuracy: 0.9994 - val_loss: 75.4158 - val_auc_4: 0.7143 - val_categorical_accuracy: 0.4532\n","Epoch 545/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 0.0034 - auc_4: 0.9999 - categorical_accuracy: 0.9992 - val_loss: 75.4342 - val_auc_4: 0.7141 - val_categorical_accuracy: 0.4520\n","Epoch 546/1000\n","3/3 [==============================] - 1s 241ms/step - loss: 0.0035 - auc_4: 0.9999 - categorical_accuracy: 0.9988 - val_loss: 75.4527 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4520\n","Epoch 547/1000\n","3/3 [==============================] - 1s 199ms/step - loss: 0.0033 - auc_4: 0.9999 - categorical_accuracy: 0.9989 - val_loss: 75.4632 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4515\n","Epoch 548/1000\n","3/3 [==============================] - 1s 329ms/step - loss: 0.0027 - auc_4: 0.9999 - categorical_accuracy: 0.9993 - val_loss: 75.4450 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4520\n","Epoch 549/1000\n","3/3 [==============================] - 1s 337ms/step - loss: 0.0022 - auc_4: 0.9999 - categorical_accuracy: 0.9998 - val_loss: 75.4058 - val_auc_4: 0.7137 - val_categorical_accuracy: 0.4515\n","Epoch 550/1000\n","3/3 [==============================] - 1s 321ms/step - loss: 0.0021 - auc_4: 0.9999 - categorical_accuracy: 0.9996 - val_loss: 75.3526 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4520\n","Epoch 551/1000\n","3/3 [==============================] - 1s 347ms/step - loss: 0.0023 - auc_4: 0.9999 - categorical_accuracy: 0.9995 - val_loss: 75.2871 - val_auc_4: 0.7137 - val_categorical_accuracy: 0.4532\n","Epoch 552/1000\n","3/3 [==============================] - 1s 260ms/step - loss: 0.0022 - auc_4: 0.9999 - categorical_accuracy: 0.9995 - val_loss: 75.2671 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4524\n","Epoch 553/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 0.0019 - auc_4: 0.9999 - categorical_accuracy: 0.9996 - val_loss: 75.2739 - val_auc_4: 0.7137 - val_categorical_accuracy: 0.4532\n","Epoch 554/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 0.0016 - auc_4: 1.0000 - categorical_accuracy: 0.9998 - val_loss: 75.2841 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4532\n","Epoch 555/1000\n","3/3 [==============================] - 1s 241ms/step - loss: 0.0015 - auc_4: 1.0000 - categorical_accuracy: 0.9998 - val_loss: 75.2984 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4532\n","Epoch 556/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 0.0015 - auc_4: 1.0000 - categorical_accuracy: 0.9996 - val_loss: 75.3005 - val_auc_4: 0.7140 - val_categorical_accuracy: 0.4532\n","Epoch 557/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 0.0012 - auc_4: 1.0000 - categorical_accuracy: 0.9996 - val_loss: 75.2762 - val_auc_4: 0.7140 - val_categorical_accuracy: 0.4545\n","Epoch 558/1000\n","3/3 [==============================] - 1s 237ms/step - loss: 0.0011 - auc_4: 1.0000 - categorical_accuracy: 0.9996 - val_loss: 75.2622 - val_auc_4: 0.7140 - val_categorical_accuracy: 0.4545\n","Epoch 559/1000\n","3/3 [==============================] - 1s 237ms/step - loss: 0.0010 - auc_4: 1.0000 - categorical_accuracy: 0.9998 - val_loss: 75.2597 - val_auc_4: 0.7142 - val_categorical_accuracy: 0.4549\n","Epoch 560/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 9.5394e-04 - auc_4: 1.0000 - categorical_accuracy: 0.9998 - val_loss: 75.2834 - val_auc_4: 0.7139 - val_categorical_accuracy: 0.4545\n","Epoch 561/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 8.7543e-04 - auc_4: 1.0000 - categorical_accuracy: 0.9998 - val_loss: 75.3167 - val_auc_4: 0.7141 - val_categorical_accuracy: 0.4549\n","Epoch 562/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 7.6746e-04 - auc_4: 1.0000 - categorical_accuracy: 0.9999 - val_loss: 75.3472 - val_auc_4: 0.7137 - val_categorical_accuracy: 0.4545\n","Epoch 563/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 7.0269e-04 - auc_4: 1.0000 - categorical_accuracy: 0.9999 - val_loss: 75.3781 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4541\n","Epoch 564/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 6.2975e-04 - auc_4: 1.0000 - categorical_accuracy: 0.9999 - val_loss: 75.4066 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4541\n","Epoch 565/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 5.3988e-04 - auc_4: 1.0000 - categorical_accuracy: 0.9999 - val_loss: 75.4307 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4528\n","Epoch 566/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 4.9097e-04 - auc_4: 1.0000 - categorical_accuracy: 0.9999 - val_loss: 75.4479 - val_auc_4: 0.7126 - val_categorical_accuracy: 0.4524\n","Epoch 567/1000\n","3/3 [==============================] - 1s 325ms/step - loss: 4.3711e-04 - auc_4: 1.0000 - categorical_accuracy: 0.9999 - val_loss: 75.4576 - val_auc_4: 0.7126 - val_categorical_accuracy: 0.4520\n","Epoch 568/1000\n","3/3 [==============================] - 1s 323ms/step - loss: 3.8412e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.4712 - val_auc_4: 0.7124 - val_categorical_accuracy: 0.4520\n","Epoch 569/1000\n","3/3 [==============================] - 1s 320ms/step - loss: 3.4503e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.4948 - val_auc_4: 0.7126 - val_categorical_accuracy: 0.4515\n","Epoch 570/1000\n","3/3 [==============================] - 1s 317ms/step - loss: 3.7508e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.4964 - val_auc_4: 0.7126 - val_categorical_accuracy: 0.4515\n","Epoch 571/1000\n","3/3 [==============================] - 1s 323ms/step - loss: 3.6837e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.4746 - val_auc_4: 0.7126 - val_categorical_accuracy: 0.4528\n","Epoch 572/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 3.4402e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.4274 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4536\n","Epoch 573/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 2.7897e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3857 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4536\n","Epoch 574/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 2.4648e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3535 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 575/1000\n","3/3 [==============================] - 1s 237ms/step - loss: 2.2083e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3304 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 576/1000\n","3/3 [==============================] - 1s 246ms/step - loss: 2.0533e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3109 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 577/1000\n","3/3 [==============================] - 1s 224ms/step - loss: 1.9654e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3030 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 578/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 1.8954e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3081 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 579/1000\n","3/3 [==============================] - 1s 202ms/step - loss: 1.8106e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3104 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 580/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 1.7777e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3112 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 581/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 1.7493e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3123 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 582/1000\n","3/3 [==============================] - 1s 242ms/step - loss: 1.7058e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3177 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 583/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 1.6270e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3263 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4541\n","Epoch 584/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 1.5604e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3294 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 585/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 1.5139e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3331 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 586/1000\n","3/3 [==============================] - 1s 314ms/step - loss: 1.4629e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3350 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 587/1000\n","3/3 [==============================] - 1s 322ms/step - loss: 1.4218e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3359 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 588/1000\n","3/3 [==============================] - 1s 314ms/step - loss: 1.3563e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3328 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 589/1000\n","3/3 [==============================] - 1s 318ms/step - loss: 1.2772e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3265 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 590/1000\n","3/3 [==============================] - 1s 329ms/step - loss: 1.2325e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3168 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 591/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 1.2034e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3067 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 592/1000\n","3/3 [==============================] - 1s 237ms/step - loss: 1.1763e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2978 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 593/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 1.1411e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2884 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 594/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 1.1111e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2814 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4549\n","Epoch 595/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 1.1037e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2771 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 596/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 1.0860e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2761 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 597/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 1.0722e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2761 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 598/1000\n","3/3 [==============================] - 1s 201ms/step - loss: 1.0555e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2764 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 599/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 1.0392e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2774 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 600/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 1.0238e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2790 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 601/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 1.0100e-04 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2815 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 602/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 9.9493e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2838 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 603/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 9.8593e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2860 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4553\n","Epoch 604/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 9.8134e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2889 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 605/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 9.7151e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2918 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4549\n","Epoch 606/1000\n","3/3 [==============================] - 1s 297ms/step - loss: 9.5776e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2958 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 607/1000\n","3/3 [==============================] - 1s 308ms/step - loss: 9.4199e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2995 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 608/1000\n","3/3 [==============================] - 1s 312ms/step - loss: 9.2771e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3042 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 609/1000\n","3/3 [==============================] - 1s 304ms/step - loss: 9.0709e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3110 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 610/1000\n","3/3 [==============================] - 1s 323ms/step - loss: 8.9423e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3160 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 611/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 8.8197e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3191 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 612/1000\n","3/3 [==============================] - 1s 189ms/step - loss: 8.6928e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3215 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 613/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 8.5661e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3242 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 614/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 8.4236e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3274 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 615/1000\n","3/3 [==============================] - 1s 188ms/step - loss: 8.2911e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3288 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 616/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 8.1994e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3286 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 617/1000\n","3/3 [==============================] - 1s 222ms/step - loss: 8.0613e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3266 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 618/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 7.9609e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3231 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 619/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 7.8804e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3217 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4553\n","Epoch 620/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 7.7980e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3230 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 621/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 7.6928e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3229 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 622/1000\n","3/3 [==============================] - 1s 189ms/step - loss: 7.6158e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3220 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 623/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 7.5478e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3206 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 624/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 7.4749e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3175 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 625/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 7.4131e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3133 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 626/1000\n","3/3 [==============================] - 1s 325ms/step - loss: 7.3354e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3109 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 627/1000\n","3/3 [==============================] - 1s 318ms/step - loss: 7.2662e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3090 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 628/1000\n","3/3 [==============================] - 1s 320ms/step - loss: 7.1783e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3076 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 629/1000\n","3/3 [==============================] - 1s 343ms/step - loss: 7.1124e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3070 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 630/1000\n","3/3 [==============================] - 1s 307ms/step - loss: 6.9689e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3074 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 631/1000\n","3/3 [==============================] - 1s 250ms/step - loss: 6.9179e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3068 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4553\n","Epoch 632/1000\n","3/3 [==============================] - 1s 198ms/step - loss: 6.8451e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3068 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4553\n","Epoch 633/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 6.7754e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3057 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4553\n","Epoch 634/1000\n","3/3 [==============================] - 1s 245ms/step - loss: 6.6973e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3035 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4553\n","Epoch 635/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 6.6273e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3012 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 636/1000\n","3/3 [==============================] - 1s 240ms/step - loss: 6.5542e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2985 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 637/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 6.4928e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2975 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 638/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 6.4374e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2977 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 639/1000\n","3/3 [==============================] - 1s 199ms/step - loss: 6.3707e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2990 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 640/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 6.3128e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3011 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4557\n","Epoch 641/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 6.2489e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3031 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4553\n","Epoch 642/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 6.1946e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3043 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4553\n","Epoch 643/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 6.1288e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3048 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 644/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 6.0874e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3054 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 645/1000\n","3/3 [==============================] - 1s 327ms/step - loss: 6.0290e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3056 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 646/1000\n","3/3 [==============================] - 1s 343ms/step - loss: 5.9624e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3056 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 647/1000\n","3/3 [==============================] - 1s 328ms/step - loss: 5.9040e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3066 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 648/1000\n","3/3 [==============================] - 1s 344ms/step - loss: 5.8521e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3096 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 649/1000\n","3/3 [==============================] - 1s 301ms/step - loss: 5.8021e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3118 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 650/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 5.7522e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3129 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 651/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 5.7189e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3138 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 652/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 5.6714e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3147 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4553\n","Epoch 653/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 5.6377e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3154 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 654/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 5.5921e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3154 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 655/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 5.5586e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3166 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 656/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 5.5152e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3157 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 657/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 5.4723e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3136 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 658/1000\n","3/3 [==============================] - 1s 245ms/step - loss: 5.4231e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3119 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 659/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 5.3807e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3106 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 660/1000\n","3/3 [==============================] - 1s 201ms/step - loss: 5.3334e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3092 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4549\n","Epoch 661/1000\n","3/3 [==============================] - 1s 198ms/step - loss: 5.2921e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3088 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4553\n","Epoch 662/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 5.2522e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3094 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 663/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 5.2186e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3098 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4553\n","Epoch 664/1000\n","3/3 [==============================] - 1s 300ms/step - loss: 5.1664e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3088 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4553\n","Epoch 665/1000\n","3/3 [==============================] - 1s 316ms/step - loss: 5.1250e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3073 - val_auc_4: 0.7127 - val_categorical_accuracy: 0.4553\n","Epoch 666/1000\n","3/3 [==============================] - 1s 343ms/step - loss: 5.0971e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3060 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 667/1000\n","3/3 [==============================] - 1s 329ms/step - loss: 5.0544e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3034 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4557\n","Epoch 668/1000\n","3/3 [==============================] - 1s 304ms/step - loss: 5.0178e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3011 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4557\n","Epoch 669/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 4.9740e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2990 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4557\n","Epoch 670/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 4.9374e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2967 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4557\n","Epoch 671/1000\n","3/3 [==============================] - 1s 244ms/step - loss: 4.9023e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2945 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4557\n","Epoch 672/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 4.8791e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2920 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4557\n","Epoch 673/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 4.8416e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2902 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4557\n","Epoch 674/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 4.8164e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2899 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4557\n","Epoch 675/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 4.7546e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2916 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4557\n","Epoch 676/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 4.7245e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2926 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4553\n","Epoch 677/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 4.6781e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2936 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4553\n","Epoch 678/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 4.6539e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2961 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 679/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 4.6199e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2981 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 680/1000\n","3/3 [==============================] - 1s 195ms/step - loss: 4.5845e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2993 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4553\n","Epoch 681/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 4.5501e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2998 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 682/1000\n","3/3 [==============================] - 1s 187ms/step - loss: 4.5165e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3009 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4545\n","Epoch 683/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 4.4787e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3025 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4545\n","Epoch 684/1000\n","3/3 [==============================] - 1s 315ms/step - loss: 4.4493e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3041 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4545\n","Epoch 685/1000\n","3/3 [==============================] - 1s 343ms/step - loss: 4.4159e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3050 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 686/1000\n","3/3 [==============================] - 1s 327ms/step - loss: 4.3864e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3058 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 687/1000\n","3/3 [==============================] - 1s 321ms/step - loss: 4.3542e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3069 - val_auc_4: 0.7129 - val_categorical_accuracy: 0.4549\n","Epoch 688/1000\n","3/3 [==============================] - 1s 254ms/step - loss: 4.3290e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3075 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 689/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 4.2906e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3078 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 690/1000\n","3/3 [==============================] - 1s 198ms/step - loss: 4.2623e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3087 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 691/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 4.2373e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3083 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 692/1000\n","3/3 [==============================] - 1s 244ms/step - loss: 4.2143e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3074 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 693/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 4.1893e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3065 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 694/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 4.1685e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3055 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 695/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 4.1359e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3040 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 696/1000\n","3/3 [==============================] - 1s 205ms/step - loss: 4.1131e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3026 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 697/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 4.0930e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3005 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 698/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 4.0683e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2982 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 699/1000\n","3/3 [==============================] - 1s 200ms/step - loss: 4.0408e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2962 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 700/1000\n","3/3 [==============================] - 1s 186ms/step - loss: 4.0184e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2944 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 701/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 3.9945e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2925 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 702/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 3.9671e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2907 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 703/1000\n","3/3 [==============================] - 1s 234ms/step - loss: 3.9499e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2893 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 704/1000\n","3/3 [==============================] - 1s 340ms/step - loss: 3.9203e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2888 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 705/1000\n","3/3 [==============================] - 1s 335ms/step - loss: 3.8905e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2887 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 706/1000\n","3/3 [==============================] - 1s 311ms/step - loss: 3.8684e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2897 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 707/1000\n","3/3 [==============================] - 1s 337ms/step - loss: 3.8367e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2914 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 708/1000\n","3/3 [==============================] - 1s 239ms/step - loss: 3.8102e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2931 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 709/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 3.7897e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2942 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 710/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 3.7701e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2956 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 711/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 3.7491e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2982 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 712/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 3.7218e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3012 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 713/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 3.7084e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3038 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 714/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 3.6959e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3044 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 715/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 3.6728e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3038 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 716/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 3.6603e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3029 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 717/1000\n","3/3 [==============================] - 1s 225ms/step - loss: 3.6468e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.3006 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 718/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 3.6242e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2981 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 719/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 3.6031e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2960 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 720/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 3.5879e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2939 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 721/1000\n","3/3 [==============================] - 1s 313ms/step - loss: 3.5686e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2916 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 722/1000\n","3/3 [==============================] - 1s 436ms/step - loss: 3.5545e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2902 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 723/1000\n","3/3 [==============================] - 1s 366ms/step - loss: 3.5369e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2892 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 724/1000\n","3/3 [==============================] - 1s 342ms/step - loss: 3.5210e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2884 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 725/1000\n","3/3 [==============================] - 1s 382ms/step - loss: 3.5054e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2873 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 726/1000\n","3/3 [==============================] - 1s 390ms/step - loss: 3.4910e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2859 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 727/1000\n","3/3 [==============================] - 1s 325ms/step - loss: 3.4583e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2858 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 728/1000\n","3/3 [==============================] - 1s 350ms/step - loss: 3.4396e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2863 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 729/1000\n","3/3 [==============================] - 1s 191ms/step - loss: 3.4217e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2868 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 730/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 3.4001e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2864 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 731/1000\n","3/3 [==============================] - 1s 242ms/step - loss: 3.3819e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2860 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 732/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 3.3651e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2862 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 733/1000\n","3/3 [==============================] - 1s 243ms/step - loss: 3.3464e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2863 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 734/1000\n","3/3 [==============================] - 1s 242ms/step - loss: 3.3301e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2864 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 735/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 3.3156e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2865 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 736/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 3.2985e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2866 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 737/1000\n","3/3 [==============================] - 1s 234ms/step - loss: 3.2838e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2868 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 738/1000\n","3/3 [==============================] - 1s 189ms/step - loss: 3.2684e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2871 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 739/1000\n","3/3 [==============================] - 1s 226ms/step - loss: 3.2568e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2875 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 740/1000\n","3/3 [==============================] - 1s 200ms/step - loss: 3.2419e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2873 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 741/1000\n","3/3 [==============================] - 1s 244ms/step - loss: 3.2284e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2863 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 742/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 3.2161e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2855 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4545\n","Epoch 743/1000\n","3/3 [==============================] - 1s 295ms/step - loss: 3.2004e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2844 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 744/1000\n","3/3 [==============================] - 1s 304ms/step - loss: 3.1873e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2822 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 745/1000\n","3/3 [==============================] - 1s 318ms/step - loss: 3.1729e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2806 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4545\n","Epoch 746/1000\n","3/3 [==============================] - 1s 332ms/step - loss: 3.1552e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2815 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 747/1000\n","3/3 [==============================] - 1s 340ms/step - loss: 3.1353e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2822 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 748/1000\n","3/3 [==============================] - 1s 199ms/step - loss: 3.1213e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2824 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 749/1000\n","3/3 [==============================] - 1s 207ms/step - loss: 3.1074e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2826 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 750/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 3.0934e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2822 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 751/1000\n","3/3 [==============================] - 1s 238ms/step - loss: 3.0803e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2812 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 752/1000\n","3/3 [==============================] - 1s 195ms/step - loss: 3.0691e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2808 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 753/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 3.0593e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2811 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 754/1000\n","3/3 [==============================] - 1s 227ms/step - loss: 3.0463e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2826 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 755/1000\n","3/3 [==============================] - 1s 201ms/step - loss: 3.0344e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2847 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 756/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 3.0230e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2855 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 757/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 3.0122e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2850 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 758/1000\n","3/3 [==============================] - 1s 237ms/step - loss: 3.0059e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2844 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 759/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 2.9922e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2835 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 760/1000\n","3/3 [==============================] - 1s 228ms/step - loss: 2.9800e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2828 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 761/1000\n","3/3 [==============================] - 1s 238ms/step - loss: 2.9674e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2826 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 762/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 2.9552e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2822 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 763/1000\n","3/3 [==============================] - 1s 304ms/step - loss: 2.9417e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2816 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 764/1000\n","3/3 [==============================] - 1s 308ms/step - loss: 2.9274e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2815 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 765/1000\n","3/3 [==============================] - 1s 311ms/step - loss: 2.9110e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2812 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 766/1000\n","3/3 [==============================] - 1s 318ms/step - loss: 2.8961e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2805 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 767/1000\n","3/3 [==============================] - 1s 341ms/step - loss: 2.8808e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2800 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 768/1000\n","3/3 [==============================] - 1s 212ms/step - loss: 2.8683e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2797 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 769/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 2.8570e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2799 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 770/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 2.8446e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2799 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 771/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 2.8336e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2795 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 772/1000\n","3/3 [==============================] - 1s 238ms/step - loss: 2.8218e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2780 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 773/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 2.8135e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2765 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 774/1000\n","3/3 [==============================] - 1s 210ms/step - loss: 2.8020e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2753 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 775/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 2.7932e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2746 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 776/1000\n","3/3 [==============================] - 1s 202ms/step - loss: 2.7819e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2749 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 777/1000\n","3/3 [==============================] - 1s 234ms/step - loss: 2.7699e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2763 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 778/1000\n","3/3 [==============================] - 1s 247ms/step - loss: 2.7580e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2779 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 779/1000\n","3/3 [==============================] - 1s 244ms/step - loss: 2.7473e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2801 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 780/1000\n","3/3 [==============================] - 1s 242ms/step - loss: 2.7362e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2825 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 781/1000\n","3/3 [==============================] - 1s 238ms/step - loss: 2.7256e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2839 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 782/1000\n","3/3 [==============================] - 1s 307ms/step - loss: 2.7167e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2846 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 783/1000\n","3/3 [==============================] - 1s 313ms/step - loss: 2.7056e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2853 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 784/1000\n","3/3 [==============================] - 1s 343ms/step - loss: 2.6952e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2852 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 785/1000\n","3/3 [==============================] - 1s 323ms/step - loss: 2.6853e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2835 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 786/1000\n","3/3 [==============================] - 1s 314ms/step - loss: 2.6735e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2815 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 787/1000\n","3/3 [==============================] - 1s 199ms/step - loss: 2.6614e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2801 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 788/1000\n","3/3 [==============================] - 1s 198ms/step - loss: 2.6515e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2798 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 789/1000\n","3/3 [==============================] - 1s 241ms/step - loss: 2.6362e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2792 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 790/1000\n","3/3 [==============================] - 1s 243ms/step - loss: 2.6233e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2785 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 791/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 2.6112e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2778 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 792/1000\n","3/3 [==============================] - 1s 201ms/step - loss: 2.6029e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2776 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 793/1000\n","3/3 [==============================] - 1s 206ms/step - loss: 2.5929e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2776 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 794/1000\n","3/3 [==============================] - 1s 243ms/step - loss: 2.5835e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2774 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 795/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 2.5735e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2776 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 796/1000\n","3/3 [==============================] - 1s 195ms/step - loss: 2.5642e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2781 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 797/1000\n","3/3 [==============================] - 1s 205ms/step - loss: 2.5556e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2783 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 798/1000\n","3/3 [==============================] - 1s 195ms/step - loss: 2.5469e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2785 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4557\n","Epoch 799/1000\n","3/3 [==============================] - 1s 252ms/step - loss: 2.5399e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2787 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4557\n","Epoch 800/1000\n","3/3 [==============================] - 1s 199ms/step - loss: 2.5324e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2788 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4557\n","Epoch 801/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 2.5252e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2790 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4557\n","Epoch 802/1000\n","3/3 [==============================] - 1s 340ms/step - loss: 2.5174e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2795 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4557\n","Epoch 803/1000\n","3/3 [==============================] - 1s 319ms/step - loss: 2.5102e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2799 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4557\n","Epoch 804/1000\n","3/3 [==============================] - 1s 339ms/step - loss: 2.5022e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2804 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4557\n","Epoch 805/1000\n","3/3 [==============================] - 1s 331ms/step - loss: 2.4948e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2808 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4557\n","Epoch 806/1000\n","3/3 [==============================] - 1s 281ms/step - loss: 2.4874e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2809 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4557\n","Epoch 807/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 2.4795e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2805 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4557\n","Epoch 808/1000\n","3/3 [==============================] - 1s 244ms/step - loss: 2.4558e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2788 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 809/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 2.4558e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2767 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 810/1000\n","3/3 [==============================] - 1s 210ms/step - loss: 2.4411e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2752 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 811/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 2.4291e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2742 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 812/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 2.4210e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2738 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 813/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 2.4136e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2735 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 814/1000\n","3/3 [==============================] - 1s 210ms/step - loss: 2.4056e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2736 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 815/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 2.3968e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2736 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 816/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 2.3890e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2735 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 817/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 2.3816e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2742 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 818/1000\n","3/3 [==============================] - 1s 203ms/step - loss: 2.3703e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2766 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 819/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 2.3559e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2783 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 820/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 2.3480e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2795 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 821/1000\n","3/3 [==============================] - 1s 327ms/step - loss: 2.3411e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2800 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 822/1000\n","3/3 [==============================] - 1s 317ms/step - loss: 2.3317e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2801 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 823/1000\n","3/3 [==============================] - 1s 318ms/step - loss: 2.3237e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2800 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 824/1000\n","3/3 [==============================] - 1s 325ms/step - loss: 2.3166e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2795 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 825/1000\n","3/3 [==============================] - 1s 326ms/step - loss: 2.3092e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2787 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 826/1000\n","3/3 [==============================] - 1s 242ms/step - loss: 2.3028e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2776 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 827/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 2.2915e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2771 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 828/1000\n","3/3 [==============================] - 1s 241ms/step - loss: 2.2819e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2771 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 829/1000\n","3/3 [==============================] - 1s 238ms/step - loss: 2.2727e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2770 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 830/1000\n","3/3 [==============================] - 1s 239ms/step - loss: 2.2619e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2780 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 831/1000\n","3/3 [==============================] - 1s 199ms/step - loss: 2.2553e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2809 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 832/1000\n","3/3 [==============================] - 1s 239ms/step - loss: 2.2457e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2832 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 833/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 2.2369e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2847 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 834/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 2.2287e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2857 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 835/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 2.2207e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2870 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4553\n","Epoch 836/1000\n","3/3 [==============================] - 1s 240ms/step - loss: 2.2138e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2890 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 837/1000\n","3/3 [==============================] - 1s 245ms/step - loss: 2.2057e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2900 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 838/1000\n","3/3 [==============================] - 1s 241ms/step - loss: 2.1992e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2908 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 839/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 2.1930e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2914 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 840/1000\n","3/3 [==============================] - 1s 317ms/step - loss: 2.1861e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2920 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 841/1000\n","3/3 [==============================] - 1s 317ms/step - loss: 2.1797e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2923 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 842/1000\n","3/3 [==============================] - 1s 335ms/step - loss: 2.1726e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2921 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 843/1000\n","3/3 [==============================] - 1s 313ms/step - loss: 2.1644e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2927 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 844/1000\n","3/3 [==============================] - 1s 321ms/step - loss: 2.1567e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2932 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 845/1000\n","3/3 [==============================] - 1s 230ms/step - loss: 2.1483e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2932 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 846/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 2.1418e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2928 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 847/1000\n","3/3 [==============================] - 1s 239ms/step - loss: 2.1332e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2923 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 848/1000\n","3/3 [==============================] - 1s 238ms/step - loss: 2.1258e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2915 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 849/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 2.1171e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2910 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 850/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 2.1097e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2910 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 851/1000\n","3/3 [==============================] - 1s 206ms/step - loss: 2.1051e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2909 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4553\n","Epoch 852/1000\n","3/3 [==============================] - 1s 202ms/step - loss: 2.0968e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2908 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 853/1000\n","3/3 [==============================] - 1s 249ms/step - loss: 2.0912e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2913 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 854/1000\n","3/3 [==============================] - 1s 241ms/step - loss: 2.0863e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2917 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4549\n","Epoch 855/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 2.0793e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2931 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4549\n","Epoch 856/1000\n","3/3 [==============================] - 1s 238ms/step - loss: 2.0744e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2945 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4549\n","Epoch 857/1000\n","3/3 [==============================] - 1s 237ms/step - loss: 2.0652e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2949 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 858/1000\n","3/3 [==============================] - 1s 243ms/step - loss: 2.0593e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2947 - val_auc_4: 0.7132 - val_categorical_accuracy: 0.4549\n","Epoch 859/1000\n","3/3 [==============================] - 1s 312ms/step - loss: 2.0567e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2941 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 860/1000\n","3/3 [==============================] - 1s 332ms/step - loss: 2.0472e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2930 - val_auc_4: 0.7131 - val_categorical_accuracy: 0.4549\n","Epoch 861/1000\n","3/3 [==============================] - 1s 346ms/step - loss: 2.0345e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2921 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 862/1000\n","3/3 [==============================] - 1s 318ms/step - loss: 2.0260e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2910 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 863/1000\n","3/3 [==============================] - 1s 324ms/step - loss: 2.0186e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2904 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 864/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 2.0119e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2904 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 865/1000\n","3/3 [==============================] - 1s 213ms/step - loss: 2.0050e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2901 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 866/1000\n","3/3 [==============================] - 1s 284ms/step - loss: 1.9990e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2898 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 867/1000\n","3/3 [==============================] - 1s 316ms/step - loss: 1.9932e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2895 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 868/1000\n","3/3 [==============================] - 1s 341ms/step - loss: 1.9866e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2893 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 869/1000\n","3/3 [==============================] - 1s 339ms/step - loss: 1.9806e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2889 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 870/1000\n","3/3 [==============================] - 1s 360ms/step - loss: 1.9749e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2885 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 871/1000\n","3/3 [==============================] - 1s 210ms/step - loss: 1.9689e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2875 - val_auc_4: 0.7134 - val_categorical_accuracy: 0.4549\n","Epoch 872/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 1.9635e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2857 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 873/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 1.9562e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2840 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 874/1000\n","3/3 [==============================] - 1s 242ms/step - loss: 1.9512e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2817 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4549\n","Epoch 875/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 1.9442e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2796 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4553\n","Epoch 876/1000\n","3/3 [==============================] - 1s 327ms/step - loss: 1.9388e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2776 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 877/1000\n","3/3 [==============================] - 1s 338ms/step - loss: 1.9334e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2755 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 878/1000\n","3/3 [==============================] - 1s 348ms/step - loss: 1.9275e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2737 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 879/1000\n","3/3 [==============================] - 1s 344ms/step - loss: 1.9219e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2725 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 880/1000\n","3/3 [==============================] - 1s 279ms/step - loss: 1.9160e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2719 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 881/1000\n","3/3 [==============================] - 1s 211ms/step - loss: 1.9105e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2720 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 882/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 1.9039e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2720 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 883/1000\n","3/3 [==============================] - 1s 237ms/step - loss: 1.8986e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2718 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 884/1000\n","3/3 [==============================] - 1s 203ms/step - loss: 1.8944e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2712 - val_auc_4: 0.7133 - val_categorical_accuracy: 0.4557\n","Epoch 885/1000\n","3/3 [==============================] - 1s 207ms/step - loss: 1.8880e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2707 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 886/1000\n","3/3 [==============================] - 1s 205ms/step - loss: 1.8823e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2706 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 887/1000\n","3/3 [==============================] - 1s 207ms/step - loss: 1.8761e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2711 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 888/1000\n","3/3 [==============================] - 1s 203ms/step - loss: 1.8690e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2713 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 889/1000\n","3/3 [==============================] - 1s 200ms/step - loss: 1.8633e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2717 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 890/1000\n","3/3 [==============================] - 1s 200ms/step - loss: 1.8602e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2731 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 891/1000\n","3/3 [==============================] - 1s 213ms/step - loss: 1.8530e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2740 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 892/1000\n","3/3 [==============================] - 1s 206ms/step - loss: 1.8464e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2738 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 893/1000\n","3/3 [==============================] - 1s 195ms/step - loss: 1.8398e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2736 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 894/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 1.8342e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2736 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 895/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 1.8279e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2733 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 896/1000\n","3/3 [==============================] - 1s 331ms/step - loss: 1.8228e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2730 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 897/1000\n","3/3 [==============================] - 1s 303ms/step - loss: 1.8170e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2732 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 898/1000\n","3/3 [==============================] - 1s 336ms/step - loss: 1.8114e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2734 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 899/1000\n","3/3 [==============================] - 1s 306ms/step - loss: 1.8059e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2736 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 900/1000\n","3/3 [==============================] - 1s 286ms/step - loss: 1.8010e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2733 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4553\n","Epoch 901/1000\n","3/3 [==============================] - 1s 243ms/step - loss: 1.7948e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2722 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4553\n","Epoch 902/1000\n","3/3 [==============================] - 1s 237ms/step - loss: 1.7846e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2704 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4553\n","Epoch 903/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 1.7755e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2687 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4553\n","Epoch 904/1000\n","3/3 [==============================] - 1s 235ms/step - loss: 1.7702e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2668 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4553\n","Epoch 905/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 1.7624e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2653 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4553\n","Epoch 906/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 1.7552e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2637 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4553\n","Epoch 907/1000\n","3/3 [==============================] - 1s 206ms/step - loss: 1.7503e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2622 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 908/1000\n","3/3 [==============================] - 1s 237ms/step - loss: 1.7445e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2612 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 909/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 1.7393e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2605 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 910/1000\n","3/3 [==============================] - 1s 206ms/step - loss: 1.7347e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2600 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 911/1000\n","3/3 [==============================] - 1s 205ms/step - loss: 1.7296e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2601 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 912/1000\n","3/3 [==============================] - 1s 198ms/step - loss: 1.7255e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2601 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 913/1000\n","3/3 [==============================] - 1s 240ms/step - loss: 1.7174e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2601 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4553\n","Epoch 914/1000\n","3/3 [==============================] - 1s 190ms/step - loss: 1.7137e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2600 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4553\n","Epoch 915/1000\n","3/3 [==============================] - 1s 334ms/step - loss: 1.7093e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2599 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 916/1000\n","3/3 [==============================] - 1s 336ms/step - loss: 1.7030e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2597 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 917/1000\n","3/3 [==============================] - 1s 322ms/step - loss: 1.6977e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2588 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 918/1000\n","3/3 [==============================] - 1s 349ms/step - loss: 1.6927e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2579 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 919/1000\n","3/3 [==============================] - 1s 324ms/step - loss: 1.6890e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2570 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 920/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 1.6827e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2562 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 921/1000\n","3/3 [==============================] - 1s 247ms/step - loss: 1.6817e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2557 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 922/1000\n","3/3 [==============================] - 1s 232ms/step - loss: 1.6778e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2554 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 923/1000\n","3/3 [==============================] - 1s 192ms/step - loss: 1.6741e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2554 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 924/1000\n","3/3 [==============================] - 1s 195ms/step - loss: 1.6695e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2562 - val_auc_4: 0.7136 - val_categorical_accuracy: 0.4557\n","Epoch 925/1000\n","3/3 [==============================] - 1s 243ms/step - loss: 1.6635e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2574 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 926/1000\n","3/3 [==============================] - 1s 231ms/step - loss: 1.6573e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2582 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 927/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 1.6519e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2589 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 928/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 1.6459e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2595 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 929/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 1.6421e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2600 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 930/1000\n","3/3 [==============================] - 1s 206ms/step - loss: 1.6366e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2605 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 931/1000\n","3/3 [==============================] - 1s 202ms/step - loss: 1.6320e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2608 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 932/1000\n","3/3 [==============================] - 1s 240ms/step - loss: 1.6273e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2611 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 933/1000\n","3/3 [==============================] - 1s 242ms/step - loss: 1.6225e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2617 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 934/1000\n","3/3 [==============================] - 1s 321ms/step - loss: 1.6187e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2629 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 935/1000\n","3/3 [==============================] - 1s 330ms/step - loss: 1.6131e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2640 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 936/1000\n","3/3 [==============================] - 1s 313ms/step - loss: 1.6082e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2651 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 937/1000\n","3/3 [==============================] - 1s 338ms/step - loss: 1.6038e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2666 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 938/1000\n","3/3 [==============================] - 1s 331ms/step - loss: 1.5998e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2685 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 939/1000\n","3/3 [==============================] - 1s 247ms/step - loss: 1.5949e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2698 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 940/1000\n","3/3 [==============================] - 1s 196ms/step - loss: 1.5899e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2704 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 941/1000\n","3/3 [==============================] - 1s 239ms/step - loss: 1.5831e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2707 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 942/1000\n","3/3 [==============================] - 1s 204ms/step - loss: 1.5785e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2710 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 943/1000\n","3/3 [==============================] - 1s 241ms/step - loss: 1.5748e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2710 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 944/1000\n","3/3 [==============================] - 1s 234ms/step - loss: 1.5705e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2706 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 945/1000\n","3/3 [==============================] - 1s 229ms/step - loss: 1.5650e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2699 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 946/1000\n","3/3 [==============================] - 1s 210ms/step - loss: 1.5616e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2701 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 947/1000\n","3/3 [==============================] - 1s 206ms/step - loss: 1.5567e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2704 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 948/1000\n","3/3 [==============================] - 1s 233ms/step - loss: 1.5522e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2709 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 949/1000\n","3/3 [==============================] - 1s 249ms/step - loss: 1.5483e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2713 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 950/1000\n","3/3 [==============================] - 1s 242ms/step - loss: 1.5440e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2717 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 951/1000\n","3/3 [==============================] - 1s 240ms/step - loss: 1.5401e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2726 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 952/1000\n","3/3 [==============================] - 1s 320ms/step - loss: 1.5374e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2733 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 953/1000\n","3/3 [==============================] - 1s 422ms/step - loss: 1.5324e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2736 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 954/1000\n","3/3 [==============================] - 1s 355ms/step - loss: 1.5286e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2736 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 955/1000\n","3/3 [==============================] - 1s 384ms/step - loss: 1.5252e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2736 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 956/1000\n","3/3 [==============================] - 1s 461ms/step - loss: 1.5210e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2733 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 957/1000\n","3/3 [==============================] - 1s 363ms/step - loss: 1.5171e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2730 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 958/1000\n","3/3 [==============================] - 1s 352ms/step - loss: 1.5133e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2726 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 959/1000\n","3/3 [==============================] - 1s 321ms/step - loss: 1.5097e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2723 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 960/1000\n","3/3 [==============================] - 1s 237ms/step - loss: 1.5051e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2725 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 961/1000\n","3/3 [==============================] - 1s 243ms/step - loss: 1.5006e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2725 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 962/1000\n","3/3 [==============================] - 1s 215ms/step - loss: 1.4966e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2727 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 963/1000\n","3/3 [==============================] - 1s 247ms/step - loss: 1.4930e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2735 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 964/1000\n","3/3 [==============================] - 1s 248ms/step - loss: 1.4883e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2738 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 965/1000\n","3/3 [==============================] - 1s 204ms/step - loss: 1.4841e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2733 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 966/1000\n","3/3 [==============================] - 1s 241ms/step - loss: 1.4801e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2727 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 967/1000\n","3/3 [==============================] - 1s 244ms/step - loss: 1.4765e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2722 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 968/1000\n","3/3 [==============================] - 1s 193ms/step - loss: 1.4726e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2712 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 969/1000\n","3/3 [==============================] - 1s 194ms/step - loss: 1.4684e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2704 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 970/1000\n","3/3 [==============================] - 1s 250ms/step - loss: 1.4634e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2698 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 971/1000\n","3/3 [==============================] - 1s 246ms/step - loss: 1.4601e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2691 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 972/1000\n","3/3 [==============================] - 1s 205ms/step - loss: 1.4564e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2683 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 973/1000\n","3/3 [==============================] - 1s 199ms/step - loss: 1.4534e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2677 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 974/1000\n","3/3 [==============================] - 1s 319ms/step - loss: 1.4501e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2674 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 975/1000\n","3/3 [==============================] - 1s 329ms/step - loss: 1.4467e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2671 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 976/1000\n","3/3 [==============================] - 1s 340ms/step - loss: 1.4434e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2666 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 977/1000\n","3/3 [==============================] - 1s 327ms/step - loss: 1.4401e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2662 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 978/1000\n","3/3 [==============================] - 1s 327ms/step - loss: 1.4364e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2661 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 979/1000\n","3/3 [==============================] - 1s 245ms/step - loss: 1.4331e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2665 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 980/1000\n","3/3 [==============================] - 1s 247ms/step - loss: 1.4298e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2671 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 981/1000\n","3/3 [==============================] - 1s 205ms/step - loss: 1.4263e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2676 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 982/1000\n","3/3 [==============================] - 1s 248ms/step - loss: 1.4224e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2683 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4561\n","Epoch 983/1000\n","3/3 [==============================] - 1s 205ms/step - loss: 1.4197e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2687 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 984/1000\n","3/3 [==============================] - 1s 242ms/step - loss: 1.4159e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2690 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 985/1000\n","3/3 [==============================] - 1s 216ms/step - loss: 1.4123e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2691 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 986/1000\n","3/3 [==============================] - 1s 240ms/step - loss: 1.4096e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2693 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 987/1000\n","3/3 [==============================] - 1s 236ms/step - loss: 1.4060e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2695 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 988/1000\n","3/3 [==============================] - 1s 197ms/step - loss: 1.4026e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2692 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 989/1000\n","3/3 [==============================] - 1s 205ms/step - loss: 1.3998e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2684 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 990/1000\n","3/3 [==============================] - 1s 303ms/step - loss: 1.3960e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2678 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 991/1000\n","3/3 [==============================] - 1s 203ms/step - loss: 1.3929e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2675 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 992/1000\n","3/3 [==============================] - 1s 278ms/step - loss: 1.3893e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2678 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 993/1000\n","3/3 [==============================] - 1s 320ms/step - loss: 1.3866e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2684 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 994/1000\n","3/3 [==============================] - 1s 328ms/step - loss: 1.3840e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2687 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4553\n","Epoch 995/1000\n","3/3 [==============================] - 1s 347ms/step - loss: 1.3803e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2685 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4553\n","Epoch 996/1000\n","3/3 [==============================] - 1s 331ms/step - loss: 1.3749e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2681 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4553\n","Epoch 997/1000\n","3/3 [==============================] - 1s 241ms/step - loss: 1.3711e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2677 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4553\n","Epoch 998/1000\n","3/3 [==============================] - 1s 210ms/step - loss: 1.3673e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2670 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4553\n","Epoch 999/1000\n","3/3 [==============================] - 1s 242ms/step - loss: 1.3649e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2662 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n","Epoch 1000/1000\n","3/3 [==============================] - 1s 234ms/step - loss: 1.3599e-05 - auc_4: 1.0000 - categorical_accuracy: 1.0000 - val_loss: 75.2656 - val_auc_4: 0.7138 - val_categorical_accuracy: 0.4557\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-d7f58028f49b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model.fit(X_train, y_train_cat, epochs=1000, verbose = 1, batch_size = 4096, validation_data = (X_test, y_test_cat))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sUSyQPY86cCb"},"source":["# NF\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JPmCvarQpaZT"},"outputs":[],"source":["import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tVi3bcOOpWEa"},"outputs":[],"source":["with open('/content/flow_ssl/data/y_test.pkl', 'wb') as fh:\n","   pickle.dump(y_test, fh)\n","with open('/content/flow_ssl/data/y_train.pkl', 'wb') as fh:\n","   pickle.dump(y_train, fh)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gkd62M6HpfUr"},"outputs":[],"source":["with open('/content/flow_ssl/data/X_test.pkl', 'wb') as fh:\n","   pickle.dump(X_test, fh)\n","with open('/content/flow_ssl/data/X_train.pkl', 'wb') as fh:\n","   pickle.dump(X_train, fh)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tjZFw0b6Plli"},"outputs":[],"source":["!unzip \"/content/gdrive/MyDrive/Shared resources/flowgmm.zip\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15390,"status":"ok","timestamp":1681554706895,"user":{"displayName":"Anunay Yadav","userId":"18135409234894719745"},"user_tz":-330},"id":"iRXGoGwwoIny","outputId":"1e4912d1-2030-454c-fe84-808c12164e8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml\n","  Cloning https://github.com/mfinzi/olive-oil-ml to /tmp/pip-install-3gif8w_0/olive-oil-ml_11cc7d9c8282430f8996302a8a5a14d0\n","  Running command git clone --filter=blob:none --quiet https://github.com/mfinzi/olive-oil-ml /tmp/pip-install-3gif8w_0/olive-oil-ml_11cc7d9c8282430f8996302a8a5a14d0\n","  Resolved https://github.com/mfinzi/olive-oil-ml to commit 32978a77414575fad65b916e75374f9e16e99ede\n","  Running command git submodule update --init --recursive -q\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.9/dist-packages (from olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (1.8.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (0.9.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (1.5.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (3.7.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (0.3.6)\n","Requirement already satisfied: tqdm>=4.38 in /usr/local/lib/python3.9/dist-packages (from olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (4.65.0)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.9/dist-packages (from olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (8.3.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (1.2.2)\n","Requirement already satisfied: torchcontrib in /usr/local/lib/python3.9/dist-packages (from olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (0.0.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.2->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (4.5.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (1.4.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (1.0.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (2.8.2)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (5.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (23.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (8.4.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (2022.7.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (1.10.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (1.2.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->olive-oil-ml@ git+https://github.com/mfinzi/olive-oil-ml->FlowGMM==0.1) (1.16.0)\n","Installing collected packages: FlowGMM\n","  Attempting uninstall: FlowGMM\n","    Found existing installation: FlowGMM 0.1\n","    Can't uninstall 'FlowGMM'. No files were found to uninstall.\n","  Running setup.py develop for FlowGMM\n","Successfully installed FlowGMM-0.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: timm==0.3.2 in /usr/local/lib/python3.9/dist-packages (0.3.2)\n","Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.9/dist-packages (1.8.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch==1.8.1) (1.22.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.8.1) (4.5.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scanpy in /usr/local/lib/python3.9/dist-packages (1.9.3)\n","Requirement already satisfied: normflows in /usr/local/lib/python3.9/dist-packages (1.6.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from scanpy) (1.2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from scanpy) (23.0)\n","Requirement already satisfied: matplotlib>=3.4 in /usr/local/lib/python3.9/dist-packages (from scanpy) (3.7.1)\n","Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.9/dist-packages (from scanpy) (1.5.3)\n","Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.9/dist-packages (from scanpy) (1.10.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from scanpy) (4.65.0)\n","Requirement already satisfied: patsy in /usr/local/lib/python3.9/dist-packages (from scanpy) (0.5.3)\n","Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.9/dist-packages (from scanpy) (3.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (from scanpy) (0.12.2)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.9/dist-packages (from scanpy) (1.2.2)\n","Requirement already satisfied: h5py>=3 in /usr/local/lib/python3.9/dist-packages (from scanpy) (3.8.0)\n","Requirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.9/dist-packages (from scanpy) (0.13.5)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.9/dist-packages (from scanpy) (8.3.1)\n","Requirement already satisfied: umap-learn>=0.3.10 in /usr/local/lib/python3.9/dist-packages (from scanpy) (0.5.3)\n","Requirement already satisfied: session-info in /usr/local/lib/python3.9/dist-packages (from scanpy) (1.0.0)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.9/dist-packages (from scanpy) (1.22.4)\n","Requirement already satisfied: anndata>=0.7.4 in /usr/local/lib/python3.9/dist-packages (from scanpy) (0.9.1)\n","Requirement already satisfied: numba>=0.41.0 in /usr/local/lib/python3.9/dist-packages (from scanpy) (0.56.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from normflows) (1.8.1)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (5.12.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (8.4.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (4.39.3)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (0.11.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.4->scanpy) (1.0.7)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.41.0->scanpy) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.41.0->scanpy) (67.6.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.0->scanpy) (2022.7.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22->scanpy) (3.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy->scanpy) (1.16.0)\n","Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.9/dist-packages (from umap-learn>=0.3.10->scanpy) (0.5.8)\n","Requirement already satisfied: stdlib-list in /usr/local/lib/python3.9/dist-packages (from session-info->scanpy) (0.8.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->normflows) (4.5.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.4->scanpy) (3.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -e .\n","!pip install timm==0.3.2 torch==1.8.1 torchvision \n","!pip install scanpy normflows\n","!pip install pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fB9weHGYpsOp","outputId":"315570c0-b4cf-44fa-84aa-c82b27f3f854"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'dataset': <class 'flow_ssl.data.nlp_datasets.AG_News'>, 'network': <function RealNVPTabularWPrior at 0x7fc05038caf0>, 'num_epochs': 10000, 'bs': 10000, 'lr': 0.0003, 'optim': <class 'torch.optim.adamw.AdamW'>, 'device': 'cuda', 'trainer': SemiFlow, 'split': {'train': 10000, 'val': 5000}, 'net_config': {'k': 1024, 'coupling_layers': 7, 'nperlayer': 1}, 'opt_config': {'weight_decay': 1e-05}, 'trainer_config': {'log_dir': '/root/tb-experiments/UCI/', 'log_args': {'minPeriod': 0.1, 'timeFrac': 0.3}, 'unlab_weight': 0.6}, 'save': False}\n","8569\n","8569\n","2394\n","Pairwise dists: [[ 0.         23.98605122 24.8773274  23.68513762 25.41487821 25.20550683\n","  24.96208074 24.57989645 24.65671609 24.65561466 24.76541649 23.86222525\n","  25.2779631  25.14839989]\n"," [23.98605122  0.         24.96672304 24.46091736 24.58927195 24.92435047\n","  24.69337564 24.49599666 24.97331937 23.87492547 24.70093235 25.25464703\n","  24.68266664 25.50999955]\n"," [24.8773274  24.96672304  0.         24.16324134 24.26854227 24.25711302\n","  24.29346973 24.79419505 24.7388067  23.47224584 24.75623485 24.89661224\n","  24.37143956 24.96792198]\n"," [23.68513762 24.46091736 24.16324134  0.         24.23472498 23.88108308\n","  24.22323769 24.10371494 24.52687336 23.92233636 23.98621507 24.49200896\n","  24.7054004  24.92180312]\n"," [25.41487821 24.58927195 24.26854227 24.23472498  0.         25.11588476\n","  25.17657326 25.54487829 24.50643264 25.04921969 24.30234499 24.4413658\n","  24.73404967 25.25287478]\n"," [25.20550683 24.92435047 24.25711302 23.88108308 25.11588476  0.\n","  24.43623478 24.4478765  25.43557413 24.02125093 25.26358185 24.47563544\n","  24.82111148 25.5220158 ]\n"," [24.96208074 24.69337564 24.29346973 24.22323769 25.17657326 24.43623478\n","   0.         24.1696152  25.06105    24.1856498  25.27586899 25.02540006\n","  25.34743061 25.07930092]\n"," [24.57989645 24.49599666 24.79419505 24.10371494 25.54487829 24.4478765\n","  24.1696152   0.         24.71810471 24.56061652 25.02639996 24.86987107\n","  24.62775263 25.30184864]\n"," [24.65671609 24.97331937 24.7388067  24.52687336 24.50643264 25.43557413\n","  25.06105    24.71810471  0.         24.40552229 25.14952171 24.59002456\n","  25.08235369 25.1978857 ]\n"," [24.65561466 23.87492547 23.47224584 23.92233636 25.04921969 24.02125093\n","  24.1856498  24.56061652 24.40552229  0.         24.33360723 24.15945488\n","  24.42338241 25.19366303]\n"," [24.76541649 24.70093235 24.75623485 23.98621507 24.30234499 25.26358185\n","  25.27586899 25.02639996 25.14952171 24.33360723  0.         24.19544046\n","  24.91581513 25.48729443]\n"," [23.86222525 25.25464703 24.89661224 24.49200896 24.4413658  24.47563544\n","  25.02540006 24.86987107 24.59002456 24.15945488 24.19544046  0.\n","  25.01737731 24.76160635]\n"," [25.2779631  24.68266664 24.37143956 24.7054004  24.73404967 24.82111148\n","  25.34743061 24.62775263 25.08235369 24.42338241 24.91581513 25.01737731\n","   0.         24.96599531]\n"," [25.14839989 25.50999955 24.96792198 24.92180312 25.25287478 25.5220158\n","  25.07930092 25.30184864 25.1978857  25.19366303 25.48729443 24.76160635\n","  24.96599531  0.        ]]\n","train:   0% 0/10000 [00:00<?, ?it/s]/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 18177446.90004157, 'Train_Acc': 0.05446058091286307, 'val_Acc': 0.059509918319719954, 'test_Acc': 0.029657477025898077, 'class_Acc_0': 0.09415584415584416, 'class_Acc_1': 0.018849206349206348, 'class_Acc_2': 0.04225352112676056, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.015748031496062992, 'class_Acc_6': 0.015765765765765764, 'class_Acc_7': 0.14285714285714285, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.5, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(1.2132609e+10, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","   Minibatch_Loss  ...       val_bpd\n","0    1.987581e+10  ...  1.817745e+07\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   0% 39/10000 [02:28<7:56:16,  2.87s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 2425.094529928748, 'Train_Acc': 0.12863070539419086, 'val_Acc': 0.12368728121353559, 'test_Acc': 0.0885547201336675, 'class_Acc_0': 0.07467532467532467, 'class_Acc_1': 0.03571428571428571, 'class_Acc_2': 0.02816901408450704, 'class_Acc_3': 0.09574468085106383, 'class_Acc_4': 0.0, 'class_Acc_5': 0.07874015748031496, 'class_Acc_6': 0.26576576576576577, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(1608697.9, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  ...     val_bpd\n","39      2668257.75  ...  2425.09453\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   1% 69/10000 [04:15<8:07:27,  2.95s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 559.4595052342545, 'Train_Acc': 0.16441908713692946, 'val_Acc': 0.15985997666277713, 'test_Acc': 0.03383458646616541, 'class_Acc_0': 0.09740259740259741, 'class_Acc_1': 0.01488095238095238, 'class_Acc_2': 0.09859154929577464, 'class_Acc_3': 0.015957446808510637, 'class_Acc_4': 0.0, 'class_Acc_5': 0.031496062992125984, 'class_Acc_6': 0.015765765765765764, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.125, 'class_Acc_10': 0.0, 'class_Acc_11': 0.0, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(370761.1, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  ...     val_bpd\n","69        587941.0  ...  559.459505\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   1% 96/10000 [05:53<7:42:58,  2.80s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 344.97341178313036, 'Train_Acc': 0.1362811203319502, 'val_Acc': 0.11901983663943991, 'test_Acc': 0.04427736006683375, 'class_Acc_0': 0.05194805194805195, 'class_Acc_1': 0.054563492063492064, 'class_Acc_2': 0.05633802816901408, 'class_Acc_3': 0.0, 'class_Acc_4': 0.0, 'class_Acc_5': 0.13385826771653545, 'class_Acc_6': 0.01126126126126126, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(224349.48, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  ...     val_bpd\n","96     366845.0625  ...  344.973412\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   1% 122/10000 [07:28<7:58:00,  2.90s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 270.31485633746973, 'Train_Acc': 0.19774377593360995, 'val_Acc': 0.1691948658109685, 'test_Acc': 0.06015037593984962, 'class_Acc_0': 0.05194805194805195, 'class_Acc_1': 0.05654761904761905, 'class_Acc_2': 0.01408450704225352, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.2677165354330709, 'class_Acc_6': 0.06981981981981981, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(172997.44, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...     val_bpd\n","122    278989.84375  ...  270.314856\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   1% 147/10000 [09:01<8:21:08,  3.05s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 211.11239342609926, 'Train_Acc': 0.2108402489626556, 'val_Acc': 0.176196032672112, 'test_Acc': 0.0785296574770259, 'class_Acc_0': 0.05519480519480519, 'class_Acc_1': 0.050595238095238096, 'class_Acc_2': 0.009389671361502348, 'class_Acc_3': 0.0, 'class_Acc_4': 0.0, 'class_Acc_5': 0.33070866141732286, 'class_Acc_6': 0.16216216216216217, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.125, 'class_Acc_10': 0.0, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.03636363636363636, 'Unlab_loss(mb)': array(132377.52, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...     val_bpd\n","147   218307.921875  ...  211.112393\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   2% 171/10000 [10:31<7:58:10,  2.92s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 179.84905003625903, 'Train_Acc': 0.2509076763485477, 'val_Acc': 0.22753792298716452, 'test_Acc': 0.08437761069340016, 'class_Acc_0': 0.06168831168831169, 'class_Acc_1': 0.061507936507936505, 'class_Acc_2': 0.0, 'class_Acc_3': 0.010638297872340425, 'class_Acc_4': 0.0, 'class_Acc_5': 0.4330708661417323, 'class_Acc_6': 0.1373873873873874, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.125, 'class_Acc_10': 0.5, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(111782.45, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","171    183316.84375  ...  179.84905\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   2% 195/10000 [11:59<7:57:48,  2.92s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 158.96598548049926, 'Train_Acc': 0.2855290456431535, 'val_Acc': 0.2718786464410735, 'test_Acc': 0.08688387635756056, 'class_Acc_0': 0.1038961038961039, 'class_Acc_1': 0.05952380952380952, 'class_Acc_2': 0.009389671361502348, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.44094488188976383, 'class_Acc_6': 0.12162162162162163, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.125, 'class_Acc_10': 0.0, 'class_Acc_11': 0.3333333333333333, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(98070.99, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...     val_bpd\n","195     158721.1875  ...  158.965985\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   2% 219/10000 [13:26<7:55:54,  2.92s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 136.4764620192013, 'Train_Acc': 0.33026452282157676, 'val_Acc': 0.3103850641773629, 'test_Acc': 0.09649122807017543, 'class_Acc_0': 0.05519480519480519, 'class_Acc_1': 0.08432539682539683, 'class_Acc_2': 0.0, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.4645669291338583, 'class_Acc_6': 0.15315315315315314, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(83278.9, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...     val_bpd\n","219   137697.890625  ...  136.476462\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   2% 243/10000 [14:54<7:38:17,  2.82s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 121.84116680223417, 'Train_Acc': 0.3381742738589212, 'val_Acc': 0.3290548424737456, 'test_Acc': 0.09690893901420217, 'class_Acc_0': 0.045454545454545456, 'class_Acc_1': 0.0763888888888889, 'class_Acc_2': 0.0, 'class_Acc_3': 0.010638297872340425, 'class_Acc_4': 0.0, 'class_Acc_5': 0.41732283464566927, 'class_Acc_6': 0.18693693693693694, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.5, 'class_Acc_11': 0.3333333333333333, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(73575.695, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...     val_bpd\n","243   122574.453125  ...  121.841167\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   3% 266/10000 [16:20<8:04:44,  2.99s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 110.57087256224185, 'Train_Acc': 0.3805757261410788, 'val_Acc': 0.38156359393232203, 'test_Acc': 0.1148705096073517, 'class_Acc_0': 0.045454545454545456, 'class_Acc_1': 0.09325396825396826, 'class_Acc_2': 0.0, 'class_Acc_3': 0.015957446808510637, 'class_Acc_4': 0.0, 'class_Acc_5': 0.4094488188976378, 'class_Acc_6': 0.24774774774774774, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.5, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(65946.46, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...     val_bpd\n","266   110841.101562  ...  110.570873\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   3% 289/10000 [17:45<7:38:35,  2.83s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 102.17473246134139, 'Train_Acc': 0.36877593360995853, 'val_Acc': 0.35822637106184363, 'test_Acc': 0.10025062656641603, 'class_Acc_0': 0.06168831168831169, 'class_Acc_1': 0.07837301587301587, 'class_Acc_2': 0.0, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.41732283464566927, 'class_Acc_6': 0.19144144144144143, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.5, 'class_Acc_11': 0.3333333333333333, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(60406.707, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...     val_bpd\n","289    99707.632812  ...  102.174732\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   3% 312/10000 [19:12<7:55:50,  2.95s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 88.95719668537507, 'Train_Acc': 0.41026970954356845, 'val_Acc': 0.396732788798133, 'test_Acc': 0.10568086883876357, 'class_Acc_0': 0.06818181818181818, 'class_Acc_1': 0.07043650793650794, 'class_Acc_2': 0.0, 'class_Acc_3': 0.010638297872340425, 'class_Acc_4': 0.0, 'class_Acc_5': 0.44881889763779526, 'class_Acc_6': 0.21621621621621623, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.5, 'class_Acc_11': 0.8333333333333334, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(51554.484, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","312     87754.53125  ...  88.957197\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   3% 335/10000 [20:37<8:02:47,  3.00s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 80.49773736579593, 'Train_Acc': 0.42855290456431533, 'val_Acc': 0.41656942823803966, 'test_Acc': 0.09273182957393483, 'class_Acc_0': 0.06818181818181818, 'class_Acc_1': 0.04265873015873016, 'class_Acc_2': 0.004694835680751174, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.5039370078740157, 'class_Acc_6': 0.1981981981981982, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.5, 'class_Acc_11': 0.5, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(46047.9, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","335    78187.578125  ...  80.497737\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   4% 358/10000 [22:03<7:48:35,  2.92s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 72.72892569409304, 'Train_Acc': 0.4608402489626556, 'val_Acc': 0.456242707117853, 'test_Acc': 0.09816207184628237, 'class_Acc_0': 0.06168831168831169, 'class_Acc_1': 0.04662698412698413, 'class_Acc_2': 0.004694835680751174, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.4881889763779528, 'class_Acc_6': 0.2274774774774775, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.5, 'class_Acc_11': 0.5, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(40956.79, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","358     70541.09375  ...  72.728926\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   4% 380/10000 [23:27<8:05:07,  3.03s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 66.10779534312847, 'Train_Acc': 0.46862033195020747, 'val_Acc': 0.441073512252042, 'test_Acc': 0.09273182957393483, 'class_Acc_0': 0.03896103896103896, 'class_Acc_1': 0.05654761904761905, 'class_Acc_2': 0.004694835680751174, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.41732283464566927, 'class_Acc_6': 0.21171171171171171, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.5, 'class_Acc_11': 0.5, 'class_Acc_12': nan, 'class_Acc_13': 0.0, 'Unlab_loss(mb)': array(36590.844, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","380    65328.777344  ...  66.107795\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   4% 403/10000 [24:53<7:39:07,  2.87s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 62.840254464848215, 'Train_Acc': 0.48651452282157676, 'val_Acc': 0.4492415402567094, 'test_Acc': 0.09816207184628237, 'class_Acc_0': 0.022727272727272728, 'class_Acc_1': 0.06349206349206349, 'class_Acc_2': 0.004694835680751174, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.3937007874015748, 'class_Acc_6': 0.23873873873873874, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.5, 'class_Acc_11': 0.6666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(34505.223, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","403    60751.207031  ...  62.840254\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   4% 425/10000 [26:16<7:56:28,  2.99s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 59.120443485240436, 'Train_Acc': 0.5079097510373444, 'val_Acc': 0.4690781796966161, 'test_Acc': 0.10066833751044277, 'class_Acc_0': 0.04220779220779221, 'class_Acc_1': 0.061507936507936505, 'class_Acc_2': 0.004694835680751174, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.4330708661417323, 'class_Acc_6': 0.23648648648648649, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.5, 'class_Acc_11': 0.3333333333333333, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(32283.516, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","425    56480.039062  ...  59.120443\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   4% 447/10000 [27:40<8:00:13,  3.02s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 55.57398788593939, 'Train_Acc': 0.5355290456431535, 'val_Acc': 0.4970828471411902, 'test_Acc': 0.11904761904761904, 'class_Acc_0': 0.025974025974025976, 'class_Acc_1': 0.09424603174603174, 'class_Acc_2': 0.009389671361502348, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.4251968503937008, 'class_Acc_6': 0.2747747747747748, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.3333333333333333, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(29935.004, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","447      54172.0625  ...  55.573988\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   5% 470/10000 [29:06<7:46:38,  2.94s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 52.972837893851136, 'Train_Acc': 0.5507002074688797, 'val_Acc': 0.5274212368728122, 'test_Acc': 0.1620718462823726, 'class_Acc_0': 0.09415584415584416, 'class_Acc_1': 0.08134920634920635, 'class_Acc_2': 0.023474178403755867, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.5669291338582677, 'class_Acc_6': 0.44144144144144143, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.3333333333333333, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(28281.262, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","470    50926.367188  ...  52.972838\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   5% 493/10000 [30:32<7:39:38,  2.90s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 49.18090035507381, 'Train_Acc': 0.6172199170124482, 'val_Acc': 0.6079346557759626, 'test_Acc': 0.1608187134502924, 'class_Acc_0': 0.1331168831168831, 'class_Acc_1': 0.08134920634920635, 'class_Acc_2': 0.051643192488262914, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.5984251968503937, 'class_Acc_6': 0.38513513513513514, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.03636363636363636, 'Unlab_loss(mb)': array(25890.912, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...  val_bpd\n","493    47028.929688  ...  49.1809\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   5% 515/10000 [31:55<7:34:37,  2.88s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 46.26665379757456, 'Train_Acc': 0.6397821576763485, 'val_Acc': 0.6336056009334889, 'test_Acc': 0.170843776106934, 'class_Acc_0': 0.11688311688311688, 'class_Acc_1': 0.08531746031746032, 'class_Acc_2': 0.051643192488262914, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.6456692913385826, 'class_Acc_6': 0.427927927927928, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.3333333333333333, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(24045.234, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","515    43964.246094  ...  46.266654\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   5% 538/10000 [33:21<7:35:50,  2.89s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 45.431773513546375, 'Train_Acc': 0.6616960580912863, 'val_Acc': 0.6534422403733956, 'test_Acc': 0.15664160401002505, 'class_Acc_0': 0.14935064935064934, 'class_Acc_1': 0.05357142857142857, 'class_Acc_2': 0.06103286384976525, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.5433070866141733, 'class_Acc_6': 0.42567567567567566, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.125, 'class_Acc_10': 0.0, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(23497.613, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","538    42177.085938  ...  45.431774\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   6% 561/10000 [34:46<7:42:26,  2.94s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 42.37063163556071, 'Train_Acc': 0.6684387966804979, 'val_Acc': 0.646441073512252, 'test_Acc': 0.14452798663324978, 'class_Acc_0': 0.16883116883116883, 'class_Acc_1': 0.060515873015873016, 'class_Acc_2': 0.04225352112676056, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.45669291338582685, 'class_Acc_6': 0.36261261261261263, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.125, 'class_Acc_10': 0.0, 'class_Acc_11': 0.3333333333333333, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(21545.576, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","561    38983.113281  ...  42.370632\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   6% 583/10000 [36:09<7:45:01,  2.96s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 40.41432234271587, 'Train_Acc': 0.7059128630705395, 'val_Acc': 0.6791131855309218, 'test_Acc': 0.15079365079365079, 'class_Acc_0': 0.14935064935064934, 'class_Acc_1': 0.07738095238095238, 'class_Acc_2': 0.046948356807511735, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.44094488188976383, 'class_Acc_6': 0.3783783783783784, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.125, 'class_Acc_10': 0.0, 'class_Acc_11': 0.0, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(20299.828, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","583     36696.15625  ...  40.414322\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   6% 605/10000 [37:32<7:21:07,  2.82s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 39.252742394957025, 'Train_Acc': 0.7313278008298755, 'val_Acc': 0.7012835472578763, 'test_Acc': 0.14578111946532998, 'class_Acc_0': 0.13636363636363635, 'class_Acc_1': 0.08630952380952381, 'class_Acc_2': 0.03755868544600939, 'class_Acc_3': 0.010638297872340425, 'class_Acc_4': 0.0, 'class_Acc_5': 0.4881889763779528, 'class_Acc_6': 0.3310810810810811, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.0, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(19569.984, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","605    35478.539062  ...  39.252742\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   6% 627/10000 [38:55<7:48:52,  3.00s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 37.66414980870039, 'Train_Acc': 0.7328838174273858, 'val_Acc': 0.7152858809801633, 'test_Acc': 0.14411027568922305, 'class_Acc_0': 0.10714285714285714, 'class_Acc_1': 0.08333333333333333, 'class_Acc_2': 0.02816901408450704, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.4330708661417323, 'class_Acc_6': 0.36936936936936937, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(18567.229, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...   val_bpd\n","627        33807.75  ...  37.66415\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   6% 649/10000 [40:17<7:25:47,  2.86s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 36.44327100300522, 'Train_Acc': 0.7484439834024896, 'val_Acc': 0.7222870478413069, 'test_Acc': 0.1532999164578112, 'class_Acc_0': 0.09740259740259741, 'class_Acc_1': 0.09623015873015874, 'class_Acc_2': 0.051643192488262914, 'class_Acc_3': 0.010638297872340425, 'class_Acc_4': 0.0, 'class_Acc_5': 0.45669291338582685, 'class_Acc_6': 0.3761261261261261, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(17771.184, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","649    32267.769531  ...  36.443271\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   7% 671/10000 [41:39<7:16:31,  2.81s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 35.88189229052665, 'Train_Acc': 0.7637448132780082, 'val_Acc': 0.7409568261376897, 'test_Acc': 0.14912280701754385, 'class_Acc_0': 0.10714285714285714, 'class_Acc_1': 0.10317460317460317, 'class_Acc_2': 0.04225352112676056, 'class_Acc_3': 0.010638297872340425, 'class_Acc_4': 0.0, 'class_Acc_5': 0.4330708661417323, 'class_Acc_6': 0.34234234234234234, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(17447.186, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","671    31471.333984  ...  35.881892\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   7% 693/10000 [43:02<7:45:52,  3.00s/it]/content/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/content/experiments/train_flows/train_semisup_flowgmm_tabular.py:87: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 34.34665872792179, 'Train_Acc': 0.7891597510373444, 'val_Acc': 0.7526254375729288, 'test_Acc': 0.15664160401002505, 'class_Acc_0': 0.1038961038961039, 'class_Acc_1': 0.10813492063492064, 'class_Acc_2': 0.02816901408450704, 'class_Acc_3': 0.005319148936170213, 'class_Acc_4': 0.0, 'class_Acc_5': 0.4803149606299213, 'class_Acc_6': 0.36936936936936937, 'class_Acc_7': 0.0, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'class_Acc_10': 0.0, 'class_Acc_11': 0.16666666666666666, 'class_Acc_12': nan, 'class_Acc_13': 0.01818181818181818, 'Unlab_loss(mb)': array(16477.158, dtype=float32)}\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  ...    val_bpd\n","693    30045.306641  ...  34.346659\n","\n","[1 rows x 21 columns]\n","/content/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   7% 700/10000 [43:40<8:56:21,  3.46s/it]"]}],"source":["!python3 experiments/train_flows/flowgmm_tabular_new.py --trainer_config \"{'unlab_weight':.6}\" --net_config \"{'k':1024,'coupling_layers':7,'nperlayer':1}\" --network RealNVPTabularWPrior --trainer SemiFlow --num_epochs 10000 --dataset AG_News --lr 3e-4 --train 10000 --bs 10000"]}],"metadata":{"colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":5}
