{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘dataset’: File exists\n",
      "mkdir: cannot create directory ‘np’: File exists\n"
     ]
    }
   ],
   "source": [
    "!bash init.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anunay18021/SingleCellClassification/flowgmm\n",
      "/home/anunay18021/SingleCellClassification\n"
     ]
    }
   ],
   "source": [
    "%cd flowgmm\n",
    "!pip install -q -e .\n",
    "!pip install -q timm==0.3.2 torch torchvision\n",
    "!pip install -q scanpy normflows\n",
    "!pip install -q pydeseq2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch import distributions\n",
    "import scanpy as sc\n",
    "import os\n",
    "from numpy.random import seed\n",
    "# from tensorflow import set_random_seed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "from pydeseq2.dds import *\n",
    "dataset_train = 'dataset/Bh.h5ad'\n",
    "dataset_test = 'dataset/smartseq2.h5ad'\n",
    "import sys\n",
    "sys.path.insert(0, '')\n",
    "\n",
    "from scripts.utils import *\n",
    "import numpy as np\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_deseq(adata_test, n_top_genes = 3000, max_value = 10, get_hvgs=False, scale_and_hvgs = False, calculate_hvg_and_log1p = True):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "        file_path: path to .h5ad containing scRNA-seq\n",
    "        \"\"\"\n",
    "        ## convert to h5ad\n",
    "        # adata_test = sc.AnnData(genes, labels)\n",
    "        adata_test.X = adata_test.to_df().to_numpy()\n",
    "        ## make var names unique\n",
    "        adata_test.obs_names_make_unique()\n",
    "        adata_test.var_names_make_unique()\n",
    "        adata_test = DeseqDataSet(adata = adata_test, design_factors='celltype')\n",
    "        adata_test.vst()\n",
    "        ## filter cells with count less than 200\n",
    "\n",
    "        ## LogNormalise\n",
    "        if not(scale_and_hvgs):\n",
    "                return {'data':adata_test}\n",
    "\n",
    "        if get_hvgs:\n",
    "                ## Get HVGS\n",
    "                # \n",
    "                if calculate_hvg_and_log1p:\n",
    "                        sc.pp.log1p(adata_test)\n",
    "                        sc.pp.highly_variable_genes(adata_test, n_top_genes = n_top_genes)\n",
    "                adata_test = adata_test[:, adata_test.var.highly_variable]\n",
    "\n",
    "                ## scale data\n",
    "                sc.pp.scale(adata_test, max_value=max_value)\n",
    "                return {'data' : adata_test, 'hvg': adata_test.var.highly_variable}\n",
    "\n",
    "        ## scale data\n",
    "        sc.pp.scale(adata_test, max_value=max_value)\n",
    "        return {'data':adata_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Fitting size factors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anunay18021/.venv/lib/python3.8/site-packages/pydeseq2/dds.py:259: RuntimeWarning: Every gene contains at least one zero, cannot compute log geometric means. Switching to iterative mode.\n",
      "  self.fit_size_factors()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting dispersions...\n",
      "... done in 110.47 seconds.\n",
      "\n",
      "Fitting MAP dispersions...\n",
      "... done in 58.44 seconds.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m adata_test\u001b[39m=\u001b[39msc\u001b[39m.\u001b[39mread(dataset_test)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarting preprocessing...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m train_dic \u001b[39m=\u001b[39m preprocess_deseq(adata_train, get_hvgs \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, scale_and_hvgs \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      6\u001b[0m test_dic \u001b[39m=\u001b[39m preprocess_deseq(adata_test)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(intersection(adata_train\u001b[39m.\u001b[39mvar\u001b[39m.\u001b[39mindex, adata_test\u001b[39m.\u001b[39mvar\u001b[39m.\u001b[39mindex)))\n",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m, in \u001b[0;36mpreprocess_deseq\u001b[0;34m(adata_test, n_top_genes, max_value, get_hvgs, scale_and_hvgs, calculate_hvg_and_log1p)\u001b[0m\n\u001b[1;32m     11\u001b[0m adata_test\u001b[39m.\u001b[39mvar_names_make_unique()\n\u001b[1;32m     12\u001b[0m adata_test \u001b[39m=\u001b[39m DeseqDataSet(adata \u001b[39m=\u001b[39m adata_test, design_factors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcelltype\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m adata_test\u001b[39m.\u001b[39;49mvst()\n\u001b[1;32m     14\u001b[0m \u001b[39m## filter cells with count less than 200\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[39m## LogNormalise\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m(scale_and_hvgs):\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/pydeseq2/dds.py:259\u001b[0m, in \u001b[0;36mDeseqDataSet.vst\u001b[0;34m(self, use_design, fit_type)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39m# Start by fitting median-of-ratio size factors, if not already present.\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msize_factors\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobsm:\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_size_factors()\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m use_design:\n\u001b[1;32m    262\u001b[0m     \u001b[39m# Check that the dispersion trend curve was fitted. If not, fit it.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[39m# This will call previous functions in a cascade.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtrend_coeffs\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muns:\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/pydeseq2/dds.py:357\u001b[0m, in \u001b[0;36mDeseqDataSet.fit_size_factors\u001b[0;34m(self, fit_type)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39melif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39many(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mall():\n\u001b[1;32m    350\u001b[0m     \u001b[39m# There is at least a zero for each gene\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    352\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEvery gene contains at least one zero, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcannot compute log geometric means. Switching to iterative mode.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    354\u001b[0m         \u001b[39mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    356\u001b[0m     )\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_iterate_size_factors()\n\u001b[1;32m    358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m\"\u001b[39m\u001b[39mnormed_counts\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobsm[\u001b[39m\"\u001b[39m\u001b[39msize_factors\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m deseq2_norm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/pydeseq2/dds.py:1018\u001b[0m, in \u001b[0;36mDeseqDataSet._fit_iterate_size_factors\u001b[0;34m(self, niter, quant)\u001b[0m\n\u001b[1;32m   1015\u001b[0m old_sf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobsm[\u001b[39m\"\u001b[39m\u001b[39msize_factors\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m   1017\u001b[0m \u001b[39m# Fit size factors using MLE\u001b[39;00m\n\u001b[0;32m-> 1018\u001b[0m res \u001b[39m=\u001b[39m minimize(objective, np\u001b[39m.\u001b[39;49mlog(old_sf), method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPowell\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   1020\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobsm[\u001b[39m\"\u001b[39m\u001b[39msize_factors\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(res\u001b[39m.\u001b[39mx \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(res\u001b[39m.\u001b[39mx))\n\u001b[1;32m   1022\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m res\u001b[39m.\u001b[39msuccess:\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/scipy/optimize/_minimize.py:687\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    684\u001b[0m     res \u001b[39m=\u001b[39m _minimize_neldermead(fun, x0, args, callback, bounds\u001b[39m=\u001b[39mbounds,\n\u001b[1;32m    685\u001b[0m                                \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    686\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpowell\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     res \u001b[39m=\u001b[39m _minimize_powell(fun, x0, args, callback, bounds, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    688\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcg\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    689\u001b[0m     res \u001b[39m=\u001b[39m _minimize_cg(fun, x0, args, jac, callback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/scipy/optimize/_optimize.py:3346\u001b[0m, in \u001b[0;36m_minimize_powell\u001b[0;34m(func, x0, args, callback, bounds, xtol, ftol, maxiter, maxfev, disp, direc, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   3344\u001b[0m direc1 \u001b[39m=\u001b[39m direc[i]\n\u001b[1;32m   3345\u001b[0m fx2 \u001b[39m=\u001b[39m fval\n\u001b[0;32m-> 3346\u001b[0m fval, x, direc1 \u001b[39m=\u001b[39m _linesearch_powell(func, x, direc1,\n\u001b[1;32m   3347\u001b[0m                                      tol\u001b[39m=\u001b[39;49mxtol \u001b[39m*\u001b[39;49m \u001b[39m100\u001b[39;49m,\n\u001b[1;32m   3348\u001b[0m                                      lower_bound\u001b[39m=\u001b[39;49mlower_bound,\n\u001b[1;32m   3349\u001b[0m                                      upper_bound\u001b[39m=\u001b[39;49mupper_bound,\n\u001b[1;32m   3350\u001b[0m                                      fval\u001b[39m=\u001b[39;49mfval)\n\u001b[1;32m   3351\u001b[0m \u001b[39mif\u001b[39;00m (fx2 \u001b[39m-\u001b[39m fval) \u001b[39m>\u001b[39m delta:\n\u001b[1;32m   3352\u001b[0m     delta \u001b[39m=\u001b[39m fx2 \u001b[39m-\u001b[39m fval\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/scipy/optimize/_optimize.py:3025\u001b[0m, in \u001b[0;36m_linesearch_powell\u001b[0;34m(func, p, xi, tol, lower_bound, upper_bound, fval)\u001b[0m\n\u001b[1;32m   3022\u001b[0m     \u001b[39mreturn\u001b[39;00m ((fval, p, xi) \u001b[39mif\u001b[39;00m fval \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (func(p), p, xi))\n\u001b[1;32m   3023\u001b[0m \u001b[39melif\u001b[39;00m lower_bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m upper_bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3024\u001b[0m     \u001b[39m# non-bounded minimization\u001b[39;00m\n\u001b[0;32m-> 3025\u001b[0m     alpha_min, fret, _, _ \u001b[39m=\u001b[39m brent(myfunc, full_output\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, tol\u001b[39m=\u001b[39;49mtol)\n\u001b[1;32m   3026\u001b[0m     xi \u001b[39m=\u001b[39m alpha_min \u001b[39m*\u001b[39m xi\n\u001b[1;32m   3027\u001b[0m     \u001b[39mreturn\u001b[39;00m squeeze(fret), p \u001b[39m+\u001b[39m xi, xi\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/scipy/optimize/_optimize.py:2569\u001b[0m, in \u001b[0;36mbrent\u001b[0;34m(func, args, brack, tol, full_output, maxiter)\u001b[0m\n\u001b[1;32m   2498\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2499\u001b[0m \u001b[39mGiven a function of one variable and a possible bracket, return\u001b[39;00m\n\u001b[1;32m   2500\u001b[0m \u001b[39mthe local minimum of the function isolated to a fractional precision\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2565\u001b[0m \n\u001b[1;32m   2566\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2567\u001b[0m options \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mxtol\u001b[39m\u001b[39m'\u001b[39m: tol,\n\u001b[1;32m   2568\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m'\u001b[39m: maxiter}\n\u001b[0;32m-> 2569\u001b[0m res \u001b[39m=\u001b[39m _minimize_scalar_brent(func, brack, args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m   2570\u001b[0m \u001b[39mif\u001b[39;00m full_output:\n\u001b[1;32m   2571\u001b[0m     \u001b[39mreturn\u001b[39;00m res[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mnit\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mnfev\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/scipy/optimize/_optimize.py:2606\u001b[0m, in \u001b[0;36m_minimize_scalar_brent\u001b[0;34m(func, brack, args, xtol, maxiter, disp, **unknown_options)\u001b[0m\n\u001b[1;32m   2603\u001b[0m brent \u001b[39m=\u001b[39m Brent(func\u001b[39m=\u001b[39mfunc, args\u001b[39m=\u001b[39margs, tol\u001b[39m=\u001b[39mtol,\n\u001b[1;32m   2604\u001b[0m               full_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, maxiter\u001b[39m=\u001b[39mmaxiter, disp\u001b[39m=\u001b[39mdisp)\n\u001b[1;32m   2605\u001b[0m brent\u001b[39m.\u001b[39mset_bracket(brack)\n\u001b[0;32m-> 2606\u001b[0m brent\u001b[39m.\u001b[39;49moptimize()\n\u001b[1;32m   2607\u001b[0m x, fval, nit, nfev \u001b[39m=\u001b[39m brent\u001b[39m.\u001b[39mget_result(full_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   2609\u001b[0m success \u001b[39m=\u001b[39m nit \u001b[39m<\u001b[39m maxiter \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (np\u001b[39m.\u001b[39misnan(x) \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39misnan(fval))\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/scipy/optimize/_optimize.py:2377\u001b[0m, in \u001b[0;36mBrent.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2374\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   2375\u001b[0m     \u001b[39m# set up for optimization\u001b[39;00m\n\u001b[1;32m   2376\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[0;32m-> 2377\u001b[0m     xa, xb, xc, fa, fb, fc, funcalls \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_bracket_info()\n\u001b[1;32m   2378\u001b[0m     _mintol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mintol\n\u001b[1;32m   2379\u001b[0m     _cg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cg\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/scipy/optimize/_optimize.py:2344\u001b[0m, in \u001b[0;36mBrent.get_bracket_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2341\u001b[0m \u001b[39m### BEGIN core bracket_info code ###\u001b[39;00m\n\u001b[1;32m   2342\u001b[0m \u001b[39m### carefully DOCUMENT any CHANGES in core ##\u001b[39;00m\n\u001b[1;32m   2343\u001b[0m \u001b[39mif\u001b[39;00m brack \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2344\u001b[0m     xa, xb, xc, fa, fb, fc, funcalls \u001b[39m=\u001b[39m bracket(func, args\u001b[39m=\u001b[39;49margs)\n\u001b[1;32m   2345\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(brack) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   2346\u001b[0m     xa, xb, xc, fa, fb, fc, funcalls \u001b[39m=\u001b[39m bracket(func, xa\u001b[39m=\u001b[39mbrack[\u001b[39m0\u001b[39m],\n\u001b[1;32m   2347\u001b[0m                                                xb\u001b[39m=\u001b[39mbrack[\u001b[39m1\u001b[39m], args\u001b[39m=\u001b[39margs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/scipy/optimize/_optimize.py:2873\u001b[0m, in \u001b[0;36mbracket\u001b[0;34m(func, xa, xb, args, grow_limit, maxiter)\u001b[0m\n\u001b[1;32m   2871\u001b[0m     fa, fb \u001b[39m=\u001b[39m fb, fa\n\u001b[1;32m   2872\u001b[0m xc \u001b[39m=\u001b[39m xb \u001b[39m+\u001b[39m _gold \u001b[39m*\u001b[39m (xb \u001b[39m-\u001b[39m xa)\n\u001b[0;32m-> 2873\u001b[0m fc \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49m((xc,) \u001b[39m+\u001b[39;49m args))\n\u001b[1;32m   2874\u001b[0m funcalls \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m   2875\u001b[0m \u001b[39miter\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/scipy/optimize/_optimize.py:3018\u001b[0m, in \u001b[0;36m_linesearch_powell.<locals>.myfunc\u001b[0;34m(alpha)\u001b[0m\n\u001b[1;32m   3017\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmyfunc\u001b[39m(alpha):\n\u001b[0;32m-> 3018\u001b[0m     \u001b[39mreturn\u001b[39;00m func(p \u001b[39m+\u001b[39;49m alpha\u001b[39m*\u001b[39;49mxi)\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/scipy/optimize/_optimize.py:569\u001b[0m, in \u001b[0;36m_wrap_scalar_function_maxfun_validation.<locals>.function_wrapper\u001b[0;34m(x, *wrapper_args)\u001b[0m\n\u001b[1;32m    567\u001b[0m ncalls[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    568\u001b[0m \u001b[39m# A copy of x is sent to the user function (gh13740)\u001b[39;00m\n\u001b[0;32m--> 569\u001b[0m fx \u001b[39m=\u001b[39m function(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49m(wrapper_args \u001b[39m+\u001b[39;49m args))\n\u001b[1;32m    570\u001b[0m \u001b[39m# Ideally, we'd like to a have a true scalar returned from f(x). For\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[39m# backwards-compatibility, also allow np.array([1.3]),\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[39m# np.array([[1.3]]) etc.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/pydeseq2/dds.py:989\u001b[0m, in \u001b[0;36mDeseqDataSet._fit_iterate_size_factors.<locals>.objective\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(p):\n\u001b[1;32m    988\u001b[0m     sf \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(p \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(p))\n\u001b[0;32m--> 989\u001b[0m     nll \u001b[39m=\u001b[39m nb_nll(\n\u001b[1;32m    990\u001b[0m         counts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m[:, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnon_zero_genes]\u001b[39m.\u001b[39;49mX,\n\u001b[1;32m    991\u001b[0m         mu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m[:, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnon_zero_genes]\u001b[39m.\u001b[39;49mlayers[\u001b[39m\"\u001b[39;49m\u001b[39m_mu_hat\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    992\u001b[0m         \u001b[39m/\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobsm[\u001b[39m\"\u001b[39;49m\u001b[39msize_factors\u001b[39;49m\u001b[39m\"\u001b[39;49m][:, \u001b[39mNone\u001b[39;49;00m]\n\u001b[1;32m    993\u001b[0m         \u001b[39m*\u001b[39;49m sf[:, \u001b[39mNone\u001b[39;49;00m],\n\u001b[1;32m    994\u001b[0m         alpha\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m[:, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnon_zero_genes]\u001b[39m.\u001b[39;49mvarm[\u001b[39m\"\u001b[39;49m\u001b[39mdispersions\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    995\u001b[0m     )\n\u001b[1;32m    996\u001b[0m     \u001b[39m# Take out the lowest likelihoods (highest neg) from the sum\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(nll[nll \u001b[39m<\u001b[39m np\u001b[39m.\u001b[39mquantile(nll, quant)])\n",
      "File \u001b[0;32m~/.venv/lib/python3.8/site-packages/pydeseq2/utils.py:329\u001b[0m, in \u001b[0;36mnb_nll\u001b[0;34m(counts, mu, alpha)\u001b[0m\n\u001b[1;32m    327\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(counts)\n\u001b[1;32m    328\u001b[0m alpha_neg1 \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m alpha\n\u001b[0;32m--> 329\u001b[0m logbinom \u001b[39m=\u001b[39m gammaln(counts \u001b[39m+\u001b[39;49m alpha_neg1) \u001b[39m-\u001b[39m gammaln(counts \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m gammaln(alpha_neg1)\n\u001b[1;32m    330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(alpha, \u001b[39m\"\u001b[39m\u001b[39m__len__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(alpha) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    332\u001b[0m         alpha_neg1 \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog(alpha)\n\u001b[1;32m    333\u001b[0m         \u001b[39m-\u001b[39m logbinom\n\u001b[1;32m    334\u001b[0m         \u001b[39m+\u001b[39m (counts \u001b[39m+\u001b[39m alpha_neg1) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog(mu \u001b[39m+\u001b[39m alpha_neg1)\n\u001b[1;32m    335\u001b[0m         \u001b[39m-\u001b[39m (counts \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlog(mu))\n\u001b[1;32m    336\u001b[0m     )\u001b[39m.\u001b[39msum(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "adata_train=sc.read(dataset_train)\n",
    "adata_test=sc.read(dataset_test)\n",
    "\n",
    "print(\"Starting preprocessing...\")\n",
    "train_dic = preprocess_deseq(adata_train, get_hvgs = True, scale_and_hvgs = True)\n",
    "test_dic = preprocess_deseq(adata_test)\n",
    "print(len(intersection(adata_train.var.index, adata_test.var.index)))\n",
    "list(adata_train.var.index)[0]\n",
    "\n",
    "col= [i for i in train_dic['hvg'].index]\n",
    "\n",
    "train_adata_pp =  train_dic['data']\n",
    "print(train_dic['hvg'])\n",
    "test_adata_pp =  test_dic['data'][:, intersection(col, test_dic['data'].var.index)]\n",
    "train_adata_pp = train_dic['data'][:, intersection(col, train_dic['data'].var.index)]\n",
    "\n",
    "train_df = train_adata_pp.to_df()\n",
    "test_df = test_adata_pp.to_df()\n",
    "\n",
    "## taking common genes\n",
    "print(\"Taking common genes...\")\n",
    "final_columns = list(set(train_df.columns).intersection(set(test_df.columns)))\n",
    "print('Common columns', len(final_columns))\n",
    "final_columns = [i for i in final_columns if i != 'celltype']\n",
    "train_df = train_df[final_columns]\n",
    "test_df = test_df[final_columns]\n",
    "\n",
    "y_train = train_adata_pp.obs.celltype.to_list()\n",
    "y_test = test_adata_pp.obs.celltype.to_list()\n",
    "\n",
    "X_train = train_df.to_numpy()\n",
    "X_test = test_df.to_numpy()\n",
    "\n",
    "labels = set(y_train)\n",
    "\n",
    "mapping = get_mapping(y_train)\n",
    "\n",
    "y_test = np.array(convert_y_to_mapping(y_test, mapping))\n",
    "\n",
    "y_train = np.array(convert_y_to_mapping(y_train, mapping))\n",
    "\n",
    "with open('dataset/np/X_train.pkl', 'wb') as fh:\n",
    "    pickle.dump(X_train, fh)\n",
    "\n",
    "with open('dataset/np/X_test.pkl', 'wb') as fh:\n",
    "    pickle.dump(X_test, fh)\n",
    "\n",
    "with open('dataset/np/y_test.pkl', 'wb') as fh:\n",
    "    pickle.dump(y_test, fh)\n",
    "\n",
    "with open('dataset/np/y_train.pkl', 'wb') as fh:\n",
    "    pickle.dump(y_train, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_y_train = train_adata_pp.obs.celltype.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/anunay18021/SingleCellClassification/flowgmm\n"
     ]
    }
   ],
   "source": [
    "%cd flowgmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.dpi'] = 300\n",
    "\n",
    "# from flow_ssl.realnvp.realnvp_toy import ToyRealNVP\n",
    "from flow_ssl.realnvp.realnvp import RealNVPTabular\n",
    "from flow_ssl.data import make_circles_ssl, make_moons_ssl, make_dataset_from_img, make_dataset_from_npz\n",
    "from flow_ssl.distributions import SSLGaussMixture\n",
    "from flow_ssl import FlowLoss\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_means(means_type, num_means=10, shape=(3, 32, 32), r=1, trainloader=None, device=None, net=None):\n",
    "\n",
    "    D = np.prod(shape)\n",
    "    means = torch.zeros((num_means, D)).to(device)\n",
    "\n",
    "    if means_type == \"pixel_const\":\n",
    "        for i in range(num_means):\n",
    "            means[i, :] = r * (i-4)\n",
    "\n",
    "    elif means_type == \"split_dims\":\n",
    "        mean_portion = D // num_means\n",
    "        for i in range(num_means):\n",
    "            means[i, i*mean_portion:(i+1)*mean_portion] = r\n",
    "\n",
    "    elif means_type == \"random\":\n",
    "        for i in range(num_means):\n",
    "            means[i] = r * torch.randn(D)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(means_type)\n",
    "\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../dataset/np/X_train.pkl', 'rb') as fh:\n",
    "    X_train = pickle.load(fh)\n",
    "\n",
    "with open('../dataset/np/X_test.pkl', 'rb') as fh:\n",
    "    X_test = pickle.load(fh)\n",
    "\n",
    "with open('../dataset/np/y_test.pkl', 'rb') as fh:\n",
    "    y_test = pickle.load(fh)\n",
    "\n",
    "with open('../dataset/np/y_train.pkl', 'rb') as fh:\n",
    "    y_train = pickle.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13}\n"
     ]
    }
   ],
   "source": [
    "print(set(list(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 3.5\n",
    "means = torch.tensor([[-r, -r], [r, r]])\n",
    "\n",
    "# r = 3.5\n",
    "# n_classes = 2\n",
    "means = get_means('random' , r=0.8*0.7, num_means=len(set(list(y_train))), trainloader=None, shape=(X_train.shape[1]), device=device).to(device)\n",
    "\n",
    "prior = SSLGaussMixture(means=means, device=device)\n",
    "\n",
    "\n",
    "flow = RealNVPTabular(num_coupling_layers=7, in_dim=X_train.shape[1], num_layers=3, hidden_dim=1024).to(device)\n",
    "loss_fn = FlowLoss(prior).to(device)\n",
    "# get_toy_nvp(D=2, prior=prior, device=None, inner_dim=256, coupling_layers_num=6, inner_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train\n",
    "labels = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_init = 2e-4\n",
    "epochs = 1500\n",
    "\n",
    "n_ul = np.sum(labels == -1)\n",
    "n_l = np.shape(labels)[0] - n_ul\n",
    "batch_size = n_l\n",
    "print_freq = 30\n",
    "\n",
    "labeled_data = data[labels != -1]\n",
    "labeled_labels = labels[labels != -1]\n",
    "unlabeled_data = data[labels == -1]\n",
    "unlabeled_labels = labels[labels == -1]\n",
    "\n",
    "optimizer = torch.optim.Adam([p for p in flow.parameters() if p.requires_grad==True], lr=lr_init,\n",
    "                             weight_decay=1e-2)\n",
    "step_size = 7500\n",
    "for t in range(epochs):\n",
    "    loss_total= []\n",
    "#     batch_idx = np.random.choice(n_ul, size=batch_size)\n",
    "#     batch_x, batch_y = unlabeled_data[batch_idx], unlabeled_labels[batch_idx]\n",
    "    for m in range(batch_size//step_size):\n",
    "      batch_x = labeled_data[m*step_size: (m + 1)*step_size]\n",
    "      batch_y = labeled_labels[m*step_size: (m + 1)*step_size]\n",
    "      batch_x, batch_y = torch.from_numpy(batch_x), torch.from_numpy(batch_y)\n",
    "      batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "      z = flow(batch_x).to(device)\n",
    "      sldj = flow.logdet().to(device)\n",
    "\n",
    "\n",
    "      loss = loss_fn(z, sldj, batch_y)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()#retain_graph=True)\n",
    "      optimizer.step()\n",
    "\n",
    "      loss_total.append(loss)\n",
    "\n",
    "      if t == int(epochs * 0.5) or t == int(epochs * 0.8):\n",
    "          for p in optimizer.param_groups:\n",
    "              p[\"lr\"] /= 10\n",
    "    if t % print_freq == 0:\n",
    "        print('iter %s:' % t, 'loss = %.3f' % float(sum(loss_total)/len(loss_total)),end=\"\\n\")\n",
    "    if t % (print_freq*10) == 0:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(flow.state_dict(), \"flow_baron_deseq.pt\")\n",
    "torch.save(loss_fn.state_dict(), \"loss_fn_baron_deseq.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.load_state_dict(torch.load(\"flow_baron_deseq.pt\"))\n",
    "loss_fn.load_state_dict(torch.load(\"loss_fn_baron_deseq.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = X_train, y_train\n",
    "# inv_list = []\n",
    "# for i in range(data.shape[0]//60000):\n",
    "#   inv_list.append(flow(torch.from_numpy(data[i*6000:(i+1)*6000]).to(device)).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = calculate_freq(y_train)\n",
    "print(freq)\n",
    "rev_mapping = {}\n",
    "for i in mapping:\n",
    "  rev_mapping[mapping[i]] = i\n",
    "print(rev_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_dist(X):\n",
    "    avg_dist = np.zeros((X.shape[0], ))\n",
    "    for i in range(X.shape[0]):\n",
    "        avg_dist[i] = np.mean(np.sqrt((X[i,0] - X[:,0])**2 + (X[i,1] - X[:,1])**2))\n",
    "    return avg_dist\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_to_generate(freq, generate_upper_limit):\n",
    "  samples_to_generate = {}\n",
    "  for i in freq:\n",
    "    if freq[i] >= generate_upper_limit:\n",
    "      continue\n",
    "    else:\n",
    "      samples_to_generate[i] = generate_upper_limit - freq[i]\n",
    "  return samples_to_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(freq, generate_upper_limit, true_labels, data, x_dist = True):\n",
    "  samples_to_generate = get_samples_to_generate(freq, generate_upper_limit)\n",
    "  zs = []\n",
    "  labels = []\n",
    "  for i in samples_to_generate:\n",
    "      z = loss_fn.prior.sample((samples_to_generate[i],), gaussian_id=i).cpu().numpy()\n",
    "      labels.extend([rev_mapping[i]]*samples_to_generate[i])\n",
    "      zs.append(z)\n",
    "  zs = np.concatenate( zs, axis=0 )\n",
    "  if x_dist:\n",
    "    zs = flow.inverse(torch.from_numpy(zs).cuda().float()).cpu().detach().numpy()\n",
    "  y_synthetic = true_labels + labels\n",
    "  data_synth = np.concatenate((data, zs), axis = 0)\n",
    "  return data_synth, y_synthetic\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(X, y):\n",
    "    dist = get_avg_dist(X)\n",
    "    mean = dist.mean()\n",
    "    std = dist.std()\n",
    "    index = np.where((mean - 3*std <= dist) & (mean + 3*std >= dist))\n",
    "    X_new = X[index, :][0,:,:]\n",
    "    Y_new = y[index]\n",
    "    z_adata_pp = sc.AnnData(X=X_new, obs={\"celltype\": Y_new})\n",
    "    z_adata_pp.obsm['X_tsne'] = X_new\n",
    "    return z_adata_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_data(X, labels, title):\n",
    "  z_adata_pp = sc.AnnData(X=X, obs={\"celltype\": np.array(labels)})\n",
    "  z_adata_pp.obsm['z_samples'] = X\n",
    "  sc.tl.tsne(z_adata_pp, use_rep= 'z_samples', random_state=0)\n",
    "  z_adata_pp = remove_outliers(z_adata_pp.obsm['X_tsne'], z_adata_pp.obs['celltype'].to_numpy())\n",
    "  with plt.rc_context({'figure.figsize': (5, 5)}):\n",
    "    sc.pl.tsne(z_adata_pp,\n",
    "               color='celltype',\n",
    "               add_outline=True,\n",
    "               legend_fontsize=14,\n",
    "               legend_fontoutline=2,\n",
    "               frameon=False,\n",
    "               title=title,\n",
    "               size = 50,\n",
    "               palette=\"tab20b\",\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data, generated_labels = generate_data(freq, 2000, train_adata_pp.obs.celltype.to_list(), data, True)\n",
    "plot_tsne_data(generated_data, generated_labels, \"TSNE deseq X space visualisation of X upscaled by data generated using NF, 2000 threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = flow(torch.from_numpy(data).to(device)).cpu().detach().numpy()\n",
    "generated_data, generated_labels = generate_data(freq, 2000, train_adata_pp.obs.celltype.to_list(), inv, False)\n",
    "plot_tsne_data(generated_data, generated_labels, \"TSNE deseq Z space visualisation of X upscaled by data generated using NF, 2000 threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data, generated_labels = generate_data(freq, 1000, train_adata_pp.obs.celltype.to_list(), data, True)\n",
    "plot_tsne_data(generated_data, generated_labels, \"TSNE deseq X space visualisation of X upscaled by data generated using NF, 1000 threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = flow(torch.from_numpy(data).to(device)).cpu().detach().numpy()\n",
    "generated_data, generated_labels = generate_data(freq, 1000, train_adata_pp.obs.celltype.to_list(), inv, False)\n",
    "plot_tsne_data(generated_data, generated_labels, \"TSNE deseq Z space visualisation of X upscaled by data generated using NF, 1000 threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data, generated_labels = generate_data(freq, 500, train_adata_pp.obs.celltype.to_list(), data, True)\n",
    "plot_tsne_data(generated_data, generated_labels, \"TSNE deseq X space visualisation of X upscaled by data generated using NF, 500 threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = flow(torch.from_numpy(data).to(device)).cpu().detach().numpy()\n",
    "generated_data, generated_labels = generate_data(freq, 500, train_adata_pp.obs.celltype.to_list(), inv, False)\n",
    "plot_tsne_data(generated_data, generated_labels, \"TSNE deseq Z space visualisation of X upscaled by data generated using NF, 500 threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data, generated_labels = generate_data(freq, 250, train_adata_pp.obs.celltype.to_list(), data, True)\n",
    "plot_tsne_data(generated_data, generated_labels, \"TSNE deseq X space visualisation of X upscaled by data generated using NF, 250 threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = flow(torch.from_numpy(data).to(device)).cpu().detach().numpy()\n",
    "generated_data, generated_labels = generate_data(freq, 250, train_adata_pp.obs.celltype.to_list(), inv, False)\n",
    "plot_tsne_data(generated_data, generated_labels, \"TSNE deseq Z space visualisation of X upscaled by data generated using NF, 250 threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data, generated_labels = generate_data(freq, 125, train_adata_pp.obs.celltype.to_list(), data, True)\n",
    "plot_tsne_data(generated_data, generated_labels, \"TSNE deseq X space visualisation of X upscaled by data generated using NF, 125 threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = flow(torch.from_numpy(data).to(device)).cpu().detach().numpy()\n",
    "generated_data, generated_labels = generate_data(freq, 125, train_adata_pp.obs.celltype.to_list(), inv, False)\n",
    "plot_tsne_data(generated_data, generated_labels, \"TSNE deseq Z space visualisation of X upscaled by data generated using NF, 125 threshold\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
