{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"gAHHs5T1xpkh"},"source":["# Feed Forward Neural Network "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nRJ9MX8tDYBO"},"source":["You need to have these three files to run all the cells in this notebook\n","1. ITClust train dataset\n","2. ITClust test dataset\n","3. FlowGMM codebase zip "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"p-_nnfyDDDxq"},"outputs":[],"source":["all_batches_file = '/home/anunay18021/SingleCellClassification/dataset/adata_pbmc_batches_raw.h5ad'"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n","/home/anunay18021/.venv/lib/python3.8/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n","/home/anunay18021/.venv/lib/python3.8/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n","/home/anunay18021/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.14.0 pynndescent==0.5.10\n"]},{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n"]}],"source":["# Call Libraries\n","import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","from torch import distributions\n","import sys\n","sys.path.insert(0, '')\n","from scripts.utils import *\n","import numpy as np\n","torch.manual_seed(0)\n","np.random.seed(0)\n","import scanpy as sc\n","sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n","sc.logging.print_header()\n","import os\n","from numpy.random import seed\n","# from tensorflow import set_random_seed\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","import pickle\n","import sys\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from pylab import rcParams\n","rcParams['figure.dpi'] = 100\n","\n","# from flow_ssl.realnvp.realnvp_toy import ToyRealNVP\n","from flow_ssl.realnvp.realnvp import RealNVPTabular\n","from flow_ssl.data import make_circles_ssl, make_moons_ssl, make_dataset_from_img, make_dataset_from_npz\n","from flow_ssl.distributions import SSLGaussMixture\n","from flow_ssl import FlowLoss\n","\n","from itertools import chain\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/anndata/_core/anndata.py:117: ImplicitModificationWarning: Transforming to str index.\n","  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n","  utils.warn_names_duplicates(\"var\")\n"]}],"source":["adata = sc.read(all_batches_file)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","____Create unique index____ \n","normalizing counts per cell\n","    finished (0:00:10)\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAgkAAAHmCAYAAAD5mB0yAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACNy0lEQVR4nOzde1zUVf4/8NdnBhxQYFBBR90BUcJbauqWeFkviYlpQSuIFwoULV2tzPUGkrcozS647ZrZLy5WKgQiGF0tFxUV3UxS0TDvbkKmJqPCDDh8fn/wnc/OwADDMAjI6/l4fB77uZxzPucz4zZvzjmfcwRRFEUQERERVSJr7AoQERFR08QggYiIiMxikEBERERmMUggIiIisxgkEBERkVkMEoiIiMgsBglERERkll1jV4Dun/Lycly9ehXOzs4QBKGxq0NERI1AFEXcvn0bnTt3hkxWc1sBg4QW5OrVq1Cr1Y1dDSIiagKuXLmCP/3pTzWmYZDQgjg7OwOo+Ifh4uJi8/K1Wi2mTp1q83Ib2vbt2+Hg4NDY1SAiui80Gg3UarX0m1ATBgktiKGLwcXFpUGChFatWsHOrvn9k3JxcWGQQEQtjiXdzs3vv+jULGwcHwSFvO7/vHT37mHe16kVZfgHQdFAQYdOfw/zvkptkLKJiB4UDBKoQSjkdnCws69fGXb1L4OIiKzHIIEsJooidDodAEChUPANiWaM3yURWYLzJJDFdDodAgICEBAQIP3AUPPE75KILNHigoTw8HAIgoA5c+ZUuTZv3jwIgoDw8HCT84cOHYJcLseECROq5Ll48SIEQUBubm6t937hhRcgl8uRkpIinRMEocZt1apVAICXXnoJgwYNgkKhwCOPPFKXRyYiIrJKiwsSAECtViMpKQklJSXSOa1Wi23btsHDw6NK+ri4OLz44ovYt28frl69atU9i4uLkZSUhCVLliA+Pl46X1BQIG0bNmyAi4uLyblFixZJaWfOnImQkBCr7k9ERFRXLXJMwsCBA3Hu3DmkpaVh+vTpAIC0tDR4eHjAy8vLJO2dO3eQnJyMH374AYWFhUhMTERUVFSd75mSkoLevXtj2bJl6Ny5M65cuQK1Wg2VSiWlUSqVEATB5JzBe++9BwD4/fffcfz48Trf3xZEUZT2tVptlevG54zTNkW1PcuDrjl9V0TUeFpkkABU/FWekJAgBQnx8fGYMWMGsrKyTNJ99tln6NmzJ3r06IHQ0FAsWLAAkZGRdR7oFRcXh9DQUCiVSowfPx6JiYl49dVXbfU4Zul0OpP+Zo1GU+/yDGpr0SjV6+HYhF9MKNXrpf2W3joTGBjY2FVoMI6OjiYthq1atUJpaalJGkEQpEDJeN+cadOmISwsTDp+/fXXsW/fPgDAiBEjMGbMGMTExCA6Ohq+vr7YsmULtm3bBplMhilTpmDbtm1V7mvoWhRFEaIoYtq0aejRowdiYmIQHByM5ORkAMCwYcOkewGQykxJSTGbzriuOTk5WL16NcrLy026M0NCQqR8ISEhSElJQXR0NABIzwEAa9asqbZsYzk5OVK9DWX5+vpW+3nm5ORIZa9YscLkvjXlM5fXOL3hc69cT2vqZ2l96svSe93POgEttLsBAEJDQ5GdnY1Lly7h0qVLOHDgAEJDQ6ukM/y4A4C/vz+Kioqwd+/eOt3rl19+QU5OjvRjFBoaioSEhAb/C27t2rVQKpXSximZqaUxDhAAVAkQANOWlNr+P5menm5ynJ2dbbKfkpKCsrIypKammqQvLy+vktdwL1EUUV5eLh2np6dL5aSnp0Ov10Ov15vcy7jM6tIZ3y8lJQXl5eUm99Pr9Sb5DGWlpqaaPEdKSkqNZRszrrfx51Ad47Ir37c2lfMaM9Svcj2tqZ+l9akvS+91P+sEtOCWBHd3d0yYMAGJiYkQRRETJkyAm5ubSZr8/HwcOXIEO3fuBADY2dkhJCQEcXFxGDVqlMX3io+Px7hx46Tyn3zySURERGDPnj0YM2aMzZ6pssjISCxcuFA6NkzFaS2FQiHtJycnV5mlUKvVSoFQK7nc6vvcD8b1M/csDzrj7+pBZuuWhMqtLsOHD5f+uh8+fDjGjBmD/Px8BAUFSekNLQmG/cr3rdySEBgYiB49eiA/Px+BgYE1tiQEBgYiJSXFbDrjugYHB+PUqVNVWhKM8xnKMtTd+DlOnz5dbdnGgoODpXobl1Wd4OBgqWxz961rXgPDZ125ntbUz9L61Jel97qfdQIAQWxhHZLh4eG4desW0tPT8cUXX2D+/PkAgI0bN+LJJ59EYGAgXF1dkZiYiCVLluCtt96C3OgHRRRFKBQKFBQUQKlU4uLFi/Dy8sKxY8fMvnWg1+uhVqtRWFhostqWXq/HtGnTsHXrVulcYmIiFixYgFu3blVb/1WrViE9Pd2itykq02g0UCqVKCoqsmpaZq1Wi4CAAABARkaG2SDBcP2jiVOsmghJe68MszKT6lVGXe9j7lkedLV9l0T04KrLb0GLbUkAKroPSktLIQgCxo0bZ3Lt3r17+Pjjj/HOO+/giSeeMLkWGBiI7du3m32NsrIvv/wSt2/fxrFjx0yCjZMnT2LGjBm4desWXF1dbfI8REREttSigwS5XC41V8krNY9nZmbijz/+QEREBJRKpcm1SZMmIS4uziRIyM/Pr1J+nz59EBcXhwkTJqB///4m13r37o1XXnkFW7duxbx582qt69mzZ3Hnzh0UFhaipKREakno3bs3WrVqZdHzEhER1UWLDhIAVNvUEhcXBz8/vyoBAlARJKxfvx7Hjx+X8k+ZMqVKuosXL+KLL74w6Yc0kMlkeOaZZxAXF2dRkDBr1iyTAZMDBgwAAFy4cAFdu3atNb8tKBQKZGRkSPvUfPG7JCJLtLggITExscbr1Y3aNfbYY49ZPCK6rKys2mvvv/++yXF4eHiV2R4NKr+a2RgEQbC471qnv2fVPXT37pndtzVr6/egqMt3SUQtV4sLEuj+sMUyzIYlo4mIqHG02HkSiIiIqGZsSSCbMe7ntlZjLGHMPnkiIvMYJJDN2Kqf29HR0Qa1ISKi+mKQQDZh3AJQ+bimFoH71VpARER1xyCBbEKn00kz+NUFZ/sjImq6OHCRiIiIzGJLAtncP8cPBkTgxa8PVxz7D4bC7n8zWur0erz41eHGqh4REVmIQQJZzOJxBpWmuFbYyU2ChPtRByIiqj92N5DFDOMOAgICTAYptrQ6EBG1FAwSGkB4eLjJmu3t27eHv78/jh8/DqBiTYeIiAh4eXnB0dER3bt3x8qVK03Wuc/KyoIgCGjbti20Wq1J+f/5z3+ksomIiBoKg4QG4u/vj4KCAhQUFOD777+HnZ0dJk6cCAD4+eefUV5ejs2bNyMvLw+xsbH44IMPEBUVVaUcZ2dn7Ny50+RcXFwcPDw87stzEBFRy8UxCQ1EoVBApVIBAFQqFZYtW4a//OUv+P333+Hv7w9/f38pbbdu3ZCfn49Nmzbh7bffNiknLCwM8fHxmDp1KgCgpKQESUlJeOmll/Daa6/dvweC6UJWlVs3jI9FUayxlaOmcmpT+T5ERNRwGCTcB3fu3MGnn34Kb29vtG/f3myaoqIitGvXrsr5Z599Fm+99RYuX74MDw8P7NixA127dsXAgQNrva9OpzPpt9doNNY/xP+VZxASElJtulJ9eY0DFUv15RaVU5vAwECr894PHh4e+O9//4vy8nLIZDKsXLkSvr6+yMnJQUxMDKKjo+Hr64stW7Zg27ZtGDFiBA4dOiSdr8w4HwCTMnJycrBmzRopQFuxYkWtZZi73hDqcs/GqJ+tPQjPQGTA7oYGkpmZCScnJzg5OcHZ2Rm7du1CcnIyZLKqH/nZs2fxz3/+Ey+88EKVax06dMD48eOlJa7j4+Mxc+ZMi+qwdu1aKJVKaVOr1fV6Jqqby5cvo7y8IiAqLy9HamrFqpYpKSkoKyuTjg3Lk2dnZ5ucr8w4X+UyUlJSoNfrUV5eDr1eb1EZ90td7tkY9bO1B+EZiAzYktBARo8ejU2bNgEA/vjjD7z//vsYP348jhw5Ak9PTyndr7/+Cn9/fwQHB2P27Nlmy5o5cyZefvllhIaG4tChQ0hJScH+/ftrrUNkZCQWLlwoHWs0mnoFCsYLISUnJ5vMlKjVaqVWgVbymmNP4+uVy6mN8X2ausotCUFBQQCA4OBg5OfnS8eBgYHYtm0bhg8fjkOHDknnK6ucz3g/ODgYp0+flloSLC3jfqjLPRujfrb2IDwDkYEgsmPX5sLDw3Hr1i3pL0QA0Ov1UCqVWLBgAWJiYgAAV69exahRo+Dr64vExESTVoasrCyMHj0af/zxB5ycnKBWq9GzZ0+4u7vjs88+Q3p6Op555pk69ctrNBoolUoUFRXBxcWlzs+l1WqlqZcrT6dsfO3DiUMBAM9nHpSOTSZTuqeXrtV1Wuaa6kBERLWry28BuxvuE0EQIJPJUFJSAqCiBWHUqFEYNGgQEhISzHZDGNjZ2eG5555DVlaWxV0NRERE9cXuhgai0+lQWFgIoKK74V//+hfu3LmDp556SgoQPD098fbbb+P333+X8hneiKjstddew+LFi6sd+EhERGRrDBIayNdff41OnToBqJjroGfPnkhJScGoUaOQmJiIs2fP4uzZs/jTn/5kkq+67oNWrVrBzc2twetdE4VCgYyMDGm/pdaBiKilYJDQABITE6W3EcwJDw9HeHh4jWWMGjWqxvEGgYGB932eAEEQLBoDoNPrAaOq6e7pq15v4DoQEVH9MUggm6u8wqNhNUgiImpeOHCRiIiIzGJLAtmE8VgBoA7LSnNcARFRk8UggWzC3FgBR0fHRqoNERHZAoMEqjfjVgNLWhBqalkgIqKmg0EC1ZtOp5NmQbQEZ0okImoeOHCRiIiIzGJLAtnUijGtsOb7UgBAzBOt0MquoluhVA9Ef6OrKSsRETUxDBLIYpaMN2glN9q3E6CwM6Sp+8RPlr4hQUREDYPdDWQxw9iDgIAA6cf7QbofERGZahFBgiAINW6rVq3CxYsXIQgC5HI5fv31V5P8BQUFsLOzgyAIuHjxonR+586d8PX1hVKphLOzM/r06YMFCxZI1xMTE03u4+TkhEGDBiEtLa3aus6ZMweCIGDDhg3SuZ9++gmtWrXCrl27TNLu2LEDDg4OOHnyZL0+HyIiInNaRJBQUFAgbRs2bICLi4vJuUWLFklpu3Tpgo8//tgk/5YtW9ClSxeTc99//z1CQkIwadIkHDlyBEePHsXrr7+OsrIyk3TG9zp27BjGjRuHyZMnIz8/v0o9d+7ciZycHHTu3NnkfP/+/bFixQo8//zzuHHjBgDg2rVrmDNnDlavXo2HH364Xp8PERGROS0iSFCpVNKmVCohCILJOScnJyltWFgYEhISTPInJCQgLCzM5Nznn3+OYcOGYfHixejRowd8fHwQGBiIjRs3mqQzvtdDDz2EmJgYyGQyHD9+3CTdr7/+ihdffBFbt26Fvb19lWeIjIyEh4cH5s2bBwB44YUX8NBDD5kEOA3NeEEprVZrsplLY2nemrbayiUioobDgYuVPP300/jggw+QnZ2N4cOHIzs7G3/88QeeeuopvPbaa1I6lUqFbdu24eTJkxb/Ja/X66VWioEDB0rny8vL8eyzz2Lx4sXo06eP2bxyuRxbtmzBwIEDMW3aNHzzzTfIzc2FXC43mx6o6NM37svXaDQW1bOm8gxCQkLMpimrZoFH4/PV5a1JYGBgnfOQ7bm5ueH69evVXu/Tpw/y8vIwYsQIHDhwAOXl5RYFeH369MG7776LnJwcrFq1CqIomtxLLpcjJCQEycnJACr+DSUlJaG8vNyknGnTpiEsLAw5OTmIiYlBcHAwkpOTIYoiBEHAihUrAAAxMTEYMmQI9u3bZ5K3R48eiImJQXR0NHx9fU3K3rJlC7Zt2waZTIaVK1dK5RjSGq4bnh2Ayf3MlVlZTk4O1qxZI+WtnN7wXNHR0SblVrdf2/0sZXxfX19fk883JSXFpvcyd7/7pSHv21jPVF8toiWhLuzt7REaGor4+HgAQHx8PEJDQ6v8df/iiy/i0UcfRd++fdG1a1dMmTIF8fHxVQbYFRUVwcnJCU5OTmjVqhXmzp2LDz/8EN27d5fSvPnmm7Czs8NLL71UY9169eqFBQsWYPv27Vi1ahV8fHxqTL927VoolUppU6vVdfkoiKqoKUAAgLy8PABAdnY29Hq9xS1AhnwpKSlSHuN76fV6pKenQ6/XS/uVAwQASE9Pl8opKyuT8pSXl0Ov1yM1NVW6lp2dXSWv4Vpqamq1ZZeXl5uUY0hruG549sr3M1dmZSkpKSZ5zV03lGXJvq1ULtP487X1vczd735pyPs21jPVF4MEM2bOnImUlBQUFhYiJSUFM2fOrJKmTZs2+OKLL3D27FlER0fDyckJf//73/HYY4+huLhYSufs7Izc3Fzk5ubi2LFjeOONNzBnzhx8/vnnAICjR4/iH//4hzTIsSZ37txBcnIyWrdujf3799f6HJGRkSgqKpK2K1eu1PGTMGW8GFNycjIyMjKQkZEh/XUHAPbVNGwYnzfOW9NmXC41DW5ubjVeN7SEDR8+HHK53OLXVg35goODpTzG95LL5QgMDIRcLpf2ZbKq//kytDgFBwfD3t5eyiOTySCXyxEUFCRdGz58eJW8hmtBQUHVli2TyUzKMaQ1XDc8e+X7mSuzsuDgYJO85q4byrJk31Yql2n8+dr6Xubud7805H0b65nqSxBbWGdvYmIiFixYgFu3bpmcv3jxIry8vHDs2DE88sgjePTRR+Hk5IS7d+/iyJEjyM3NxYABA3DhwgV07drVbNkXLlyAj48PPvzwQ8yYMaPae/n7++POnTvIzs7Ghg0bsHDhQpP/4On1eshkMqjVapO3KebOnYu9e/di+/bt8PX1xebNm/Hcc89Z/OwajQZKpRJFRUVwcXGxOJ+BVquVpl82nlrZ+HzME60Q/W3FZErrn1RI8yTo7olY8qWuSl5r7kdERNary28BWxKqMXPmTGRlZZltRahO165d0bp1a9y9e7fGdHK5HCUlJQCAZ599FsePH5daG3Jzc9G5c2csXrwY33zzjZRn9+7d+Oijj7Blyxb0798fMTExWLBgAQoKCqx7QCIiolpw4GI1Zs+ejeDgYLi6upq9vmrVKhQXF+PJJ5+Ep6cnbt26hffeew9lZWUYO3aslE4URRQWFgIASkpKsHv3bnzzzTfSgKb27dujffv2JmXb29tDpVKhR48eACqivoiICCxevBiPPvooAOCVV17Bzp078fzzz0tdF0RERLbEIKEadnZ2Nfa/jhw5Ehs3bsRzzz2H3377DW3btsWAAQPw7bffSj/uQMUPfKdOnQBU9Ol7enpizZo1WLp0qcV1WbBgAZRKJVatWiWdk8lkSEhIwCOPPIKPP/64Tt0O1lIoFMjIyJD2H7T7ERGRqRY3JqElq++YhOo01JgEIiKyvbr8FrAlgWyq1Gg+hNJ7otnzRETUPDBIIJsyLBMNQGpRICKi5olvNxAREZFZbEmgejMeYCiKojTrpEKhMDuZDgchEhE1D2xJIJsSBEEKAnQ6XZVpeasLHIiIqOlhSwLVm06nk95uqA3fbCAiaj7YkkBERERmMUggm3ppohwvTZQZHcvw0sTql7MmIqKmi90NZDFLBiXa2wGAYHRs+fgDS8onIqL7hy0JZDHD2IOAgADpx7w5lU9ERHXDIIGIiIjMatFBQnh4OARBqLL5+/sDqFj62dz1devWAQAuXrxo9npoaKh0j5deegmDBg2CQqHAI488UmN9evbsCYVCIa0aaSwtLQ1PPPEE2rdvD0EQkJuba7PPgYiIyJwWPybB398fCQkJJueMJ/tZs2YNZs+ebXLd2dnZ5Pi7775Dnz59pGNHR0eT6zNnzsThw4dx/PjxauuRnZ2NkpISBAUFYcuWLVVWibx79y6GDx+OyZMnV6nP/WI854FWqzW7L4pilbEE1eWrrHI5RETUuFp8kKBQKKBSqaq97uzsXON1AGjfvn21ad577z0AwO+//15jkBAXF4dp06Zh5MiRePnll6sECc8++yyAitYLS+l0OpO+fY1GY3He6sozCAkJMZvmnt4weNH0XG35KgsMDKxr9QAAHh4euHLlikmQIZPJMHz4cOzbtw+CIEAmk2HFihXw9fVFTk4OYmJiEB0dDV9fX6vuSUT0oGrR3Q1Nxe3bt5GSkoLQ0FCMHTsWRUVF2L9/f73LXbt2LZRKpbSp1Wob1LZpu3z5cpVWiPLycmRnZwOoaKHQ6/VITU0FAKSkpKCsrEw6JiKi/2nxLQmZmZlwcnIyORcVFYWoqCgAwNKlSxEdHW1y/auvvsJf/vIX6Xjo0KGQyf4Xb+3fvx8DBgywuA5JSUl46KGHpC6LKVOmIC4uzuQe1oiMjMTChQulY41GU69AwbgbJjk5WZo5UavVSi0EdmamRDA+Z5yvMuNyrGVpS0JQUBAAIDg4GPn5+dIxERH9T4sPEkaPHo1NmzaZnGvXrp20v3jxYoSHh5tc79Kli8lxcnIyevXqJR3X9Yc4Pj7eZLBjaGgoRo4ciX/+859Vxj/UhUKhsOliSsZjDRwcHMz+2Jub28CSfJU1xPTNy5cvr3LO19cXmZmZNr0PEdGDosUHCW3atIG3t3e1193c3Gq8DlQEBbWlqc6pU6eQk5ODI0eOmIxD0Ov1SEpKarRBikRERByT0Mji4uIwYsQI/PTTT8jNzZW2hQsXIi4urrGrR0RELViLb0nQ6XRV5iWws7ODm5sbgIpBhZWvt27dGi4uLhaVf/bsWdy5cweFhYUoKSmR5jfo3bs3BEHAJ598gjVr1uDhhx82yTdr1iy8++67yMvLQ58+fXDz5k1cvnwZV69eBQDk5+cDAFQqVa1vXxAREVmjxQcJX3/9NTp16mRyrkePHvj5558BACtWrMCKFStMrr/wwgv44IMPLCp/1qxZ2Lt3r3RsGNB44cIFHD16FDdu3MAzzzxTJV+vXr3Qq1cvxMXF4d1338WuXbswY8YM6fqUKVMAACtXrsSqVassqkt9KRQKZGRkSPvNrXwiIqobQeSsNS2GRqOBUqlEUVGRxS0hltBqtQgICACA/1vxUcR7meX/dywDIOC9zIrJEhpiQCIREVmuLr8FLb4lgWzLEAz877i8kWpCRET1xYGLREREZBZbEqjejMcSABWzGhqmcFYoFCbzJHCsARFR88EggerFOCCoLTgwN9ESERE1XQwSqF50Op00aLEmHLBIRNT8cEwCERERmcUggWxmysT/7U8PBEIDG6smRERkC+xuIIvVNOYAAORG/5rsrfiXVVv5RER0f7ElgSxmGH8QEBAg/Zg3p/KJiKhuGCQQERGRWS02SAgPD4cgCJgzZ06Va/PmzYMgCFKamrbq1k3QaDRYvnw5evbsCQcHB6hUKvj5+SEtLQ3GM2Hn5eVh8uTJcHd3h0KhgI+PD1asWIHi4mKT8j788EOMGjUKLi4uEAQBt27dsuXHQUREVEWLDRIAQK1WIykpCSUlJdI5rVaLbdu2wcPDAwBQUFAgbRs2bICLi4vJuUWLFlUp99atWxg6dCg+/vhjREZG4scff8S+ffsQEhKCJUuWoKioCACQk5ODwYMHo7S0FF988QXOnDmD119/HYmJiRg7dixKS0ulMouLi+Hv74+oqKgG/lSIiIgqtOiBiwMHDsS5c+eQlpaG6dOnAwDS0tLg4eEBLy8vADBZhlmpVEIQhFqXZo6KisLFixdx5swZdO7cWTrv4+ODqVOnwsHBAaIoIiIiAr169UJaWhpksop4zdPTEz4+PhgwYABiY2OxdOlSAMCCBQsAAFlZWbZ6/DozbgHRarUm/1txvXJ6VElfE9OyuO4YEVFja9FBAgDMnDkTCQkJUpAQHx+PGTNmWP1jXF5ejqSkJEyfPt0kQDBwcnICABw7dgynTp3Ctm3bpADBoH///vDz88P27dulIMEaOp3OZACgRqOxuixDeQYhISFVrutN13bCPaNjc+lrEhgYWKf0TdW0adPQo0cPrF69GuXl5Zg2bRrCwsKk6zk5OYiJiUF0dDR8fX2l4yFDhmDfvn1S+pycHKxZswaiKEIQBGn5cuO8ljC+nzX5ayrP2jKIqOlq0d0NABAaGors7GxcunQJly5dwoEDBxAaGmp1edevX8cff/yBnj171pjuzJkzAIBevXqZvd6rVy8pjbXWrl0LpVIpbWq1ul7lUd2lp6cjJSUF5eXl0rGxlJQUlJWVITU11eQ4OzvbJH1KSgr0ej3Ky8uh1+uRmppaJa8ljPNYk7+m8ojowdPiWxLc3d0xYcIEJCYmQhRFTJgwAW5ubhblvXz5Mnr37i0dR0VFISIiok73b8hm9cjISCxcuFA61mg09QoUjBdnSk5OhoODA7RardRKIJebprczOjakr4lxWQ+KwMBA9OjRA6dOnUJ5eXmVFpLg4GDk5+cjKCjI5NjQkmBIHxwcjNOnT0stCYb0xnktUfl+dc1fW3lE9GBp8UECUNHlMH/+fADAxo0bLc7XuXNn5ObmSsft2rWDq6srXF1d8fPPP9eY18fHBwBw+vRpDBgwoMr106dPS2mspVAobLrqovHkRg4ODlV+9CvPfWR8bC59TR60tR6++uors+d9fX2RmZlp9nj58uUm57/88ssq+Y3zWqLy/eqav7byiOjB0uK7GwDA398fpaWlKCsrw7hx4yzOZ2dnB29vb2lr164dZDIZpkyZgq1bt+Lq1atV8ty5cwf37t3DI488gp49eyI2NlZqijb46aef8N1332Hq1Kn1fjYiIiJrMUgAIJfLcfr0aZw6dQryym3mVnj99dehVqsxePBgfPzxxzh16hR++eUXxMfHY8CAAbhz5w4EQUBcXBxOnTqFSZMm4ciRI7h8+TJSUlLw1FNPYciQIdIbDQBQWFiI3NxcnD17FgBw4sQJ5Obm4ubNm/WuLxERkTnsbvg/Li4uNiurXbt2yMnJwbp16xATE4NLly6hbdu26Nu3L9566y0olUoAwNChQ5GTk4PVq1dj/PjxuH37Njw8PBAWFobIyEiTroIPPvgAq1evlo5HjBgBAEhISEB4eLjN6l4ThUKBjIwMab+5lU9ERHUjiHwhvcXQaDRQKpUoKiqyWVCk1WoREBAAoGIVyKT/656eHggIAD5Nrzh+0MYYEBE1V3X5LWBLAtlMktH4ta3pjVYNIiKyEY5JICIiIrPYkkD1YjyOQBRFaVZGhUJh8sokxxgQETU/bEkgmxEEQQoGdDqdyURRlY+JiKjpY0sC1YtOp5MGLtaGgxeJiJoXtiQQERGRWQwSyGaeDKrYqjsmIqLmhd0NZLGaBiYCgF2lf02Vj211HyIiuj/YkkAWM4w/CAgIkH7Em/N9iIioZgwSiIiIyCwGCTUIDw+HIAgQBAH29vbw8vLCkiVLoNVqpTSG64IgQKlUYtiwYdizZ490/ffff8fcuXPh4eEBhUIBlUqFcePG4cCBAwCAmzdv4sUXX0SPHj3g6OgIDw8PvPTSSygqKpLKSExMNLmP8Xbt2rX794EQEVGLwjEJtfD390dCQgLKyspw9OhRhIWFQRAEvPnmm1KahIQE+Pv74/r161i+fDkmTpyIkydPolu3bpg0aRJKS0uxZcsWdOvWDb/99hu+//573LhxAwBw9epVXL16FW+//TZ69+6NS5cuYc6cObh69SpSU1MBACEhIfD39zepV3h4OLRaLTp06HD/PgwiImpRGCTUwvDXPwCo1Wr4+flh9+7dJkGCq6srVCoVVCoVNm3ahC5dumD37t0ICQnB/v37kZWVhZEjRwIAPD098dhjj0l5H374YezYsUM67t69O15//XWEhobi3r17sLOzg6OjIxwdHaU0v//+O/bs2YO4uLiGfnwTxpMhGVpTjFtVRBGoPMbQeP4k47Q1MS2TEzARETUWBgl1cPLkSRw8eBCenp7VpjH8mJeWlsLJyQlOTk5IT0+Hr6+vxVMTG1bmsqvm9YCPP/4YrVu3RlBQze8X6nQ6k4F/Go3GovvXVJ5BSEhIlet6fdU3GvT6/+2by1ObwMDAOqXv06cPzpw5g+joaPj6+la5npOTg5iYmGqv15WtyyMiako4JqEWmZmZcHJygoODA/r27Ytr165h8eLFZtMWFxcjOjoacrkcI0eOhJ2dHRITE7Flyxa4urpi2LBhiIqKwvHjx6u93/Xr1/Haa6/h+eefrzZNXFwcpk2bZtK6YM7atWuhVCqlTa1WW/bQzVheXh7KysqkrprKUlJSarxeV7Yuj4ioKWFLQi1Gjx6NTZs24e7du4iNjYWdnR0mTZpkkmbq1KmQy+UoKSmBu7s74uLi0K9fPwDApEmTMGHCBOzfvx85OTn46quvsH79enz00UcIDw83KUej0WDChAno3bs3Vq1aZbY+hw4dwunTp/HJJ5/UWvfIyEgsXLjQpPz6BArGLSHJyclwcHCAVquVWgjk8qp5jM8Z8tTGuMy6MrQkVNfKEhwcjPz8/FpbYSxl6/KIiJoSBgm1aNOmDby9vQEA8fHx6N+/P+Li4hARESGliY2NhZ+fH5RKJdzd3auU4eDggLFjx2Ls2LF49dVXMWvWLKxcudIkSLh9+zb8/f3h7OyMnTt3wt7e3mx9PvroIzzyyCMYNGhQrXVXKBQ2XX3ReFIjBweHKj/45uY8Mj5nLk9tbL3eg6+vLzIzM5tseURETQm7G+pAJpMhKioK0dHRKCkpkc6rVCp4e3ubDRDM6d27N+7evSsdazQaPPHEE2jVqhV27dpV7Y/inTt38Nlnn5kEKERERA2FQUIdBQcHQy6XY+PGjbWmvXHjBh5//HF8+umnOH78OC5cuICUlBSsX79eWjnRECDcvXsXcXFx0Gg0KCwsRGFhIfTGo/5Q0Vx/7949hIaGNsizERERGWN3Qx3Z2dlh/vz5WL9+PebOnVtjWicnJwwePBixsbE4d+4cysrKoFarMXv2bERFRQEAfvzxRxw+fBgApG4NgwsXLqBr167ScVxcHP7617/C1dXVps9kKYVCgYyMDGm/ud+HiIhqJoh8Eb3F0Gg0UCqV0iuWtqDVaqVWEcOKj1/+30D/yse2Hl9ARER1V5ffArYkkM18mVrzMRERNS8ck0BERERmsSWB6sV4/ABQMY2yYWZGhUJh8tokxxcQETUvDBLIaoaAoHJgYDzuoHKgQEREzQeDBLKaTqeTBi1Wh4MViYiaL45JICIiIrMYJJBNDZoK/HlaY9eCiIhsgd0NZFNy80tOEBFRM8QggSxWeYCircvjAEcioqaFQQJZzHigovFrj7YqjwMciYialhY7JiE8PByCIGDOnDlVrs2bNw+CIEhpatpWrVpltnyNRoPly5ejZ8+ecHBwgEqlgp+fH9LS0mA8E3ZeXh4mT54Md3d3KBQK+Pj4YMWKFSguLjYp74UXXkD37t3h6OgId3d3BAQE4Oeff7bpZ0JERGSsxQYJAKBWq5GUlGSy7LNWq8W2bdvg4eEBACgoKJC2DRs2wMXFxeTcokWLqpR769YtDB06FB9//DEiIyPx448/Yt++fQgJCcGSJUtQVFQEAMjJycHgwYNRWlqKL774AmfOnMHrr7+OxMREjB07FqWlpVKZgwYNQkJCAk6fPo1vvvkGoijiiSeeqLJSJBERka206O6GgQMH4ty5c0hLS8P06dMBAGlpafDw8ICXlxcAQKVSSemVSiUEQTA5Z05UVBQuXryIM2fOoHPnztJ5Hx8fTJ06FQ4ODhBFEREREejVqxfS0tIgk1XEa56envDx8cGAAQMQGxuLpUuXAgCef/55qZyuXbsiJiYG/fv3x8WLF9G9e3fbfCC1MG4B0Wq1NaSDRemMr3GdMSKipqdFBwkAMHPmTCQkJEhBQnx8PGbMmIGsrCyryisvL0dSUhKmT59uEiAYODk5AQCOHTuGU6dOYdu2bVKAYNC/f3/4+flh+/btUpBg7O7du0hISICXlxfUanW1ddHpdNLAQKCiC6Q+jMsKCQmpNl35PViUzlhgYKC11WoUHh4euHz5MmQyGaZMmYJt27ZJ12QyGURRhCiKUreU4dhAEATIZDIMGzYM+/btq1L+tGnTEBYWBqCixWnNmjUAgBUrVgAAYmJiEB0dDV9fX+Tk5JgcGzN3zdJzREQtursBAEJDQ5GdnY1Lly7h0qVLOHDgAEJDQ60u7/r16/jjjz/Qs2fPGtOdOXMGANCrVy+z13v16iWlMXj//ffh5OQEJycnfPXVV9i9ezdatWpV7T3Wrl0LpVIpbTUFFFQ3ly9fBlARFKanp5tcKy8vlwICURRNjg1EUYRer0d2drbZ8o3LTElJgV6vh16vR2pqKlJSUlBWVobU1FTpuvGxMXPXLD1HRNTigwR3d3dMmDABiYmJSEhIwIQJE+Dm5mZR3suXL0s/2k5OTnjjjTfq3Gxel/TTp0/HsWPHsHfvXvj4+GDy5Mk1NudHRkaiqKhI2q5cuVKnulVm/NpjcnIykpOTzaaTGbVPJScnIyMjw+xWXf7mwDBmRSaTVWkFkclk0uuchhaDyq93CoIAuVyO4cOHmy3fuMzg4GDI5XLI5XIEBQUhODgY9vb2CAoKkq4bHxszd83Sc0RELb67Aajocpg/fz4AYOPGjRbn69y5M3Jzc6Xjdu3awdXVFa6urrW+eeDj4wMAOH36NAYMGFDl+unTp6U0BoYWgYceegi+vr5o27Ytdu7cialTp5q9h0KhsOnKi8Y/dDW9rmj8e+jg4GDRq43N/RVIQ9eANZYvX17jdV9fX3z55Zcm5zIzM02uGx9Xzlv5mqXniIhafEsCAPj7+6O0tBRlZWUYN26cxfns7Ozg7e0tbe3atZP6qLdu3YqrV69WyXPnzh3cu3cPjzzyCHr27InY2FiUl5ebpPnpp5/w3XffVfvjD0Dq4zYeJ0BERGRLDBIAyOVynD59GqdOnYJcLq93ea+//jrUajUGDx6Mjz/+GKdOncIvv/yC+Ph4DBgwAHfu3IEgCIiLi8OpU6cwadIkHDlyBJcvX0ZKSgqeeuopDBkyBAsWLAAAnD9/HmvXrsXRo0dx+fJlHDx4EMHBwXB0dMSTTz5Z7/oSERGZw+6G/+Pi4mKzstq1a4ecnBysW7cOMTExuHTpEtq2bYu+ffvirbfeglKpBAAMHToUOTk5WL16NcaPH4/bt2/Dw8MDYWFhiIyMlLoKHBwcsH//fmzYsAF//PEHOnbsiBEjRuDgwYPo0KGDzepdG4VCIc20qFAo6t2KUbk8IiJqWgSRL6i3GBqNBkqlEkVFRTYJirRarTStssGgqRVjEn74vzcCm/tYAyKiB01dfgvYkkA2dXR7Y9eAiIhshWMSiIiIyCy2JJDVDGMKalrymWMNiIiaLwYJZDVBEKTxBo6Ojo1cGyIisjUGCWQVQ+tBba0IlWcaJCKi5oNBAllFp9NVebOhMr7ZQETUvHHgIhEREZnFIIFsJ7w1hPDWjV0LIiKyEXY3kMWMxx+Ym4NLsLds/EFN4xiIiKjpYEsCWcwwDiEgIKBeUzLbqhwiImpYLTZICA8PhyAImDNnTpVr8+bNgyAIUpqatlWrVpktX6PRYPny5ejZsyccHBygUqng5+eHtLQ0k7/C8/LyMHnyZLi7u0OhUMDHxwcrVqxAcXGxlObmzZt48cUX0aNHDzg6OsLDwwMvvfQSioqKbP65EBERGbTo7ga1Wo2kpCTExsZK7/lrtVps27YNHh4eAICCggIpfXJyMlasWIH8/HzpnJOTU5Vyb926heHDh6OoqAgxMTF49NFHYWdnh71792LJkiV4/PHH4erqipycHPj5+cHPzw9ffPEFOnbsiCNHjuDvf/87vv/+e/z73/9Gq1atcPXqVVy9ehVvv/02evfujUuXLmHOnDm4evUqUlNTG/hTIiKilqpFBwkDBw7EuXPnkJaWhunTpwMA0tLS4OHhAS8vLwCASqWS0iuVSgiCYHLOnKioKFy8eBFnzpxB586dpfM+Pj6YOnUqHBwcIIoiIiIi0KtXL6SlpUEmq2jU8fT0hI+PDwYMGIDY2FgsXboUDz/8MHbs2CGV0717d7z++usIDQ3FvXv3YGd3f75G4xYQrVZrdRrj81xfjIio6WrRQQIAzJw5EwkJCVKQEB8fjxkzZiArK8uq8srLy5GUlITp06ebBAgGhpaHY8eO4dSpU9i2bZsUIBj0798ffn5+2L59O5YuXWr2PobVu2oKEHQ6nUmfv0ajseaRTMozCAsLM5/o3v92Q0JCai0zMDCwXnVqDG5ubrh+/brZc4ZuKKBiRsqePXsiLy8PACCTybBy5Urk5+dL3/vKlSvh6+uLnJwcxMTEIDo62uzx/dbY9yeipqHFjkkwCA0NRXZ2Ni5duoRLly7hwIEDCA0Ntbq869ev448//kDPnj1rTHfmzBkAQK9evcxe79Wrl5TG3D1ee+01PP/88zXeY+3atVAqldKmVqsteAKqTeUAwficKIooLy9HeXk59Hq9FCAAFQFkamoq0tPTTY4BICUlBWVlZdUe32+NfX8iahpafJDg7u6OCRMmIDExEQkJCZgwYQLc3Nwsynv58mU4OTlJ2xtvvFHn5vO6ptdoNJgwYQJ69+5d7aBJg8jISBQVFUnblStX6nSvyowXa9qyZYv5REYNG8nJycjIyKiyJScn16sejc3cvw/DOUEQIJPJIJPJIJfL0adPHymNTCZDUFCQ1HpiOAaA4OBg2NvbV3t8vzX2/YmoaWjx3Q1ARZfD/PnzAQAbN260OF/nzp2Rm5srHbdr1w6urq5wdXXFzz//XGNeHx8fAMDp06cxYMCAKtdPnz4tpTG4ffs2/P394ezsjJ07d8Le3r7GeygUCpuuwmg8n0F10y0LggDRKE1t0zK3xKmbfX19q3TX+Pr6IjMzs9rj+62x709ETUOLb0kAAH9/f5SWlqKsrAzjxo2zOJ+dnR28vb2lrV27dpDJZJgyZQq2bt2Kq1evVslz584d3Lt3D4888gh69uyJ2NhYlJeXm6T56aef8N1332Hq1KnSOY1GgyeeeAKtWrXCrl27WtwPKxER3X8MEgDI5XKcPn0ap06dglwur3d5r7/+OtRqNQYPHoyPP/4Yp06dwi+//IL4+HgMGDAAd+7cgSAIiIuLw6lTpzBp0iQcOXIEly9fRkpKCp566ikMGTIECxYsAPC/AOHu3buIi4uDRqNBYWEhCgsLodfr611fIiIic9jd8H9cXFxsVla7du2Qk5ODdevWISYmBpcuXULbtm3Rt29fvPXWW1AqlQCAoUOHIicnB6tXr8b48eNx+/ZteHh4ICwsDJGRkVJXwY8//ojDhw8DALy9vU3udeHCBXTt2tVmda+JQqFARkYGgPq9umhcji27Q4iIyLYE0QYvquv1epw4cQKenp5o27atLepFDUCj0UCpVEqvT9aHVqutslS0MLsNAED8f3cBtMzxBkRETV1dfgus6m5YsGAB4uLiAFQECCNHjsTAgQOhVqutnl+Amj+xTATKODkSEdGDwqogITU1Ff379wcAfP7557hw4QJ+/vlnvPLKK1i+fLlNK0jNSGIxxMTi2tMREVGzYFWQcP36dWlq4i+//BLBwcHw8fHBzJkzceLECZtWkIiIiBqHVQMXO3bsiFOnTqFTp074+uuvsWnTJgBAcXGxTd4OoKbPMPhQFEVpumaFQmEylwIHJRIRNW9WBQkzZszA5MmT0alTJwiCAD8/PwDA4cOHa52OmB4MgiBAoVBAp9NJC1ZVDhZ0Ol2VwIGIiJoPq4KEVatW4eGHH8aVK1cQHBws/cUol8uxbNkym1aQmi6dTlflDYfK+IYDEVHzZfU8CebmdK92ZUAiIiJqdiwOEt577z2LC33ppZesqgw1X8K0P0Pc9kOVfSIiar4sDhJiY2MtSicIAoOEB1TlcQcm7OTm9y0si+MWiIiaHouDhAsXLjRkPagZMB6DYJhW2VZlcdwCEVHTU+8FnkRRrNc8/k1deHg4BEGAIAiwt7eHl5cXlixZAq1WK6UxXBcEAUqlEsOGDcOePXtMyggMDKz2Hh9++CFGjRoFFxcXCIKAW7duVUlz8+ZNTJ8+HS4uLnB1dUVERATu3Lljy0clIiIyYXWQ8PHHH6Nv375wdHSEo6Mj+vXrh08++cSWdWsy/P39UVBQgPPnzyM2NhabN2/GypUrTdIkJCSgoKAABw4cgJubGyZOnIjz589bVH5xcTH8/f0RFRVVbZrp06cjLy8Pu3fvRmZmJvbt24fnn3++Xs9FRERUE6vebnj33Xfx6quvYv78+Rg2bBgAIDs7G3PmzMH169fxyiuv2LSSjU2hUEgzTKrVavj5+WH37t148803pTSurq5QqVRQqVTYtGkTunTpgt27d+OFF16otXzDktDVrXtx+vRpfP311/jPf/6DP//5zwCAf/7zn3jyySfx9ttvo3PnzvV7QAsZtxgZt6RUvlZTOnPnH+SWKCKi5syqIOGf//wnNm3ahOeee0469/TTT6NPnz5YtWrVAxckGDt58iQOHjwIT0/PatM4OjoCAEpLS21yz0OHDsHV1VUKEADAz88PMpkMhw8fxjPPPGM2n06nkwYHAhUrf9WHcVkhISGmF++Vm92vks6MmrpiDPr06YO8vDyMGDEChw4dQnR0NHx9fWvNl5OTg5iYGIvTExHR/1jV3VBQUIChQ4dWOT906FAUFBTUu1JNTWZmJpycnODg4IC+ffvi2rVrWLx4sdm0xcXFiI6Ohlwux8iRI21y/8LCQnTo0MHknJ2dHdq1a4fCwsJq861duxZKpVLa1Gq1TerTGPLy8gBUtFiVlZUhNTXVonwpKSl1Sk9ERP9jVUuCt7c3Pvvssyp96MnJyXjooYdsUrGmZPTo0di0aRPu3r2L2NhY2NnZYdKkSSZppk6dCrlcjpKSEri7uyMuLg79+vVrpBpXiIyMxMKFC6VjjUZTr0DB+LXH5ORkAEYtBXZG8abRfnJystk3F7RarUWtDAaGloThw4fj0KFDZifzMic4OBj5+fkWpyciov+xKkhYvXo1QkJCsG/fPmlMwoEDB/D999/js88+s2kFm4I2bdrA29sbABAfH4/+/fsjLi4OERERUprY2Fj4+flBqVTC3d3dpvdXqVS4du2aybl79+7h5s2b0lgJcxQKhU0XWTKey6DyD78gCBDN7Ds4ONT6emNDvgLp6+uLzMzMBimbiOhBZ1V3w6RJk3D48GG4ubkhPT0d6enpcHNzw5EjR6rtH39QyGQyREVFITo6GiUlJdJ5lUoFb29vmwcIADBkyBDcunULR48elc7t2bMH5eXlGDx4sM3vR0REBNRj7YZBgwbh008/tWVdmo3g4GAsXrwYGzduxKJFiyzKU1RUhNzcXJNz7du3h1qtRmFhIQoLC3H27FkAwIkTJ+Ds7AwPDw+0a9cOvXr1gr+/P2bPno0PPvgAZWVlmD9/PqZMmXLf3mwgIqKWx+ogQa/XY+fOnTh9+jQAoHfv3ggICICdndVFNht2dnaYP38+1q9fj7lz51qUJysrCwMGDDA5FxERgY8++ggffPABVq9eLZ0fMWIEgIq5F8LDwwEAW7duxfz58zFmzBjIZDJMmjSpTutp2IJCoZBmWjQsE22rsoiIqOkRRCteUs/Ly8PTTz+NwsJC9OjRAwBw5swZuLu74/PPP8fDDz9s84pS/Wk0GiiVShQVFcHFxaXe5Wm1WmlqZeG5wRA/Plxln1MuExE1LXX5LbBqTMKsWbPQp08f/Pe//8WPP/6IH3/8EVeuXEG/fv04C2BLdU9vfp+IiJotq/oGcnNz8cMPP6Bt27bSubZt2+L111/Ho48+arPKUfNhvDQ0l4kmInowWNWS4OPjg99++63K+WvXrkmvChIREVHzZnFLgvGUvmvXrsVLL72EVatWSVPd5uTkYM2aNSbrGdCDzXjwoSiK0kBGhUIhzanAQYlERM2XxQMXZTKZyWQ6hmyGc8bHej37pJsiWw5cNAQF1QUH5o6JiKjx1eW3wOKWhH//+9/1rhg9OHQ6nfRmQ3X4ZgMRUfNmcZBgq8WKiIiIqHmweuYjrVaL48eP49q1aygvLze59vTTT9e7YtT8yJ71r+hu+virxq4KERHZgFVBwtdff43nnnsO169fr3KNYxIeXMbjD8wNZRHsLf/nVNNYBiIiahqsegXyxRdfRHBwMAoKClBeXm6yMUB4cBnGIQQEBNRrSmZbl0VERA3DqiDht99+w8KFC9GxY0db14eIiIiaCKuChKCgIGRlZdm4KvdPeHg4BEHAnDlzqlybN28eBEGQ0tS0rVq1qkr+VatWmS07NzcXgiDg4sWLAICLFy+alOXs7Iw+ffpg3rx5+OWXX6qt+4EDB2BnZ4dHHnmkPh8BERFRrawak/Cvf/0LwcHB2L9/P/r27Qt7e3uT6y+99JJNKteQ1Go1kpKSEBsbC0dHRwAVgzG3bdsGDw8PAEBBQYGUPjk5GStWrEB+fr50zsnJyWzZDg4OiIuLw9///nc89NBDNdbju+++Q58+fVBcXIwTJ07gH//4B/r374/PP/8cY8aMMUl769YtPPfccxgzZozZGS8bmvE4BK1Wa3WaytesWGOMiIjuA6uChO3bt+Pbb7+Fg4MDsrKyTAadCYLQLIKEgQMH4ty5c0hLS8P06dMBAGlpafDw8ICXlxcAQKVSSemVSiUEQTA5V50ePXqgQ4cOWL58OT777LMa07Zv314qs1u3bnjqqacwZswYRERE4Ny5c5DL5VLaOXPmYNq0aZDL5UhPT6+1HjqdzqS/33jWTGsYlxUWFmY+kdHiTiEhIRaVGxgYWJ9q1ZlcLkfPnj2Rl5dX5VqfPn1w5swZDBkyBPv27YMgCJDJZAgJCUFKSgqCg4ORnJwMoOL5DPsrVqyQZh+ti5ycHMTExCA4OBgpKSmIjo62qhwiooZgVXfD8uXLsXr1ahQVFeHixYu4cOGCtJ0/f97WdWwwM2fOREJCgnQcHx+PGTNm2KTsdevWYceOHfjhh7otdiSTyfDyyy/j0qVLOHr0qHQ+ISEB58+fx8qVKy0ua+3atVAqldKmVqvrVJcHlV6vNxsgABXLoJeVlSE7OxtARSuHXq9Heno6ysrKkJ6eDr1eL50z7KemplpVl5SUFKncsrIyq8shImoIVgUJpaWlCAkJgUxmVfYmIzQ0FNnZ2bh06RIuXbqEAwcOIDQ01CZlDxw4EJMnT8bSpUvrnLdnz54AII1f+OWXX7Bs2TJ8+umnsLOzvPEnMjISRUVF0nblypU618WY8ToMW7ZsMZ/I7n8tH8nJycjIyDC7Gf4CbwxyuRx9+vQxe61Pnz6wt7fH8OHDAVS0jMnlcgQGBsLe3h6BgYGQy+XSOcN+UFCQVXUJDg6WyrW3t7e6HCKihmBVd0NYWBiSk5MRFRVl6/rcV+7u7pgwYQISExMhiiImTJgANzc3i/JevnwZvXv3lo6joqKqfB4xMTHo1asXvv32W3To0MHielVeB2PatGlYvXo1fHx8LC4DqPhRt+UCS8bdStVNt1w5jSXTMjfV6ZuXL19ucmzoYjHuaqm228VCvr6+yMzMtElZRES2ZlWQoNfrsX79enzzzTfo169flYGL7777rk0qdz/MnDkT8+fPBwBs3LjR4nydO3dGbm6udNyuXbsqabp3747Zs2dj2bJliIuLs7js06dPAwC8vLxw+/Zt/PDDDzh27JhUz/LycoiiCDs7O3z77bd4/PHHLS6biIjIUlYFCSdOnMCAAQMAACdPnjS51txmzvP390dpaSkEQcC4ceMszmdnZwdvb+9a061YsQLdu3dHUlKSReWWl5fjvffeg5eXFwYMGABBEHDixAmTNO+//z727NmD1NRUaZAlERGRrVkVJDxIK0LK5XLpL3fjNwlspWPHjli4cCHeeusts9dv3LiBwsJCFBcX4+TJk9iwYQOOHDmCL774QqrPww8/bJKnQ4cOcHBwqHKeiIjIlqwKEhISEjBlyhRpfoHmrrb1tOtr0aJF2LRpk9l5A/z8/AAArVu3hqenJ0aPHo0PP/zQolaK+02hUCAjIwNA/ec2MC7LluMmiIjIdgTRiv/ad+zYESUlJQgODkZERASGDh3aEHUjG9NoNFAqlSgqKqp3YKTVahEQEGByrvIqkE11QCIRUUtWl98Cq95h/PXXX7FlyxZcv34do0aNQs+ePfHmm2+isLDQqgrTg6H8k6+5TDQR0QPEqiDBzs4OzzzzDDIyMnDlyhXMnj0bW7duhYeHB55++mlkZGSgvLzc1nUlIiKi+8iqMQnGOnbsiOHDh+PMmTM4c+YMTpw4gbCwMLRt2xYJCQkYNWqUDapJTY1hTIEoitJ0zQqFwuTtFo41ICJq3qyeMvG3337D22+/jT59+mDUqFHQaDTIzMzEhQsX8Ouvv2Ly5MmcHOYBJgiCFBQ4ODhAoVBAp9NBq9VKgxp1Oh0XbyIiasasGrj41FNP4ZtvvoGPjw9mzZqF5557rspkQteuXYNKpWK3QxNiy4GLgPnBi5Vx8CIRUdNSl98Cq7obOnTogL1792LIkCHVpnF3d8eFCxesKZ6IiIiaAKu6G+Li4qoECLdu3TI5FgQBnp6eVleMmhf5lGfM7hMRUfNlVZDw5ptvmqziN3nyZLRv3x5dunTBTz/9ZLPKUdMiiiK0Wq3JuAOJ3M78vjVlERFRk2BVkPDBBx9ArVYDAHbv3o3du3fjq6++wvjx47F48WKbVpCaDp1Oh4CAAAQEBEhvNDSFsoiIqGFYNSahsLBQChIyMzMxefJkPPHEE+jatSsGDx5s0woSERFR47CqJaFt27a4cuUKAODrr7+W1h8QRRF6vd52tWtA4eHhEAQBgiDA3t4eXl5eWLJkicn6CobrgiBAqVRi2LBh2LNnj0kZgYGB1d7jww8/xKhRo+Di4gJBEKqM2wCAp59+Gh4eHnBwcECnTp3w7LPP4urVq2bL69mzJxQKBWe2JCKi+8KqIOGvf/0rpk2bhrFjx+LGjRsYP348AODYsWNNcmGi6vj7+6OgoADnz59HbGwsNm/ejJUrV5qkSUhIQEFBAQ4cOAA3NzdMnDgR58+ft6j84uJi+Pv7Iyoqqto0o0ePxmeffYb8/Hzs2LED586dQ1BQUJV02dnZKCkpQVBQELZs2VK3ByUiIrKCVd0NsbGx6Nq1K65cuYL169fDyckJAFBQUIC//e1vNq1gQ1IoFFCpVAAAtVoNPz8/7N69G2+++aaUxtXVFSqVCiqVCps2bUKXLl2we/duvPDCC7WWv2DBAgBAVlZWtWleeeUVad/T0xPLli1DYGAgysrKYG9vL12Li4vDtGnTMHLkSLz88stYunRpHZ+2/owHGFZe0dL4Wk3pzJ3nwEUioqbJqiDB3t4eixYtqnLe+AcPACZMmICPPvoInTp1sq5299HJkydx8ODBGl/bNCyNXVpa2iB1uHnzJrZu3YqhQ4eaBAi3b99GSkoKDh8+jJ49e6KoqAj79+/HX/7ylxrL0+l0JoMCNRpNvepnXFZISIjpReNuJqP9KunMqK7LRiaTYcqUKUhKSkJ5eTmmTZuGHj16YM2aNQCAFStWwNfX1/IHMJKTk4OYmBhER0dbXQYR0YPO6mmZLbFv3z6UlJQ05C3qJTMzE05OTnBwcEDfvn1x7dq1at/OKC4uRnR0NORyOUaOHGnTeixduhRt2rRB+/btcfnyZWRkZJhcT0pKwkMPPYQ+ffpALpdjypQpiIuLq7XctWvXQqlUSpthsGlzUV5ejvT0dGnWzvT0dKSkpECv10Ov1yM1NdXqslNSUlBWVlavMoiIHnT1XuCpORs9ejQ2bdqEu3fvIjY2FnZ2dpg0aZJJmqlTp0Iul6OkpATu7u6Ii4tDv379bFqPxYsXIyIiApcuXcLq1avx3HPPITMzU1osKT4+HqGhoVL60NBQjBw5Ev/85z/h7OxcbbmRkZFYuHChdKzRaOoVKBgv2GSYJ0NqKZDL/5fQaD85OdnstMxarbbWVgaZTIbAwECpJSEwMBA9evTA6dOnAcDs2A1LBQcHIz8/v15lEBE96Fp0kNCmTRtpoGV8fDz69++PuLg4RERESGliY2Ph5+cHpVIJd3f3BqmHm5sb3Nzc4OPjg169ekGtViMnJwdDhgzBqVOnkJOTgyNHjpiMQ9Dr9UhKSsLs2bOrLVehUNh0JUbjFR4r//AbX6ucrra1G2pb36HyQmFffvmlRfWtia+vLzIzM+tdDhHRg6xBuxuaE5lMhqioKERHR5t0kahUKnh7ezdYgFCZoWnd0P8fFxeHESNG4KeffkJubq60LVy40KIuByIiImsxSDASHBwMuVyOjRs3WpynqKjI5Mc7NzdXmkOisLAQubm5OHv2LADgxIkTyM3Nxc2bNwEAhw8fxr/+9S/k5ubi0qVL2LNnD6ZOnYru3btjyJAhKCsrwyeffIKpU6fi4YcfNtlmzZqFw4cPIy8vz/YfBBERERgkmLCzs8P8+fOxfv163L1716I8WVlZGDBggMm2evVqABXTVw8YMEDqEhgxYgQGDBiAXbt2AQBat26NtLQ0jBkzBj169EBERAT69euHvXv3QqFQYNeuXbhx4waeeabqgkm9evVCr1697mtrgkKhQEZGBjIyMurdjWHLsoiIqGEIYgO+pL527VrMnTsXrq6uDXULqoO6rCFuCa1Wi4CAAAAVKz/qk3ZW2a9tvAEREd1fdfktsLol4ZNPPsGwYcPQuXNnXLp0CQCwYcMGk9f3IiMjGSC0EIagoPI+ERE1X1YFCZs2bcLChQvx5JNP4tatW9J6Da6urtiwYYMt60dERESNxKruht69e+ONN95AYGAgnJ2d8dNPP6Fbt244efIkRo0ahevXrzdEXamebN3dIIqi9BaG8b5CoZBegzTeJyKixtfg3Q0XLlzAgAEDqpxXKBQWD/ijB0d1AQIRETVvVk2m5OXlhdzc3CrrHHz99dfo1auXTSpGTZ9Op5MGLlaHAxeJiJovq4KEhQsXYt68edBqtRBFEUeOHMH27duxdu1afPTRR7auIxERETUCq4KEWbNmwdHREdHR0SguLsa0adPQuXNn/OMf/8CUKVNsXUdqRuynz4QgAKWfxjd2VYiIqJ6sXrth+vTpmD59OoqLi3Hnzh106NDBlvWiJqjy2ANzBKMlri0th2MYiIiapnov8NS6dWu0bt3aFnWhJs54DELl5azrUw7HLBARNU1Wvd3w22+/4dlnn0Xnzp1hZ2cHuVxushEREVHzZ1WQEB4ejh9//BGvvvoqUlNTkZaWZrI9SMLDwyEIAgRBgL29Pby8vLBkyRJotVopjeG6IAhQKpUYNmwY9uzZY1JGYGBgtff48MMPMWrUKLi4uEAQBNy6datKmqeffhoeHh5wcHBAp06d8Oyzz+Lq1au2fFQiIiITVnU3ZGdnY//+/XjkkUdsXJ2myd/fHwkJCSgrK8PRo0cRFhYGQRDw5ptvSmkSEhLg7++P69evY/ny5Zg4cSJOnjyJbt261Vp+cXEx/P394e/vj8jISLNpRo8ejaioKHTq1Am//vorFi1ahKCgIBw8eNBmz0lERGTMqiBBrVajAdeFanIUCgVUKhWAimf38/PD7t27TYIEV1dXqFQqqFQqbNq0CV26dMHu3bvxwgsv1Fr+ggULAFSsKFmdV155Rdr39PTEsmXLEBgYiLKyMthbMFjQFoy/c+OWlLqmMz7Xkv4dERE1N1YFCRs2bMCyZcuwefNmdO3a1cZVatpOnjyJgwcPVplIypijoyMAoLS0tEHqcPPmTWzduhVDhw6tMUDQ6XTSWwRAxVSc9WFcVkhISPUJ792zLB1QYzeMwYgRI3Do0CFER0fD19e3yvWcnBzExMRUe52IiKxj1ZiEkJAQZGVloXv37nB2dka7du1MtgdNZmYmnJyc4ODggL59++LatWtYvHix2bTFxcWIjo6GXC7HyJEjbVqPpUuXok2bNmjfvj0uX75c6xsGa9euhVKplDa1Wm3T+twv2dnZKCsrQ2pqqtnrKSkpNV4nIiLrWN2S0JKMHj0amzZtwt27dxEbGws7OztMmjTJJM3UqVMhl8tRUlICd3d3xMXFoV+/fjatx+LFixEREYFLly5h9erVeO6555CZmVntPAORkZFYuHChdKzRaOoVKBjPjZCcnAygmpYCOzuTdJVfcdRqtbW2MBgbPnw4Dh06hKCgILPXg4ODkZ+fX+11IiKyjlVBQlhYmK3r0aS1adMG3t7eAID4+Hj0798fcXFxiIiIkNLExsbCz88PSqUS7u7uDVIPNzc3uLm5wcfHB7169YJarUZOTg6GDBliNr1Coah20iNrGAcjNc1tUDldTWltMU+Cr68vMjMz61UGERFVZVV3AwCcO3cO0dHRmDp1Kq5duwYA+Oqrr5CXl2ezyjVFMpkMUVFRiI6ORklJiXRepVLB29u7wQKEysrLywGYjhMgIiKyJauChL1796Jv3744fPgw0tLScOfOHQDATz/9hJUrV9q0gk1RcHAw5HI5Nm7caHGeoqIi5ObmmmxXrlwBABQWFiI3Nxdnz54FAJw4cQK5ubm4efMmAODw4cP417/+hdzcXFy6dAl79uzB1KlT0b1792pbEYiIiOrLqiBh2bJliImJwe7du9GqVSvp/OOPP46cnBybVa6psrOzw/z587F+/XrcvXvXojxZWVkYMGCAybZ69WoAwAcffIABAwZg9uzZACpG8w8YMAC7du0CUDH1dVpaGsaMGYMePXogIiIC/fr1w969e23anVAbhUKBjIwMZGRk1Ou+tiqHiIgaliBa8aK6k5MTTpw4AS8vLzg7O+Onn35Ct27dcPHiRfTs2bPGd+ip8Wg0GiiVShQVFcHFxaXe5Wm1WmkNBoPKq0BybQYioqalLr8FVg1cdHV1RUFBAby8vEzOHzt2DF26dLGmSHpAlG3lEtFERA8Kq7obpkyZgqVLl6KwsBCCIKC8vBwHDhzAokWL8Nxzz9m6jkRERNQIrOpuKC0txbx585CYmAi9Xg87Ozvcu3cP06dPR2JiIleCbKJs3d0giiJ0Op30v0DFeAPjVyArHxMRUeOqy2+BVUGCwZUrV3DixAncuXMHAwYMwEMPPWRtUXQf2CpIsCQ4MGCQQETUtDT4mATjWfwMcnJyIAgCHBwc4O3tjYCAgAdyimaqmJuh8oDF6nDgIhFR82VVkHDs2DH8+OOP0Ov16NGjBwDgzJkzkMvl6NmzJ95//338/e9/R3Z2Nnr37m3TChMREdH9YVWQYGglSEhIkJoqioqKMGvWLAwfPhyzZ8/GtGnT8Morr+Cbb76xaYWpaXIIfQWC/f/NmXGvDCWfvNu4FSIionqz6u2Gt956C6+99ppJX4ZSqcSqVauwfv16tG7dGitWrMDRo0dtVlFq2gT7VtIGu+qXryYioubDqiChqKhIWq/B2O+//w6NRgOgYi6F0tLS+tWOmhRRFKHVam06WZZxmfUYQ0tERA3A6u6GmTNn4p133sGjjz4KAPjPf/6DRYsWITAwEABw5MgR+Pj42Kyi1PjqMmDRmjI5yJGIqGmxqiVh8+bNGDNmDKZMmQJPT094enpiypQpGDNmDD744AMAQM+ePfHRRx/ZtLLWCg8PhyAImDNnTpVr8+bNgyAIUpqatlWrVlV7j+3bt0Mul2PevHnSuVGjRtVY3qhRowAAXbt2lc61adMGAwcOREpKikn5t27dwrx589CpUycoFAr4+Pjgyy+/tMnnQ0REZI5VLQlOTk74f//v/yE2Nhbnz58HAHTr1g1OTk5SmkceecQmFbQVtVqNpKQkxMbGwtHREUDF2gPbtm2Dh4cHAKCgoEBKn5ycjBUrViA/P186Z/x8lcXFxWHJkiXYvHkz3nnnHTg4OCAtLU3qcrly5Qoee+wxfPfdd+jTpw8AmCyOtWbNGsyePRsajQbvvPMOQkJC0KVLFwwdOhSlpaUYO3YsOnTogNTUVHTp0gWXLl2Cq6urzT4fIiKiyqwKEgycnJzQr18/W9WlQQ0cOBDnzp1DWloapk+fDgBIS0uDh4eHtAaFSqWS0iuVSgiCYHKuOhcuXMDBgwexY8cO/Pvf/0ZaWhqmTZtmMk+EoR+/ffv2Zst0dnaGSqWCSqXCxo0b8emnn+Lzzz/H0KFDER8fj5s3b+LgwYOwt68YFNi1a1erPwtrWTpmwDhdbeMXjK9zTAIRUdNSryChuZk5cyYSEhKkICE+Ph4zZsxAVlZWvcpNSEjAhAkToFQqERoairi4OEybNs3q8uzs7GBvby+1QuzatQtDhgzBvHnzkJGRAXd3d0ybNg1Lly6tcQpsnU4nzYgIQBpUai3jsmp0r0zaDQkJsbh8w3iWxjJt2jSkpKTAx8cHeXl5AAAPDw9cvnxZSmM4HjFiBA4cOAAAWLFiBT777DPk5eWhT58+ePfdd5GTk4OVK1cCgHTOWE5ODmJiYhAdHQ1fX9/79IRERHVj1ZiE5io0NBTZ2dm4dOkSLl26hAMHDiA0NLReZZaXlyMxMVEqZ8qUKcjOzsaFCxesKq+0tBRr165FUVERHn/8cQDA+fPnkZqaCr1ejy+//BKvvvoq3nnnHcTExNRY1tq1a6FUKqVNrVZbVaeWIj09HWVlZVKAAMAkQDA+zs7Ohl6vh16vR2pqqpTH8L/GY0qMyzNISUlBWVkZUlNTbf4cRES20qJaEtzd3TFhwgQkJiZCFEVMmDABbm5uFuW9fPmyyeyRUVFRiIqKwu7du3H37l08+eSTAAA3NzeMHTsW8fHxeO211yyu29KlSxEdHQ2tVgsnJyesW7cOEyZMAFARiHTo0AEffvgh5HI5Bg0ahF9//RVvvfWW9NeqOZGRkSZTaGs0mnoFCgqFwrKERvMkJCcn1/jGglarrVNrQ0MKDAy0uCVh+PDhUktCUFAQysvLpZYEAAgODsbJkycBQDpnLDg4GPn5+QgKCmroxyIislqLChKAii6H+fPnAwA2btxocb7OnTsjNzdXOjaMN4iLi8PNmzelwZBAxY/68ePHsXr1ashkljXWLF68GOHh4XByckLHjh1NFkXq1KkT7O3tTboWevXqhcLCQpSWlpoMgDSmUCgs/2G3gKULNRmnc3BwsPi1xqbwCmRYWJhV+Sp3Gfj6+tY426ivry8yMzOtuhcR0f3S4oIEf39/lJaWQhAEjBs3zuJ8dnZ28Pb2Njl348YNZGRkICkpyeSvRb1ej+HDh+Pbb7+Fv7+/ReW7ublVKd9g2LBh2LZtG8rLy6Wg48yZM+jUqVO1AQIREVF9tbggQS6X4/Tp09J+fXzyySdo3749Jk+eXOWv7CeffBJxcXEWBwk1mTt3Lv71r3/h5ZdfxosvvohffvkFb7zxBl566aV6l01ERFSdFhckAKh1/WxLxcfH45lnnjHbDD9p0iQ8++yzuH79usXjHqqjVqvxzTff4JVXXkG/fv3QpUsXvPzyy1i6dGm9yq0rhUKBjIwMm44jMJRp2CcioqZDEPlyeouh0WigVCpRVFRUr0BJq9VWmZ65ulUgm8I4AyIi+p+6/Ba0yJYEsj3tp7GNXQUiIrKxFjVPAhEREVmOLQlUZ4ZxBKIoSrMwKhQKs2MzOM6AiKj5YpBAdSYIgjTOwHh+CCIierAwSCCrGLciVNeiUF3rAhERNQ8MEsgqOp2uyhsOlfHNBiKi5o0DF4mIiMgsBglUb85T15jdJyKi5o3dDWSxyuMQDASjVR+N92srg2MWiIiaNrYkkMUM4xACAgKkH/rGKIOIiO4PBgm1CA8PhyAIEAQB9vb28PLywpIlS6DVaqU0huuCIECpVGLYsGHYs2ePSRmBgYHV3uOFF15A9+7d4ejoCHd3dwQEBODnn382m/bGjRv405/+BEEQcOvWLVs9JhERURUMEizg7++PgoICnD9/HrGxsdi8eTNWrlxpkiYhIQEFBQU4cOAA3NzcMHHiRJw/f96i8gcNGoSEhAScPn0a33zzDURRxBNPPAG9Xl8lbUREBPr162eT5yIiIqoJgwQLKBQKqFQqqNVqBAYGws/PD7t37zZJ4+rqCpVKhYcffhibNm1CSUlJlTTVef755zFixAh07doVAwcORExMDK5cuYKLFy+apNu0aRNu3bqFRYsW2erR6sR4HIJxS4rx+cppzG3m0hIRUdPDgYt1dPLkSRw8eBCenp7VpjHMQlhaWlrn8u/evYuEhAR4eXlBrVZL50+dOoU1a9bg8OHDFrdQ6HQ6k35/jUZT5/pULs8gLCzsfxfulZndr2056Zq6YCrr06cPzpw5g+joaPj6+gIAcnJyEBMTg+joaACQ9g3XiYioftiSYIHMzEw4OTnBwcEBffv2xbVr17B48WKzaYuLixEdHQ25XI6RI0dafI/3338fTk5OcHJywldffYXdu3ejVauKpZd1Oh2mTp2Kt956Cx4eHhaXuXbtWiiVSmkzDjqam7y8PJSVlSE1NVU6l5KSIp0z3iciIttgS4IFRo8ejU2bNuHu3buIjY2FnZ0dJk2aZJJm6tSpkMvlKCkpgbu7O+Li4uo0dmD69OkYO3YsCgoK8Pbbb2Py5Mk4cOAAHBwcEBkZiV69eiE0NLRO9Y6MjMTChQulY41GU69AwXixpi1btvyvNcH4tUej/eTk5CozLmq12lpbGMwxtCQEBQVJ54KDg5Gfny+dM94nIqL6Y5BggTZt2sDb2xsAEB8fj/79+yMuLg4RERFSmtjYWPj5+UGpVMLd3b3O9zD8tf/QQw/B19cXbdu2xc6dOzF16lTs2bMHJ06ckP5KNvTlu7m5Yfny5Vi9erXZMhUKhU1XYTSe08D4x9/4fOU0NU3LXN9pm319fZGZmSkdG+8TEVH9MUioI5lMhqioKCxcuBDTpk2Txh+oVCopkKgvURRNJh3asWMHSkpKpOv/+c9/MHPmTOzfvx/du3e3yT2JiIgqY5BgheDgYCxevBgbN260+E2DoqIi5Obmmpxr3749ysrKkJycjCeeeALu7u7473//i3Xr1sHR0RFPPvkkAFQJBK5fvw4A6NWrF1xdXev9PEREROYwSLCCnZ0d5s+fj/Xr12Pu3LkW5cnKysKAAQNMzkVERGDNmjXYv38/NmzYgD/++AMdO3bEiBEjcPDgQXTo0KEhqm81hUKBjIwMANa/vmhchi27QoiIyPYEkS+rtxgajQZKpRJFRUVwcXGpV1larVZaKtrl2bXQfBJZZZ9LRRMRNT11+S3gK5BUb6LR3AjG+0RE1LwxSKB6u719hdl9IiJq3hgkEBERkVkcuEhWqTyI0fC6pkKhkOZK4MBEIqLmjS0JREREZBZbEsgqOp1OeruhOny7gYioeWNLAhEREZnFIIHqbcy0d8zuExFR88buBrKY8QBF4zm45HYKs/u1lWE8yJGIiJoetiSQxQzjEAICAqQf+sYog4iI7g8GCURERGQWg4RahIeHQxAECIIAe3t7eHl5YcmSJdBqtVIaw3VBEKBUKjFs2DDs2bPHpIzAwMBa7yWKIsaPHw9BEJCenm5y7aWXXsKgQYOgUCjwyCOP2OjpiIiIqscgwQL+/v4oKCjA+fPnERsbi82bN2PlypUmaRISElBQUIADBw7Azc0NEydOxPnz5+t0nw0bNtTYRz9z5kyEhIRY9Qy2YDwOwThIMj5fOY25zVxaIiJqejhw0QIKhQIqlQoAoFar4efnh927d+PNN9+U0ri6ukKlUkGlUmHTpk3o0qULdu/ejRdeeMGie+Tm5uKdd97BDz/8gE6dOlW5/t577wEAfv/9dxw/ftyiMnU6nUm/v0ajsShfTeUZhIWFSfv6e6Vm92sLaGprXXFzc8P169cBVLTWyGQy9OzZE3l5eRgxYgSWL19ucd1zcnIQExOD6Oho+Pr6WpyPiKglY0tCHZ08eRIHDx5Eq1atqk3j6OgIACgtLa02jbHi4mJMmzYNGzdulIIRW1i7di2USqW0qdVqm5V9PxgCBKCi1UGv1yMvLw8AkJ2dXaeyUlJSUFZWhtTUVJvWkYjoQcaWBAtkZmbCyckJ9+7dg06ng0wmw7/+9S+zaYuLixEdHQ25XI6RI0daVP4rr7yCoUOH1jqDYV1FRkZi4cKF0rFGo6lXoGC8FsOWLVuk1gS53f8CJuP95OTkKjMuarVai7tMampJGD58eJ3qHhwcjPz8fAQFBdUpHxFRS8YgwQKjR4/Gpk2bcPfuXcTGxsLOzg6TJk0ySTN16lTI5XKUlJTA3d0dcXFx6NevX61l79q1C3v27MGxY8dsXm+FQmHTRZaMx0sY//gbn6+cpqZpme/ntM2+vr7IzMy8L/ciInpQsLvBAm3atIG3tzf69++P+Ph4HD58GHFxcSZpYmNjkZubi8LCQhQWFpr02ddkz549OHfuHFxdXWFnZwc7u4q4bdKkSRg1apStH4WIiMhibEmoI5lMhqioKCxcuBDTpk2Txh+oVCp4e3vXubxly5Zh1qxZJuf69u2L2NhYPPXUUzapMxERkTUYJFghODgYixcvxsaNG7Fo0SKL8hQVFSE3N9fkXPv27aFWq80OVvTw8ICXl5d0fPbsWdy5cweFhYUoKSmRyurdu3eNgyhtSaFQICMjA4D1ry8al2HLrhAiIrI9BglWsLOzw/z587F+/XrMnTvXojxZWVkYMGCAybmIiAh89NFHFuWfNWsW9u7dKx0byrpw4QK6du1qWcXrSRAEaQyB8XwH1pZBRERNG4OEWiQmJpo9v2zZMixbtgxA7X9VJyYmVluOOebKy8rKsjj//aa/pzO7T0REzRsHLlK9fb/t72b3iYioeWOQQERERGaxu4GsUnkQo2HKZoVCIc2VwIGJRETNG4MEqhNRFKHVaqsEBYbBiMZBAhERNW8MEqhOdDpdjQsz3c9ZFImIqGFxTAIRERGZxSCB6uX5Ke/j+anvN3Y1iIioAbC7gSxmGI9gzN7essGJ1Q1uJCKipostCWQxnU5n8TLP5vIGBAQgICBAChaIiKhpY5BAREREZjVqkBAeHg5BEDBnzpwq1+bNmwdBEKQ0NW2rVq3CxYsXTc61a9cOI0eOxP79+03KXbVqldl75ubmQhAEXLx4EQAsLu///b//h7/85S9o27Yt2rZtCz8/Pxw5csQkzahRo7BgwYJqP4fXX38dQ4cORevWreHq6lrl+k8//YSpU6dCrVbD0dERvXr1wj/+8Y8aPlkiIqL6a/SWBLVajaSkJJSUlEjntFottm3bBg8PDwBAQUGBtG3YsAEuLi4m54xXYvzuu+9QUFCAffv2oXPnzpg4cSJ+++03k3s6ODggLi4Ov/zyS631q628rKwsTJ06Ff/+979x6NAhqNVqPPHEE/j1118t/gxKS0sRHBxc7WJRR48eRYcOHfDpp58iLy8Py5cvR2RkJP71r39ZfA9bqG6NCuPzWq222q22coiIqGlp9IGLAwcOxLlz55CWlobp06cDANLS0kyWSjZeSlmpVEIQhCrLK1+/fh1AxfLLKpUKKpUKUVFRSEpKwuHDh/H0009LaXv06IEOHTpg+fLl+Oyzz2qsX23lbd261ST9Rx99hB07duD777/Hc889Z9FnsHr1agDVLyY1c+ZMk+Nu3brh0KFDSEtLw/z586stV6fTmfT/azQai+pTU3nm3LtXKu1bMmahpnkWqH7c3Nzwxx9/QK/XAwBGjBiB5cuXY+HChcjLy6s2n4eHBy5fviylB4AtW7Zg27ZtEAQBMpkMK1asgK+vr9n8OTk5iImJQXR0NHx9fZGTk4M1a9YAQJV8NV2rTeX7EFHDavSWBKDiRzAhIUE6jo+Px4wZM+pVZklJCT7++GMAQKtWrapcX7duHXbs2IEffvjBJuUZFBcXo6ysDO3atbOi1pYrKiqq9R5r166FUqmUNrVa3aB1osZ3/fp1KUAAgOzsbACoMUAAgMuXL5ukB4D09HQAFS0/er0eqamp1eZPSUlBWVmZlCYlJQV6vd5svpqu1abyfYioYTV6SwIAhIaGIjIyEpcuXQIAHDhwAElJSVYtjzx06FDIZDIUFxdDFEUMGjQIY8aMqZJu4MCBmDx5MpYuXYrvv/++3uUZLF26FJ07d4afn1+d626pgwcPIjk5GV988UWN6SIjI7Fw4ULpWKPR1CtQqG4tBju7/wVNycnJZmdc1Gq1Vr8ZQZar3JIwfPhwAECfPn0sakkwpAcqWnyMWxKCgoKqzR8cHIz8/HwpTXBwME6fPg0AVfLVdK02le9DRA2rSQQJ7u7umDBhAhITEyGKIiZMmAA3NzerykpOTkbPnj1x8uRJLFmyBImJibC3tzebNiYmBr169cK3336LDh061Lu8devWScFNQ01NfPLkSQQEBGDlypV44oknakyrUChsushSdXMbGJ93cHCo9dk5dfP99+6779Y5T1hYGMLCwixK6+vri8zMTJPjL7/8stq01V2r632IqGE1iSABqOhyMPSvb9y40epy1Go1HnroITz00EO4d+8ennnmGZw8edLsj2X37t0xe/ZsLFu2DHFxcfUq7+2338a6devw3XffoV+/flbXvyanTp3CmDFj8PzzzyM6OrpB7kFERGTQJMYkAIC/vz9KS0tRVlaGcePG2aTMoKAg2NnZ4f33q582eMWKFThz5gySkpKsLm/9+vV47bXX8PXXX+PPf/5zvettTl5eHkaPHo2wsDC8/vrrDXIPIiIiY02mJUEul0v9lHK53CZlCoKAl156CatWrcILL7yA1q1bV0nTsWNHLFy4EG+99ZZV5b355ptYsWIFtm3bhq5du6KwsBAA4OTkBCcnJynv77//jtzcXJPyOnXqhI4dO+Ly5cu4efMmLl++DL1eL6Xz9vaGk5MTTp48iccffxzjxo3DwoULpXvI5XK4u7tb+ekQERHVrMm0JACAi4sLXFxcbFpmWFgYysrKapxTYNGiRSY/6HUpb9OmTSgtLUVQUBA6deokbW+//bZJvm3btmHAgAEm2//7f/8PQEVrxoABA7By5UrcuXNHum548yI1NRW///47Pv30U5N7PProo9Z8JFZTKBRITk62Om9GRgYyMjJsOk6CiIgajiByZpsWQ6PRQKlUoqioyOpgTKvVIiAgQDp+fsr7gAB8uP1vADgokYioqavLb0GT6W6g5unDpL81dhWIiKiBNKnuBiIiImo62JJAdaJQKJCeni5N0axQKEzmSeB4AyKiBweDBKoTQRDg6OgIBwcHKVAQRdFk3xA0VA4giIioeWGQQFbR6XQmAxjN4SBGIqLmjWMSiIiIyCwGCVRvS8a/Y3afiIiaN3Y3kMUqjz0waGWnMLtfU36OVyAiavrYkkAWM4xDCAgIkH7s72d+IiK6vxgkEBERkVkMEmoQHh4OQRAgCALs7e3h5eWFJUuWQKvVSmkM1wVBgFKpxLBhw7Bnzx7p+u+//465c+fCw8MDCoUCKpUK48aNw4EDBwAAN2/exIsvvogePXrA0dERHh4eeOmll1BUVGRSl++//x5Dhw6Fs7MzVCoVli5dinv37t2fD4KIiFokBgm18Pf3R0FBAc6fP4/Y2Fhs3rwZK1euNEmTkJCAgoICHDhwAG5ubpg4cSLOnz8PAJg0aRKOHTuGLVu24MyZM9i1axdGjRqFGzduAACuXr2Kq1ev4u2338bJkyeRmJiIr7/+GhEREVL5P/30E5588kn4+/vj2LFjSE5Oxq5du7Bs2bL790EQEVGLw4GLtTD89Q8AarUafn5+2L17N958800pjaurK1QqFVQqFTZt2oQuXbpg9+7dCAkJwf79+5GVlYWRI0cCADw9PfHYY49JeR9++GHs2LFDOu7evTtef/11hIaG4t69e7Czs0NycjL69euHFStWAKhYQnr9+vWYPHkyVq5cCWdn5/vxUZgMVjRuTTE+X12amvIQEVHTxCChDk6ePImDBw/C09Oz2jSOjo4AgNLSUjg5OcHJyQnp6enw9fW1eMpiw8pcdnYVX49Op6syKZGjoyO0Wi2OHj2KUaNGmS1Hp9OZDBDUaDQW3b86xmWFhYVJ+2X6UrP7ISEh1ZYVGBhY5/sbd+2EhIRIy1avWLECvr6+dS6PiIhqxu6GWmRmZsLJyQkODg7o27cvrl27hsWLF5tNW1xcjOjoaMjlcowcORJ2dnZITEzEli1b4OrqimHDhiEqKgrHjx+v9n7Xr1/Ha6+9hueff146N27cOBw8eBDbt2+HXq/Hr7/+ijVr1gAACgoKqi1r7dq1UCqV0qZWq638FJoGURRRXl4OvV6P9PR06PV66PV6pKamNnbViIgeSAwSajF69Gjk5ubi8OHDCAsLw4wZMzBp0iSTNFOnToWTkxOcnZ2xY8cOxMXFoV+/fgAqxiRcvXoVu3btgr+/P7KysjBw4EAkJiZWuZdGo8GECRPQu3dvrFq1Sjr/xBNP4K233sKcOXOgUCjg4+ODJ598EgAgk1X/FUZGRqKoqEjarly5Uq/PwrglZMuWLdK+vbyV2f3k5GRkZGRIm+Evf2sJggCZTAa5XI7AwEDI5XLI5XIEBQXVq1wiIjKP3Q21aNOmDby9vQEA8fHx6N+/P+Li4kwGFsbGxsLPzw9KpRLu7u5VynBwcMDYsWMxduxYvPrqq5g1axZWrlyJ8PBwKc3t27fh7+8PZ2dn7Ny5E/b29iZlLFy4EK+88goKCgrQtm1bXLx4EZGRkejWrVu1dVcoFDZdldF48iPj7g/j85XTVLd2gy3WdTDu8iAiIttjS0IdyGQyREVFITo6GiUlJdJ5lUoFb29vswGCOb1798bdu3elY41GgyeeeAKtWrXCrl27qv3xFAQBnTt3hqOjI7Zv3w61Wo2BAwfW76GIiIiqwSChjoKDgyGXy7Fx48Za0964cQOPP/44Pv30Uxw/fhwXLlxASkoK1q9fL62gaAgQ7t69i7i4OGg0GhQWFqKwsBB6vV4q66233sKJEyeQl5eH1157DevWrcN7770HuVzeYM9KREQtG7sb6sjOzg7z58/H+vXrMXfu3BrTOjk5YfDgwYiNjcW5c+dQVlYGtVqN2bNnIyoqCgDw448/4vDhwwAgdWsYXLhwAV27dgUAfPXVV3j99deh0+nQv39/ZGRkYPz48bZ/wBooFApkZGQAsO4VRuP8tuwGISKihiGIfGG9xdBoNFAqldIrlvWh1Wql1pAl49/B+q/+XmXfFuMOiIjIturyW8DuBqo3Q1BQeZ+IiJo3BglERERkFsckkFUqj08wzMaoUCik1yA57oCIqHljSwLVS00BgvGcCURE1PywJYGsotPppIGL5nDQIhFR88eWBCIiIjKLQQLZzFtD36w9ERERNRsMEshmFHIOVCQiepBwTAJZzHiQojVzcFU3yJGIiJomtiSQxQyDFQMCAqQf+/uZn4iI7i8GCTUIDw+HIAgQBAH29vbw8vLCkiVLoNVqpTSG64IgQKlUYtiwYdizZ490/ffff8fcuXPh4eEBhUIBlUqFcePG4cCBA1KaDz/8EKNGjYKLiwsEQcCtW7eq1OXMmTMICAiAm5sbXFxcMHz4cPz73/9u0OcnIqKWjUFCLfz9/VFQUIDz588jNjYWmzdvxsqVK03SJCQkoKCgAAcOHICbmxsmTpyI8+fPAwAmTZqEY8eOYcuWLThz5gx27dqFUaNG4caNG1L+4uJi+Pv7S4s+mTNx4kTcu3cPe/bswdGjR9G/f39MnDgRhYWFDfPgRETU4nFMQi0Mf/0DgFqthp+fH3bv3o033/zfSH5XV1eoVCqoVCps2rQJXbp0we7duxESEoL9+/cjKysLI0eOBAB4enriscceM7nHggULAABZWVlm63D9+nX88ssviIuLQ79+/QAA69atw/vvv4+TJ09K9WtoxuMQjFtTLL1ufI7rihERNX0MEurg5MmTOHjwIDw9PatN4+joCAAoLS2Fk5MTnJyckJ6eDl9fX6unKW7fvj169OiBjz/+GAMHDoRCocDmzZvRoUMHDBo0qNp8Op3OpO9fo9FYdX/j8gzCwsKqXC8tL5X2Q0JCaiwrMDCwxusjRozAoUOHEBwcjJSUFERHR8PX19ckTU5ODmJiYsxeIyKi+mN3Qy0yMzPh5OQEBwcH9O3bF9euXcPixYvNpi0uLkZ0dDTkcjlGjhwJOzs7JCYmYsuWLXB1dcWwYcMQFRWF48eP16kOgiDgu+++w7Fjx+Ds7AwHBwe8++67+Prrr9G2bdtq861duxZKpVLa1Gp1ne7bmLKzs1FWVob09HSUlZUhNTW1SpqUlJRqrxERUf0xSKjF6NGjkZubi8OHDyMsLAwzZszApEmTTNJMnToVTk5OcHZ2xo4dO0y6BSZNmoSrV69i165d8Pf3R1ZWFgYOHIjExESL6yCKIubNm4cOHTpg//79OHLkCAIDA/HUU0+hoKCg2nyRkZEoKiqStitXrlj1GRgYt4Rs2bKlyvVWslbSfnJyMjIyMky25ORki+81fPhw2NvbIzAwEPb29ggKCqqSJjg4uNprRERUf+xuqEWbNm3g7e0NAIiPj0f//v0RFxeHiIgIKU1sbCz8/PygVCrh7u5epQwHBweMHTsWY8eOxauvvopZs2Zh5cqVCA8Pt6gOe/bsQWZmJv744w+4uLgAAN5//33s3r0bW7ZswbJly8zmUygUNl2J0XheA3PrMlS+XtPaDXVZ28Fc1wYA+Pr6IjMz06IyiIio7tiSUAcymQxRUVGIjo5GSUmJdF6lUsHb29tsgGBO7969cffuXYvvW1xcLN2/cn3Ky8stLoeIiKguGCTUUXBwMORyOTZu3Fhr2hs3buDxxx/Hp59+iuPHj+PChQtISUnB+vXrTVZQLCwsRG5uLs6ePQsAOHHiBHJzc3Hz5k0AwJAhQ9C2bVuEhYXhp59+wpkzZ7B48WJcuHABEyZMaJgHJSKiFo/dDXVkZ2eH+fPnY/369Zg7d26NaZ2cnDB48GDExsbi3LlzKCsrg1qtxuzZs03mRPjggw+wevVq6XjEiBEAKuZfCA8Ph5ubG77++mssX74cjz/+OMrKytCnTx9kZGSgf//+DfOgZigUCmRkZACw7hVG4/y27AYhIqKGIYh8Yb3F0Gg0UCqVKCoqksY2WEur1Zq0hgAVq0AuPrgUQN3GHBAR0f1Tl98CdjeQzRgCBCIiejAwSCAiIiKzOCaBrGIYX1Dd8s8cc0BE1PyxJYGsVlOAYDxnAhERNU9sSSCr6HS6atdf4KBFIqIHA1sSiIiIyCwGCWQT74xc1NhVICIiG2OQQDahkLeqPRERETUrHJNAFjMeqGjpHFzVDW4kIqKmjy0JZDGdToeAgAAEBARIP/wNkYeIiJqGFhkkhIeHQxAEzJkzp8q1efPmQRAEKU1N26pVq6rkX7Vqldmyc3NzIQgCLl68CAC4ePGiSVnOzs7o06cP5s2bh19++cUkb1paGsaOHQt3d3e4uLhgyJAh+Oabb2z2eRAREZnTIoMEAFCr1UhKSjJZ8lmr1WLbtm3w8PAAABQUFEjbhg0b4OLiYnJu0SLzg/UcHBwQFxdX5cfenO+++w4FBQX46aef8MYbb+D06dPo378/vv/+eynNvn37MHbsWHz55Zc4evQoRo8ejaeeegrHjh2r56dARERUvRY7JmHgwIE4d+4c0tLSMH36dAAVf7F7eHjAy8sLAKBSqaT0SqUSgiCYnKtOjx490KFDByxfvhyfffZZjWnbt28vldmtWzc89dRTGDNmDCIiInDu3DnI5XJs2LDBJM8bb7yBjIwMfP755xgwYEBdHrtejMchaLVai64Z73MtMSKi5qXFBgkAMHPmTCQkJEhBQnx8PGbMmIGsrKx6l71u3To8+uij+OGHH/DnP//Z4nwymQwvv/wynnnmGRw9ehSPPfZYlTTl5eW4ffs22rVrV2NZOp3OZByARqOx/AGqKc8gLCzM5FppeZm0HxISYjZ/dZMvNTWOjo4mLUxAxfeycuVKAEBMTAyio6Ph6+uLnJwcrFmzBqIoQhAErFixQkrj4+ODvLw8jBgxAsuXL7/vz0FEVF8ttrsBAEJDQ5GdnY1Lly7h0qVLOHDgAEJDQ21S9sCBAzF58mQsXVr3lRF79uwJANL4hcrefvtt3LlzB5MnT66xnLVr10KpVEqbWq2uc11aosoBAlARmKWmpiIlJQVlZWVITU0FAKSkpECv16O8vBx6vd4kTV5eHgAgOzv7vtafiMhWWnSQ4O7ujgkTJiAxMREJCQmYMGEC3NzcLMp7+fJlODk5Sdsbb7xRJU1MTAz279+Pb7/9tk71MjTLm3tdcNu2bVi9ejU+++wzdOjQocZyIiMjUVRUJG1XrlypUz0qM160acuWLSbXWsnspf3k5GRkZGQgIyMDycnJ9bpnY3B0dKxyTiaTISgoCMHBwbC3t0dQUBAAIDg4GHK5HDKZDHK53CRNnz59AADDhw+/r/UnIrKVFt3dAFR0OcyfPx8AsHHjRovzde7cGbm5udKxuab/7t27Y/bs2Vi2bBni4uIsLvv06dMAII2NMEhKSsKsWbOQkpICPz+/WstRKBQ2XY3ROGipvDZD5Wvm1m54UNZ0yMzMlPZ9fX3x5Zdf1piGiKi5avFBgr+/P0pLSyEIAsaNG2dxPjs7O3h7e9eabsWKFejevTuSkpIsKre8vBzvvfcevLy8TAYlbt++HTNnzkRSUhImTJhgcT2JiIis1eKDBLlcLv3lLpfLbV5+x44dsXDhQrz11ltmr9+4cQOFhYUoLi7GyZMnsWHDBhw5cgRffPGFVJ9t27YhLCwM//jHPzB48GAUFhYCqGgWVyqVNq8zERERwCABAODi4tKg5S9atAibNm2q8togAKnboHXr1vD09MTo0aPx4YcfmrRSfPjhh7h37x7mzZuHefPmSefDwsKQmJjYoHU3plAokJGRAcDy1xmN89iy64OIiBqeIPLl9RZDo9FAqVSiqKio3oGRVqtFQECAdPzOyEX4+963ATw4Yw+IiB5EdfktaNFvN5DtGAIEIiJ6cDBIICIiIrM4JoGsolAokJ6ebnYZaI49ICJ6MDBIIKsIggBHR0ezEw8REdGDgUECWUUUReh0Oul/gaqtCeZmjCQiouaDQQJZRafTmbzdUBnfcCAiav44cJGIiIjMYpBANvPO47MauwpERGRD7G4gixmPPzA3B5dCbl/lnLm8HK9ARNQ8sCWBLGYYhxAQECD94N+PvERE1DgYJNQgPDwcgiBAEATY29vDy8sLS5YsMVmDwXBdEAQolUoMGzYMe/bska7//vvvmDt3Ljw8PKBQKKBSqTBu3DgcOHBASvPhhx9i1KhRcHFxgSAIuHXrlkk9Ll68iIiICHh5ecHR0RHdu3fHypUrUVpa2uCfARERtVwMEmrh7++PgoICnD9/HrGxsdi8eTNWrlxpkiYhIQEFBQU4cOAA3NzcMHHiRJw/fx4AMGnSJBw7dgxbtmzBmTNnsGvXLowaNQo3btyQ8hcXF8Pf3x9RUVFm6/Dzzz+jvLwcmzdvRl5eHmJjY/HBBx9Um56IiMgWOCahFoa//gFArVbDz88Pu3fvxptvvimlcXV1hUqlgkqlwqZNm9ClSxfs3r0bISEh2L9/P7KysjBy5EgAgKenJx577DGTeyxYsAAAkJWVZbYO/v7+8Pf3l467deuG/Px8bNq0CW+/ff/WTDAeh2BuRcuarhsfc00xIqLmgUFCHZw8eRIHDx6Ep6dntWkMMxCWlpbCyckJTk5OSE9Ph6+vr02nKy4qKkK7du1qTKPT6Uz6/zUaTb3uaVxWWFhYleul5fek/ZCQkGrLCQwMtOh+MpkMU6ZMQUpKCoYMGYJ9+/ZBJpNh5cqV8PX1ldLl5OQgJiYG0dHRJueJiKh+2N1Qi8zMTDg5OcHBwQF9+/bFtWvXsHjxYrNpi4uLER0dDblcjpEjR8LOzg6JiYnYsmULXF1dMWzYMERFReH48eP1qtPZs2fxz3/+Ey+88EKN6dauXQulUiltarW6Xve938rLy5Geno6ysjJkZ2dL51JTU03SpaSkoKysrMp5IiKqHwYJtRg9ejRyc3Nx+PBhhIWFYcaMGZg0aZJJmqlTp8LJyQnOzs7YsWMH4uLi0K9fPwAVYxKuXr2KXbt2wd/fH1lZWRg4cCASExOtqs+vv/4Kf39/BAcHY/bs2TWmjYyMRFFRkbRduXLFqnsaGLeEbNmypcr1VrL/NUwlJycjIyND2pKTk+t8P5lMhsDAQNjb22P48OHSuaCgIJN0wcHBsLe3r3KeiIjqh90NtWjTpg28vb0BAPHx8ejfvz/i4uIQEREhpYmNjYWfnx+USiXc3d2rlOHg4ICxY8di7NixePXVVzFr1iysXLkS4eHhdarL1atXMXr0aAwdOhQffvhhrekVCoVNuziM5zYwN+Vy5evVTctc1ymbDV0by5cvN3vd19cXmZmZFpdHRESWYUtCHchkMkRFRSE6OholJSXSeZVKBW9vb7MBgjm9e/fG3bt363TvX3/9FaNGjcKgQYOQkJAAmYxfHRERNSz+0tRRcHAw5HI5Nm7cWGvaGzdu4PHHH8enn36K48eP48KFC0hJScH69etNFkcqLCxEbm4uzp49CwA4ceIEcnNzcfPmTQD/CxA8PDzw9ttv4/fff0dhYSEKCwsb5iGJiIjA7oY6s7Ozw/z587F+/XrMnTu3xrROTk4YPHgwYmNjce7cOZSVlUGtVmP27Nkmcxx88MEHWL16tXQ8YsQIABXzL4SHh2P37t04e/Yszp49iz/96U8m97ifrxMqFApkZGRYdV/jvLbsAiEiooYjiHxpvcXQaDRQKpUoKiqCi4tLvcrSarVVlor+19i5mL97EwAuFU1E1FTV5beA3Q1kMzp9WWNXgYiIbIhBAtnM3/d81NhVICIiG2KQQERERGZx4GILYhh+Ut/pmQ1lffLJJxBFUZquWaFQSHMl6HQ6rlJJRNQEGX4DLBmSyCChBbl9+zYANLvpmYmIyPZu374NpVJZYxq+3dCClJeX4+rVq3B2djaZHbEuNBoN1Go1rly5Uu83JBrTg/IcwIPzLHyOpoXP0bTY8jlEUcTt27fRuXPnWifmY0tCCyKTyarMs2AtFxeXZv1/OIMH5TmAB+dZ+BxNC5+jabHVc9TWgmDAgYtERERkFoMEIiIiMotBAtWJQqHAypUrm/3Uyg/KcwAPzrPwOZoWPkfT0ljPwYGLREREZBZbEoiIiMgsBglERERkFoMEIiIiMotBAhEREZnFIIHqZOPGjejatSscHBwwePBgHDlypLGrVCerVq2CIAgmW8+ePRu7WrXat28fnnrqKXTu3BmCICA9Pd3kuiiKWLFiBTp16gRHR0f4+fnhl19+aZzK1qC25wgPD6/y/fj7+zdOZWuwdu1aPProo3B2dkaHDh0QGBiI/Px8kzRarRbz5s1D+/bt4eTkhEmTJuG3335rpBqbZ8lzjBo1qsp3MmfOnEaqsXmbNm1Cv379pImGhgwZgq+++kq63hy+C4PanuV+fx8MEshiycnJWLhwIVauXIkff/wR/fv3x7hx43Dt2rXGrlqd9OnTBwUFBdKWnZ3d2FWq1d27d9G/f39s3LjR7PX169fjvffewwcffIDDhw+jTZs2GDduHLRa7X2uac1qew4A8Pf3N/l+tm/ffh9raJm9e/di3rx5yMnJwe7du1FWVoYnnngCd+/eldK88sor+Pzzz5GSkoK9e/fi6tWr+Otf/9qIta7KkucAgNmzZ5t8J+vXr2+kGpv3pz/9CevWrcPRo0fxww8/4PHHH0dAQADy8vIANI/vwqC2ZwHu8/chElnoscceE+fNmycd6/V6sXPnzuLatWsbsVZ1s3LlSrF///6NXY16ASDu3LlTOi4vLxdVKpX41ltvSedu3bolKhQKcfv27Y1QQ8tUfg5RFMWwsDAxICCgUepTH9euXRMBiHv37hVFseLzt7e3F1NSUqQ0p0+fFgGIhw4daqxq1qryc4iiKI4cOVJ8+eWXG69SVmrbtq340UcfNdvvwpjhWUTx/n8fbEkgi5SWluLo0aPw8/OTzslkMvj5+eHQoUONWLO6++WXX9C5c2d069YN06dPx+XLlxu7SvVy4cIFFBYWmnw3SqUSgwcPbnbfDQBkZWWhQ4cO6NGjB+bOnYsbN240dpVqVVRUBABo164dAODo0aMoKysz+U569uwJDw+PJv2dVH4Og61bt8LNzQ0PP/wwIiMjUVxc3BjVs4her0dSUhLu3r2LIUOGNNvvAqj6LAb38/vgAk9kkevXr0Ov16Njx44m5zt27Iiff/65kWpVd4MHD0ZiYiJ69OiBgoICrF69Gn/5y19w8uRJODs7N3b1rFJYWAgAZr8bw7Xmwt/fH3/961/h5eWFc+fOISoqCuPHj8ehQ4cgl8sbu3pmlZeXY8GCBRg2bBgefvhhABXfSatWreDq6mqStil/J+aeAwCmTZsGT09PdO7cGcePH8fSpUuRn5+PtLS0RqxtVSdOnMCQIUOg1Wrh5OSEnTt3onfv3sjNzW1230V1zwLc/++DQQK1KOPHj5f2+/Xrh8GDB8PT0xOfffYZIiIiGrFmBABTpkyR9vv27Yt+/fqhe/fuyMrKwpgxYxqxZtWbN28eTp482SzGttSkuud4/vnnpf2+ffuiU6dOGDNmDM6dO4fu3bvf72pWq0ePHsjNzUVRURFSU1MRFhaGvXv3Nna1rFLds/Tu3fu+fx/sbiCLuLm5QS6XVxkR/Ntvv0GlUjVSrerP1dUVPj4+OHv2bGNXxWqGz/9B+24AoFu3bnBzc2uy38/8+fORmZmJf//73ybLsKtUKpSWluLWrVsm6Zvqd1Ldc5gzePBgAGhy30mrVq3g7e2NQYMGYe3atejfvz/+8Y9/NLvvAqj+Wcxp6O+DQQJZpFWrVhg0aBC+//576Vx5eTm+//57k76y5ubOnTs4d+4cOnXq1NhVsZqXlxdUKpXJd6PRaHD48OFm/d0AwH//+1/cuHGjyX0/oihi/vz52LlzJ/bs2QMvLy+T64MGDYK9vb3Jd5Kfn4/Lly83qe+ktucwJzc3FwCa3HdSWXl5OXQ6XbP5LmpieBZzGvz7uG9DJKnZS0pKEhUKhZiYmCieOnVKfP7550VXV1exsLCwsatmsb///e9iVlaWeOHCBfHAgQOin5+f6ObmJl67dq2xq1aj27dvi8eOHROPHTsmAhDfffdd8dixY+KlS5dEURTFdevWia6urmJGRoZ4/PhxMSAgQPTy8hJLSkoaueamanqO27dvi4sWLRIPHTokXrhwQfzuu+/EgQMHig899JCo1Wobu+om5s6dKyqVSjErK0ssKCiQtuLiYinNnDlzRA8PD3HPnj3iDz/8IA4ZMkQcMmRII9a6qtqe4+zZs+KaNWvEH374Qbxw4YKYkZEhduvWTRwxYkQj19zUsmXLxL1794oXLlwQjx8/Li5btkwUBEH89ttvRVFsHt+FQU3P0hjfB4MEqpN//vOfooeHh9iqVSvxscceE3Nychq7SnUSEhIidurUSWzVqpXYpUsXMSQkRDx79mxjV6tW//73v0UAVbawsDBRFCteg3z11VfFjh07igqFQhwzZoyYn5/fuJU2o6bnKC4uFp944gnR3d1dtLe3Fz09PcXZs2c3ySDU3DMAEBMSEqQ0JSUl4t/+9jexbdu2YuvWrcVnnnlGLCgoaLxKm1Hbc1y+fFkcMWKE2K5dO1GhUIje3t7i4sWLxaKiosateCUzZ84UPT09xVatWonu7u7imDFjpABBFJvHd2FQ07M0xvfBpaKJiIjILI5JICIiIrMYJBAREZFZDBKIiIjILAYJREREZBaDBCIiIjKLQQIRERGZxSCBiIiIzGKQQERERGYxSCCi+0oURTz//PNo164dBEGQ5p5vTFlZWRAEocoiQEQtHYMEIgIAbN26FWq1Gm3btsXChQtNrl28eBE+Pj7QaDT1vs/XX3+NxMREZGZmoqCgAA8//HCVNImJiXB1da1z2dbmay4e9OejpseusStARI3v+vXrmDVrFhITE9GtWzdMmDABjz/+OCZOnAgA+Nvf/oZ169bBxcWl3vcyrLo5dOjQepdFRA2LLQlEhPPnz0OpVCIkJASPPvooRo8ejdOnTwMAtm/fDnt7e/z1r3+1qKy9e/fiscceg0KhQKdOnbBs2TLcu3cPABAeHo4XX3wRly9fhiAI6Nq1a5X8WVlZmDFjBoqKiiAIAgRBwKpVqwAAf/zxB5577jm0bdsWrVu3xvjx4/HLL7/Umu+TTz7Bn//8Zzg7O0OlUmHatGm4du1anT6jW7du4YUXXkDHjh3h4OCAhx9+GJmZmdL1HTt2oE+fPlAoFOjatSveeecdk/yCICA9Pd3knKurKxITEwFUtNYIgoC0tDSMHj0arVu3Rv/+/XHo0KFan+/999/HQw89BAcHB3Ts2BFBQUF1ejaiajXY0lFE1GzcvHlTdHZ2Fn/88Ufxxo0bopeXl/j111+LN2/eFLt37y5evnzZonL++9//iq1btxb/9re/iadPnxZ37twpurm5iStXrhRFURRv3bolrlmzRvzTn/4kFhQUmF2iW6fTiRs2bBBdXFykpYtv374tiqIoPv3002KvXr3Effv2ibm5ueK4ceNEb29vsbS0tMZ8cXFx4pdffimeO3dOPHTokDhkyBBx/Pjx0j0Nq1P+8ccfZp9Lr9eLvr6+Yp8+fcRvv/1WPHfunPj555+LX375pSiKovjDDz+IMplMXLNmjZifny8mJCSIjo6OJqtCAhB37txpUq5SqZTSXLhwQQQg9uzZU8zMzBTz8/PFoKAg0dPTUywrK6v2+f7zn/+Icrlc3LZtm3jx4kXxxx9/FP/xj39Y9H0R1YZBAhGJoiiKaWlp4sMPPyx2795d+lGfOXOmGBsbK+7du1d85JFHxD59+ogpKSnVlhEVFSX26NFDLC8vl85t3LhRdHJyEvV6vSiKohgbGyt6enrWWJeEhARRqVSanDtz5owIQDxw4IB07vr166Kjo6P42WefVZvPnP/85z8iACmIqC1I+Oabb0SZTFbt8tvTpk0Tx44da3Ju8eLFYu/evaVjS4OEjz76SLqel5cnAhBPnz5d7fPt2LFDdHFxETUaTW2PTVRn7G4gIgDAM888gxMnTuDs2bNYtWoV9u7di+PHj+P555/HlClTsGHDBuzYsQMRERHVNtWfPn0aQ4YMgSAI0rlhw4bhzp07+O9//1uv+p0+fRp2dnYYPHiwdK59+/bo0aOH1DVSnaNHj+Kpp56Ch4cHnJ2dMXLkSADA5cuXLbp3bm4u/vSnP8HHx6faug0bNszk3LBhw/DLL79Ar9dbdA+Dfv36SfudOnUCgBq7RsaOHQtPT09069YNzz77LLZu3Yri4uI63ZOoOgwSiKgKnU6Hv/3tb9i8eTPOnj2Le/fuYeTIkejRowd8fHxw+PDhxq6ixe7evYtx48bBxcUFW7duxX/+8x/s3LkTAFBaWmpRGY6OjvWuhyAIEEXR5FxZWVmVdPb29iZ5AKC8vLzacp2dnfHjjz9i+/bt6NSpE1asWIH+/fvzdU6yCQYJRFRFTMz/b9f+QVrnwjCAP7dqtIiIFFFQQpdqU6SD0EFECyLq1sFVBwehCC4qOAr2DqKbdhMHHYSCi239A1IVNLgIVQeJEfyDiovRRVzUvnf4+Aq9N722d7l3eH5jDu9JzhmSJ8n7HX19fWhtbcXn52e28RD478GW7+1Y0zQcHR3lPAx1XUdVVRUaGxsLPr+iKL+cQ9M0fHx85AQUy7JwcXEBn8+Xt84wDFiWhZmZGXR0dMDr9RbdtOj3+3F/fw/TNG3HNU2Drus5x3RdR1NTE0pKSgAAtbW1eHx8zI5fXl4W/cZvtz4AKC0tRXd3N2ZnZ3F2doabmxvs7u4WNTeRHYYEIspxfn6OWCyG6elpAIDX64XD4cDS0hI2NjZgGAYCgYBt7cjICO7u7jA6OgrDMLC+vo6pqSmMjY3B4Sj8duN2u/H6+opUKoWnpye8vb3B4/EgFApheHgYh4eHOD09xcDAABoaGhAKhfLWqaoKRVGwsLCAq6srxONxRCKRovYkGAyis7MT/f392NnZwfX1Nba2trC9vQ0AGB8fRyqVQiQSgWmaWF5eRjQaxcTERHaOrq4uRKNRpNNpHB8fIxwO53w1+NN9SSaTmJ+fx8nJCW5vb7GysoJMJoPm5uai5iay9bebIojo35HJZKS9vV0SiUTO8UQiIaqqSl1dnSwuLv52jv39fQkEAqIoitTX18vk5KS8v79nxwtpXBQRCYfD4nK5BEC2kfL5+VkGBwelurpanE6n9Pb2immaX9atrq6K2+2W8vJyaWtrk3g8LgAknU6LyNeNiyIilmXJ0NCQuFwuqaiokJaWFkkmk9nxtbU18fl8UlZWJqqqytzcXE79w8OD9PT0SGVlpXg8Htnc3LRtXPz/mkREXl5eBIDs7e3lXd/BwYEEg0GpqakRp9Mpfr9fYrHYl/tLVIhvIj/9JCMiIiICfzcQERFRHgwJREREZIshgYiIiGwxJBAREZEthgQiIiKyxZBAREREthgSiIiIyBZDAhEREdliSCAiIiJbDAlERERkiyGBiIiIbP0A1TvVdheXGoQAAAAASUVORK5CYII=","text/plain":["<Figure size 500x550 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["____Filtering the data____\n","pre filtering: (30495, 33694)\n","filtered out 2035 cells that have less than 200 genes expressed\n","filtered out 9096 genes that are detected in less than 3 cells\n","post filtering: (28460, 24598)\n","____Log normalizing____\n","normalizing counts per cell\n","    finished (0:00:01)\n","____Selecting highly variable genes____\n","pre: (28460, 24598)\n","If you pass `n_top_genes`, all cutoffs are ignored.\n","extracting highly variable genes\n","    finished (0:00:04)\n","--> added\n","    'highly_variable', boolean vector (adata.var)\n","    'means', float vector (adata.var)\n","    'dispersions', float vector (adata.var)\n","    'dispersions_norm', float vector (adata.var)\n","pre: (28460, 24598)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1280x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["post: (28460, 3000)\n","____Scaling the data____\n"]},{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n","  view_to_actual(adata)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>gene_symbols</th>\n","      <th>SCYL3</th>\n","      <th>FUCA2</th>\n","      <th>TMEM176A</th>\n","      <th>HSPB6</th>\n","      <th>PDK4</th>\n","      <th>SLC22A16</th>\n","      <th>ARX</th>\n","      <th>SLC25A13</th>\n","      <th>SLC4A1</th>\n","      <th>THSD7A</th>\n","      <th>...</th>\n","      <th>CH17-262H11.1</th>\n","      <th>TRBJ1-5</th>\n","      <th>RP11-328P23.4</th>\n","      <th>CH17-212P11.4</th>\n","      <th>CH17-224D4.1</th>\n","      <th>RP11-596C23.6</th>\n","      <th>CTC-490G23.6</th>\n","      <th>PRNCR1</th>\n","      <th>RP1-273N12.4</th>\n","      <th>TRBV6-2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_ACAGAC</th>\n","      <td>-0.210501</td>\n","      <td>2.240501</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>2.772827</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_ACAGGA</th>\n","      <td>1.656750</td>\n","      <td>2.347928</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_ACGTTG</th>\n","      <td>-0.210501</td>\n","      <td>-0.162299</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_AGACCA</th>\n","      <td>-0.210501</td>\n","      <td>-0.162299</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_CAACTC</th>\n","      <td>-0.210501</td>\n","      <td>-0.162299</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows  3000 columns</p>\n","</div>"],"text/plain":["gene_symbols               SCYL3     FUCA2  TMEM176A     HSPB6      PDK4  \\\n","pbmc1_Celseq2_1_ACAGAC -0.210501  2.240501 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_ACAGGA  1.656750  2.347928 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_ACGTTG -0.210501 -0.162299 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_AGACCA -0.210501 -0.162299 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_CAACTC -0.210501 -0.162299 -0.133715 -0.017045 -0.092075   \n","\n","gene_symbols            SLC22A16       ARX  SLC25A13    SLC4A1    THSD7A  ...  \\\n","pbmc1_Celseq2_1_ACAGAC -0.022733 -0.017383 -0.148193  2.772827 -0.018138  ...   \n","pbmc1_Celseq2_1_ACAGGA -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","pbmc1_Celseq2_1_ACGTTG -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","pbmc1_Celseq2_1_AGACCA -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","pbmc1_Celseq2_1_CAACTC -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","\n","gene_symbols            CH17-262H11.1   TRBJ1-5  RP11-328P23.4  CH17-212P11.4  \\\n","pbmc1_Celseq2_1_ACAGAC      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_ACAGGA      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_ACGTTG      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_AGACCA      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_CAACTC      -0.016476 -0.037941      -0.019149      -0.009174   \n","\n","gene_symbols            CH17-224D4.1  RP11-596C23.6  CTC-490G23.6    PRNCR1  \\\n","pbmc1_Celseq2_1_ACAGAC     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_ACAGGA     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_ACGTTG     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_AGACCA     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_CAACTC     -0.018344      -0.035799     -0.009078 -0.125148   \n","\n","gene_symbols            RP1-273N12.4   TRBV6-2  \n","pbmc1_Celseq2_1_ACAGAC     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_ACAGGA     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_ACGTTG     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_AGACCA     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_CAACTC     -0.020136 -0.046757  \n","\n","[5 rows x 3000 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["\n","print(\"\\n____Create unique index____ \")\n","adata.var_names_make_unique()\n","sc.pl.highest_expr_genes(adata, n_top=20, )\n","        \n","print(\"____Filtering the data____\")\n","print(\"pre filtering:\",adata.shape)\n","sc.pp.filter_cells(adata, min_genes=200)\n","sc.pp.filter_genes(adata, min_cells=3)\n","print(\"post filtering:\",adata.shape)\n","\n","print(\"____Log normalizing____\")\n","sc.pp.normalize_total(adata, target_sum=1e4)\n","sc.pp.log1p(adata)\n","\n","print(\"____Selecting highly variable genes____\")\n","print(\"pre:\",adata.shape)\n","sc.pp.highly_variable_genes(adata, min_mean=0.001 , max_mean=3, min_disp=0.3, n_top_genes=3000)\n","print(\"pre:\",adata.shape)\n","adata.raw = adata\n","adata = adata[:, adata.var.highly_variable]\n","\n","sc.pl.highly_variable_genes(adata)\n","print(\"post:\",adata.shape)\n","\n","print(\"____Scaling the data____\")\n","sc.pp.scale(adata, max_value=10)\n","adata.to_df().head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["all_batches = list(set(adata.obs.Method.values))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["['10x Chromium (v3)',\n"," 'CEL-Seq2',\n"," 'Drop-seq',\n"," '10x Chromium (v2) B',\n"," '10x Chromium (v2)',\n"," '10x Chromium (v2) A',\n"," 'Seq-Well',\n"," 'inDrops']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["all_batches"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["batch_name = 'Seq-Well'"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["mapping = {}\n","reverse_mapping = {}\n","cnt = 0\n","for i in set(adata.obs.CellType.values):\n","    mapping[i] = cnt\n","    reverse_mapping[cnt] = i\n","    cnt += 1"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["total_classes = len(set(adata.obs.CellType.values))"]},{"cell_type":"markdown","metadata":{},"source":["# One vs all for batch '10x Chromium (v2) B'"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["train_df = adata[adata.obs['Method'] != batch_name].to_df()\n","test_df = adata[adata.obs['Method'] == batch_name].to_df()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Taking common genes...\n","Common columns 3000\n"]}],"source":["print(\"Taking common genes...\")\n","final_columns = list(set(train_df.columns).intersection(set(test_df.columns)))\n","print('Common columns', len(final_columns))\n","final_columns = [i for i in final_columns if i != 'CellType'] \n","train_df = train_df[final_columns]\n","test_df = test_df[final_columns]\n","\n","y_train = adata[adata.obs['Method'] != batch_name].obs.CellType.to_list()\n","y_test = adata[adata.obs['Method'] == batch_name].obs.CellType.to_list()\n","\n","X_train = train_df.to_numpy()\n","X_test = test_df.to_numpy()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["y_test_lab = convert_y_to_mapping(y_test, mapping)\n","y_test_lab = np.array(y_test_lab)\n","\n","y_train_lab = convert_y_to_mapping(y_train, mapping)\n","y_train_lab = np.array(y_train_lab)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["with open('/home/anunay18021/SingleCellClassification/dataset/np/X_train_'+batch_name+'.pkl', 'wb') as fh:\n","        pickle.dump(X_train, fh)\n","\n","with open('/home/anunay18021/SingleCellClassification/dataset/np/X_test_'+batch_name+'.pkl', 'wb') as fh:\n","    pickle.dump(X_test, fh)\n","\n","with open('/home/anunay18021/SingleCellClassification/dataset/np/y_test_'+batch_name+'.pkl', 'wb') as fh:\n","    pickle.dump(y_test_lab, fh)\n","\n","with open('/home/anunay18021/SingleCellClassification/dataset/np/y_train_'+batch_name+'.pkl', 'wb') as fh:\n","    pickle.dump(y_train_lab, fh)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["25116"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["len(y_train_lab)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/anunay18021/SingleCellClassification/flowgmm\n"]}],"source":["%cd flowgmm"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n0Zfu1blzejB","outputId":"ecf9742d-4067-4ad6-e529-2bcf3bf0669b"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'num_classes': 10, 'metric_name': 'Seq-Well', 'dataset': <class 'flow_ssl.data.nlp_datasets.AG_News'>, 'network': <function RealNVPTabularWPrior at 0x7f1b7798bdc0>, 'num_epochs': 500, 'bs': 5000, 'lr': 0.0003, 'optim': <class 'torch.optim.adamw.AdamW'>, 'device': 'cuda', 'trainer': SemiFlow, 'split': {'train': 200, 'val': 5000}, 'net_config': {'k': 1024, 'coupling_layers': 7, 'nperlayer': 1}, 'opt_config': {'weight_decay': 1e-05}, 'trainer_config': {'log_dir': '/home/anunay18021/tb-experiments/UCI/', 'log_args': {'minPeriod': 0.1, 'timeFrac': 0.3}, 'unlab_weight': 0.6}, 'save': False}\n","Seq-Well\n","25116\n","25116\n","3344\n","Pairwise dists: [[ 0.         43.26609407 43.29821386 43.37894322 43.38489296 42.52338116\n","  43.32521309 42.7396277  42.54512044 42.63468641]\n"," [43.26609407  0.         42.90046927 43.06665889 43.1685962  43.89246336\n","  43.18936002 43.29689437 43.11490918 43.14754915]\n"," [43.29821386 42.90046927  0.         42.75266514 43.41320231 43.91987738\n","  43.6646075  43.37605235 43.71957295 43.20270423]\n"," [43.37894322 43.06665889 42.75266514  0.         42.89536908 44.24226683\n","  42.59025298 42.51270141 43.10515471 43.11678736]\n"," [43.38489296 43.1685962  43.41320231 42.89536908  0.         44.51122219\n","  43.70066681 43.12289716 43.90783662 43.75386842]\n"," [42.52338116 43.89246336 43.91987738 44.24226683 44.51122219  0.\n","  43.45360865 43.73985126 43.86758512 43.6654565 ]\n"," [43.32521309 43.18936002 43.6646075  42.59025298 43.70066681 43.45360865\n","   0.         43.7633365  43.06712448 43.69274406]\n"," [42.7396277  43.29689437 43.37605235 42.51270141 43.12289716 43.73985126\n","  43.7633365   0.         43.381526   42.94416222]\n"," [42.54512044 43.11490918 43.71957295 43.10515471 43.90783662 43.86758512\n","  43.06712448 43.381526    0.         42.81350779]\n"," [42.63468641 43.14754915 43.20270423 43.11678736 43.75386842 43.6654565\n","  43.69274406 42.94416222 42.81350779  0.        ]]\n","10 Seq-Well\n","train:   0%|                                            | 0/500 [00:00<?, ?it/s]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 10.01240577910199, 'Train_Acc': 0.04612688172043011, 'val_Acc': 0.03861464968152866, 'test_Acc': 0.053528708133971294, 'class_Acc_0': 0.0, 'class_Acc_1': 0.11211573236889692, 'class_Acc_2': 0.043620501635768805, 'class_Acc_3': 0.26470588235294124, 'class_Acc_4': nan, 'class_Acc_5': 0.03827751196172249, 'class_Acc_6': nan, 'class_Acc_7': 0.03740157480314961, 'class_Acc_8': 0.0, 'class_Acc_9': 0.027027027027027025, 'Unlab_loss(mb)': array(4092.4614, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","   Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc    val_bpd\n","0     6674.151367   0.046127     4092.461426  ...  0.053529  0.038615  10.012406\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   1%|                                 | 4/500 [01:06<2:02:26, 14.81s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 8.5684445643305, 'Train_Acc': 0.308022980030722, 'val_Acc': 0.31210191082802546, 'test_Acc': 0.1922846889952153, 'class_Acc_0': 0.0, 'class_Acc_1': 0.9927667269439421, 'class_Acc_2': 0.0970556161395856, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.0023923444976076554, 'class_Acc_6': nan, 'class_Acc_7': 0.003937007874015748, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(1056.7367, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","25     2046.072144   0.308023     1056.736694  ...  0.192285  0.312102  8.568445\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   2%|                                 | 8/500 [02:11<2:00:22, 14.68s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 8.236657798974269, 'Train_Acc': 0.4591946543778802, 'val_Acc': 0.4578025477707006, 'test_Acc': 0.41626794258373206, 'class_Acc_0': 0.0, 'class_Acc_1': 0.9620253164556961, 'class_Acc_2': 0.8200654307524536, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.008771929824561403, 'class_Acc_6': nan, 'class_Acc_7': 0.19094488188976377, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-42.554455, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","48       804.96582   0.459195      -42.554455  ...  0.416268  0.457803  8.236658\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   2%|                                | 12/500 [03:18<2:01:41, 14.96s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 8.058542098188681, 'Train_Acc': 0.6862503840245775, 'val_Acc': 0.6687898089171974, 'test_Acc': 0.5173444976076556, 'class_Acc_0': 0.0, 'class_Acc_1': 0.9222423146473779, 'class_Acc_2': 0.797164667393675, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.08293460925039872, 'class_Acc_6': nan, 'class_Acc_7': 0.7578740157480316, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-475.0654, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","72      220.032333    0.68625     -475.065399  ...  0.517344  0.66879  8.058542\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   3%|                                | 16/500 [04:23<1:58:09, 14.65s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.869955535936158, 'Train_Acc': 0.7547281720430107, 'val_Acc': 0.7360668789808917, 'test_Acc': 0.5717703349282297, 'class_Acc_0': 0.0, 'class_Acc_1': 0.8716094032549726, 'class_Acc_2': 0.7884405670665212, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.2376395534290271, 'class_Acc_6': nan, 'class_Acc_7': 0.8051181102362206, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-869.9463, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","96     -374.186249   0.754728     -869.946289  ...   0.57177  0.736067  7.869956\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   4%|                               | 19/500 [05:16<2:05:25, 15.65s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.664800203623625, 'Train_Acc': 0.7894517357910906, 'val_Acc': 0.7691082802547771, 'test_Acc': 0.5729665071770335, 'class_Acc_0': 0.0, 'class_Acc_1': 0.8806509945750451, 'class_Acc_2': 0.6314067611777535, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.3588516746411483, 'class_Acc_6': nan, 'class_Acc_7': 0.781496062992126, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-1707.763, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","119    -1272.877197   0.789452    -1707.762939  ...  0.572967  0.769108   7.6648\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   5%|                               | 23/500 [06:20<1:59:16, 15.00s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.433445626816211, 'Train_Acc': 0.8073239324116743, 'val_Acc': 0.7890127388535032, 'test_Acc': 0.6581937799043063, 'class_Acc_0': 0.0, 'class_Acc_1': 0.8300180831826399, 'class_Acc_2': 0.7251908396946563, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.4968102073365231, 'class_Acc_6': nan, 'class_Acc_7': 0.8740157480314962, 'class_Acc_8': 0.5555555555555555, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-1414.3552, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","142    -1520.705322   0.807324    -1414.355225  ...  0.658194  0.789013  7.433446\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   5%|                               | 27/500 [07:26<1:58:26, 15.02s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.258280986885048, 'Train_Acc': 0.8099207373271889, 'val_Acc': 0.7898089171974523, 'test_Acc': 0.6785287081339713, 'class_Acc_0': 0.0, 'class_Acc_1': 0.755877034358047, 'class_Acc_2': 0.7219193020719737, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.5749601275917066, 'class_Acc_6': nan, 'class_Acc_7': 0.9015748031496064, 'class_Acc_8': 0.5555555555555555, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-1519.7378, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","165     -2026.97876   0.809921    -1519.737793  ...  0.678529  0.789809  7.258281\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   6%|                               | 31/500 [08:31<1:54:39, 14.67s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.111102493942955, 'Train_Acc': 0.8173879569892474, 'val_Acc': 0.794984076433121, 'test_Acc': 0.701255980861244, 'class_Acc_0': 0.0, 'class_Acc_1': 0.7540687160940326, 'class_Acc_2': 0.7306434023991275, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.6379585326953748, 'class_Acc_6': nan, 'class_Acc_7': 0.8818897637795277, 'class_Acc_8': 0.5555555555555555, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-2123.7156, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","188    -2522.748047   0.817388    -2123.715576  ...  0.701256  0.794984  7.111102\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   7%|                              | 35/500 [09:36<1:53:59, 14.71s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.003087042724832, 'Train_Acc': 0.81144866359447, 'val_Acc': 0.7882165605095541, 'test_Acc': 0.6967703349282297, 'class_Acc_0': 0.0, 'class_Acc_1': 0.636528028933092, 'class_Acc_2': 0.791712104689204, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.6196172248803827, 'class_Acc_6': nan, 'class_Acc_7': 0.9153543307086617, 'class_Acc_8': 0.5555555555555555, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-2650.7778, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","210    -3097.016357   0.811449    -2650.777832  ...   0.69677  0.788217  7.003087\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   8%|                              | 38/500 [10:28<1:58:47, 15.43s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.921135553989806, 'Train_Acc': 0.824557910906298, 'val_Acc': 0.7925955414012739, 'test_Acc': 0.7102272727272727, 'class_Acc_0': 0.0, 'class_Acc_1': 0.6672694394213381, 'class_Acc_2': 0.7328244274809159, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.7280701754385964, 'class_Acc_6': nan, 'class_Acc_7': 0.8090551181102362, 'class_Acc_8': 0.5555555555555555, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-3285.514, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","233    -3711.766602   0.824558    -3285.513916  ...  0.710227  0.792596  6.921136\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   8%|                              | 42/500 [11:33<1:51:55, 14.66s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.84134963410481, 'Train_Acc': 0.8221993241167436, 'val_Acc': 0.7917993630573248, 'test_Acc': 0.6555023923444976, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.7902350813743219, 'class_Acc_2': 0.6619411123227915, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.5629984051036683, 'class_Acc_6': nan, 'class_Acc_7': 0.8484251968503937, 'class_Acc_8': 0.5, 'class_Acc_9': 0.027027027027027025, 'Unlab_loss(mb)': array(-2658.0444, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","256    -3522.470215   0.822199    -2658.044434  ...  0.655502  0.791799  6.84135\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   9%|                              | 46/500 [12:40<1:53:35, 15.01s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.752184083131222, 'Train_Acc': 0.8270919815668203, 'val_Acc': 0.7977707006369427, 'test_Acc': 0.6863038277511961, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6311030741410487, 'class_Acc_2': 0.6892039258451471, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.6762360446570973, 'class_Acc_6': nan, 'class_Acc_7': 0.8937007874015749, 'class_Acc_8': 0.5555555555555555, 'class_Acc_9': 0.027027027027027025, 'Unlab_loss(mb)': array(-2873.2773, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","278     -3845.01416   0.827092    -2873.277344  ...  0.686304  0.797771  6.752184\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  10%|                             | 50/500 [13:45<1:50:45, 14.77s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.691108231964577, 'Train_Acc': 0.8255129339477727, 'val_Acc': 0.79578025477707, 'test_Acc': 0.6958732057416268, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5931283905967449, 'class_Acc_2': 0.6564885496183206, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.7535885167464115, 'class_Acc_6': nan, 'class_Acc_7': 0.8700787401574804, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.027027027027027025, 'Unlab_loss(mb)': array(-3006.4988, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","301     -4080.43042   0.825513    -3006.498779  ...  0.695873  0.79578  6.691108\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  11%|                             | 54/500 [14:50<1:48:59, 14.66s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.605395733061919, 'Train_Acc': 0.8339626420890938, 'val_Acc': 0.7965764331210191, 'test_Acc': 0.6818181818181818, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6274864376130198, 'class_Acc_2': 0.6673936750272628, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.6858054226475279, 'class_Acc_6': nan, 'class_Acc_7': 0.8877952755905513, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.027027027027027025, 'Unlab_loss(mb)': array(-3430.8462, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","324    -4510.416016   0.833963    -3430.846191  ...  0.681818  0.796576  6.605396\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  11%|                             | 57/500 [15:43<1:54:59, 15.57s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.595283600804698, 'Train_Acc': 0.842319569892473, 'val_Acc': 0.7937898089171974, 'test_Acc': 0.659688995215311, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6636528028933092, 'class_Acc_2': 0.7393675027262814, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.5717703349282296, 'class_Acc_6': nan, 'class_Acc_7': 0.8523622047244094, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-3186.009, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","346     -4355.29248    0.84232    -3186.009033  ...  0.659689  0.79379  6.595284\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  12%|                             | 61/500 [16:47<1:48:40, 14.85s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.488544713972938, 'Train_Acc': 0.8434235944700461, 'val_Acc': 0.7985668789808917, 'test_Acc': 0.6438397129186603, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.6853526220614827, 'class_Acc_2': 0.5888767720828789, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.6371610845295055, 'class_Acc_6': nan, 'class_Acc_7': 0.8346456692913387, 'class_Acc_8': 0.5, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-3448.537, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","368     -4694.19873   0.843424    -3448.537109  ...   0.64384  0.798567  6.488545\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  13%|                            | 65/500 [17:55<1:50:00, 15.17s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.456683437384296, 'Train_Acc': 0.8461035944700461, 'val_Acc': 0.7993630573248408, 'test_Acc': 0.6351674641148325, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.7016274864376131, 'class_Acc_2': 0.5965103598691384, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.6228070175438597, 'class_Acc_6': nan, 'class_Acc_7': 0.7854330708661418, 'class_Acc_8': 0.38888888888888895, 'class_Acc_9': 0.027027027027027025, 'Unlab_loss(mb)': array(-3783.9136, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","390    -4976.311035   0.846104    -3783.913574  ...  0.635167  0.799363  6.456683\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  14%|                            | 68/500 [18:47<1:53:26, 15.76s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.38827447346058, 'Train_Acc': 0.8585198156682028, 'val_Acc': 0.8065286624203821, 'test_Acc': 0.625, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.7179023508137433, 'class_Acc_2': 0.6019629225736095, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.5614035087719298, 'class_Acc_6': nan, 'class_Acc_7': 0.8385826771653545, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-3619.658, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","412     -5022.47168    0.85852    -3619.657959  ...     0.625  0.806529  6.388274\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  14%|                            | 72/500 [19:53<1:47:42, 15.10s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.350817705095105, 'Train_Acc': 0.8602030107526881, 'val_Acc': 0.804140127388535, 'test_Acc': 0.5956937799043063, 'class_Acc_0': 0.0, 'class_Acc_1': 0.7359855334538878, 'class_Acc_2': 0.5528898582333697, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.5119617224880383, 'class_Acc_6': nan, 'class_Acc_7': 0.8366141732283465, 'class_Acc_8': 0.5, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-3725.8535, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","434    -5212.235352   0.860203    -3725.853516  ...  0.595694  0.80414  6.350818\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  15%|                            | 76/500 [20:59<1:45:31, 14.93s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.291246774585534, 'Train_Acc': 0.8654303533026113, 'val_Acc': 0.8089171974522293, 'test_Acc': 0.6127392344497608, 'class_Acc_0': 0.0, 'class_Acc_1': 0.6708860759493671, 'class_Acc_2': 0.6085059978189749, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.55103668261563, 'class_Acc_6': nan, 'class_Acc_7': 0.8248031496062993, 'class_Acc_8': 0.38888888888888895, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-3827.947, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","457      -5398.1875    0.86543    -3827.947021  ...  0.612739  0.808917  6.291247\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  16%|                           | 79/500 [21:52<1:49:15, 15.57s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.247553708003351, 'Train_Acc': 0.8704879877112135, 'val_Acc': 0.8101114649681529, 'test_Acc': 0.6154306220095693, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6220614828209764, 'class_Acc_2': 0.5659760087241003, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.6012759170653907, 'class_Acc_6': nan, 'class_Acc_7': 0.8464566929133859, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-4688.307, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","479    -6046.201172   0.870488    -4688.307129  ...  0.615431  0.810111  6.247554\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  17%|                           | 83/500 [22:59<1:46:27, 15.32s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.21035406058022, 'Train_Acc': 0.8787025499231951, 'val_Acc': 0.8128980891719745, 'test_Acc': 0.5792464114832536, 'class_Acc_0': 0.0, 'class_Acc_1': 0.7305605786618445, 'class_Acc_2': 0.5387131952017448, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.48963317384370014, 'class_Acc_6': nan, 'class_Acc_7': 0.81496062992126, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-4028.605, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","500    -5696.298828   0.878703     -4028.60498  ...  0.579246  0.812898  6.210354\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  17%|                           | 87/500 [24:04<1:43:19, 15.01s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.16928621056007, 'Train_Acc': 0.8804784024577573, 'val_Acc': 0.8188694267515924, 'test_Acc': 0.5885167464114832, 'class_Acc_0': 0.0, 'class_Acc_1': 0.6455696202531644, 'class_Acc_2': 0.5616139585605233, 'class_Acc_3': 0.0, 'class_Acc_4': nan, 'class_Acc_5': 0.521531100478469, 'class_Acc_6': nan, 'class_Acc_7': 0.8503937007874017, 'class_Acc_8': 0.38888888888888895, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-4357.223, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","522    -5983.299805   0.880478    -4357.223145  ...  0.588517  0.818869  6.169286\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  18%|                           | 90/500 [24:57<1:46:07, 15.53s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.129468743204755, 'Train_Acc': 0.8837328417818741, 'val_Acc': 0.8188694267515924, 'test_Acc': 0.59061004784689, 'class_Acc_0': 0.0, 'class_Acc_1': 0.6455696202531644, 'class_Acc_2': 0.5856052344601963, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.5135566188197768, 'class_Acc_6': nan, 'class_Acc_7': 0.8385826771653545, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-4165.4717, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","544    -5954.795898   0.883733     -4165.47168  ...   0.59061  0.818869  6.129469\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  19%|                          | 94/500 [26:03<1:42:58, 15.22s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.105049532904917, 'Train_Acc': 0.8890818433179724, 'val_Acc': 0.8248407643312102, 'test_Acc': 0.5780502392344498, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6781193490054249, 'class_Acc_2': 0.49836423118865864, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.5478468899521531, 'class_Acc_6': nan, 'class_Acc_7': 0.7913385826771654, 'class_Acc_8': 0.38888888888888895, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-4260.1177, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","566     -6071.23291   0.889082    -4260.117676  ...   0.57805  0.824841  6.10505\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  20%|                          | 98/500 [27:08<1:39:26, 14.84s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.060860422495605, 'Train_Acc': 0.8906739170506912, 'val_Acc': 0.8248407643312102, 'test_Acc': 0.5980861244019139, 'class_Acc_0': 0.0, 'class_Acc_1': 0.6057866184448463, 'class_Acc_2': 0.5856052344601963, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.5598086124401914, 'class_Acc_6': nan, 'class_Acc_7': 0.8169291338582678, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-4592.9907, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","588    -6371.523438   0.890674    -4592.990723  ...  0.598086  0.824841  6.06086\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  20%|                         | 101/500 [28:02<1:44:53, 15.77s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.0256194731004, 'Train_Acc': 0.9008227956989248, 'val_Acc': 0.82921974522293, 'test_Acc': 0.5816387559808612, 'class_Acc_0': 0.0, 'class_Acc_1': 0.6546112115732369, 'class_Acc_2': 0.5834242093784078, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.5087719298245614, 'class_Acc_6': nan, 'class_Acc_7': 0.7795275590551182, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-4384.3535, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","610    -6260.483398   0.900823    -4384.353516  ...  0.581639  0.82922  6.025619\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  21%|                         | 105/500 [29:08<1:38:31, 14.96s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.998238323470195, 'Train_Acc': 0.8994851612903225, 'val_Acc': 0.8248407643312102, 'test_Acc': 0.5565191387559809, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6998191681735985, 'class_Acc_2': 0.5354416575790621, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.4688995215311005, 'class_Acc_6': nan, 'class_Acc_7': 0.7480314960629921, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-4474.8955, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","632    -6431.162598   0.899485    -4474.895508  ...  0.556519  0.824841  5.998238\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  22%|                         | 109/500 [30:13<1:35:45, 14.69s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.0098756877648665, 'Train_Acc': 0.9019011367127496, 'val_Acc': 0.8320063694267515, 'test_Acc': 0.5717703349282297, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.6274864376130198, 'class_Acc_2': 0.5681570338058887, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.507177033492823, 'class_Acc_6': nan, 'class_Acc_7': 0.7716535433070867, 'class_Acc_8': 0.5, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-4698.989, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","654    -6612.003418   0.901901     -4698.98877  ...   0.57177  0.832006  6.009876\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  22%|                        | 112/500 [31:05<1:39:58, 15.46s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.939853554093282, 'Train_Acc': 0.9076627956989247, 'val_Acc': 0.8324044585987261, 'test_Acc': 0.5532296650717703, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.640144665461121, 'class_Acc_2': 0.52453653217012, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.4800637958532696, 'class_Acc_6': nan, 'class_Acc_7': 0.7834645669291339, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-4567.493, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","676     -6591.32666   0.907663    -4567.493164  ...   0.55323  0.832404  5.939854\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  23%|                        | 116/500 [32:10<1:33:42, 14.64s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.90855359952535, 'Train_Acc': 0.9090325038402458, 'val_Acc': 0.8339968152866242, 'test_Acc': 0.5633971291866029, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.6130198915009041, 'class_Acc_2': 0.520174482006543, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.5342902711323764, 'class_Acc_6': nan, 'class_Acc_7': 0.7500000000000001, 'class_Acc_8': 0.5, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-4473.135, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","699    -6611.675781   0.909033    -4473.134766  ...  0.563397  0.833997  5.908554\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  24%|                        | 120/500 [33:18<1:36:01, 15.16s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.887937900663062, 'Train_Acc': 0.9048418433179723, 'val_Acc': 0.8312101910828026, 'test_Acc': 0.5523325358851675, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6220614828209764, 'class_Acc_2': 0.529989094874591, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.5007974481658692, 'class_Acc_6': nan, 'class_Acc_7': 0.7401574803149606, 'class_Acc_8': 0.38888888888888895, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-4948.735, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","720    -6913.296875   0.904842    -4948.734863  ...  0.552333  0.83121  5.887938\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  25%|                        | 123/500 [34:11<1:38:39, 15.70s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.8486756501736625, 'Train_Acc': 0.9099572350230414, 'val_Acc': 0.8320063694267515, 'test_Acc': 0.5583133971291866, 'class_Acc_0': 0.0, 'class_Acc_1': 0.6075949367088607, 'class_Acc_2': 0.5376226826608506, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.511164274322169, 'class_Acc_6': nan, 'class_Acc_7': 0.7539370078740159, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-4758.375, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","742    -6940.924805   0.909957       -4758.375  ...  0.558313  0.832006  5.848676\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  25%|                       | 127/500 [35:15<1:31:39, 14.74s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.818740197702508, 'Train_Acc': 0.9108773579109063, 'val_Acc': 0.82921974522293, 'test_Acc': 0.5382775119617225, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6491862567811935, 'class_Acc_2': 0.500545256270447, 'class_Acc_3': 0.08823529411764706, 'class_Acc_4': nan, 'class_Acc_5': 0.4481658692185008, 'class_Acc_6': nan, 'class_Acc_7': 0.7992125984251968, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-4706.7783, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc  val_bpd\n","765    -6862.613281   0.910877     -4706.77832  ...  0.538278  0.82922  5.81874\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  26%|                       | 131/500 [36:21<1:31:05, 14.81s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.799053891251003, 'Train_Acc': 0.9156997235023041, 'val_Acc': 0.8359872611464968, 'test_Acc': 0.5296052631578947, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6383363471971066, 'class_Acc_2': 0.5016357688113413, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.4393939393939394, 'class_Acc_6': nan, 'class_Acc_7': 0.7775590551181104, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-4843.589, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","787    -7108.860352     0.9157    -4843.588867  ...  0.529605  0.835987  5.799054\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  27%|                       | 134/500 [37:13<1:34:15, 15.45s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.758981768496624, 'Train_Acc': 0.9134564055299539, 'val_Acc': 0.8375796178343949, 'test_Acc': 0.5463516746411483, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6347197106690777, 'class_Acc_2': 0.48418756815703384, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.5055821371610846, 'class_Acc_6': nan, 'class_Acc_7': 0.7559055118110237, 'class_Acc_8': 0.38888888888888895, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-5700.9883, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","809    -7741.839844   0.913456    -5700.988281  ...  0.546352  0.83758  5.758982\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  28%|                       | 138/500 [38:19<1:30:32, 15.01s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.756746577400559, 'Train_Acc': 0.9162756989247312, 'val_Acc': 0.8296178343949044, 'test_Acc': 0.4958133971291866, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6618444846292947, 'class_Acc_2': 0.4940021810250817, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.37320574162679426, 'class_Acc_6': nan, 'class_Acc_7': 0.704724409448819, 'class_Acc_8': 0.38888888888888895, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-4816.788, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","831    -7114.372559   0.916276    -4816.788086  ...  0.495813  0.829618  5.756747\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  28%|                       | 142/500 [39:27<1:29:59, 15.08s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.722868603813434, 'Train_Acc': 0.912448356374808, 'val_Acc': 0.8359872611464968, 'test_Acc': 0.5296052631578947, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5641952983725136, 'class_Acc_2': 0.45256270447110136, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.5430622009569378, 'class_Acc_6': nan, 'class_Acc_7': 0.6909448818897639, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5010.8784, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","853    -7298.135742   0.912448    -5010.878418  ...  0.529605  0.835987  5.722869\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  29%|                      | 145/500 [40:18<1:31:45, 15.51s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.6890796245981345, 'Train_Acc': 0.9191652841781874, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.5245215311004785, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5732368896925859, 'class_Acc_2': 0.47001090512540883, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.49521531100478466, 'class_Acc_6': nan, 'class_Acc_7': 0.7342519685039371, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5912.736, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","875    -7972.499512   0.919165     -5912.73584  ...  0.524522  0.840366  5.68908\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  30%|                      | 148/500 [41:22<1:47:59, 18.41s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.665646161984112, 'Train_Acc': 0.9229334562211982, 'val_Acc': 0.8335987261146497, 'test_Acc': 0.5170454545454546, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6238698010849908, 'class_Acc_2': 0.5256270447110141, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.4043062200956938, 'class_Acc_6': nan, 'class_Acc_7': 0.7539370078740159, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5144.761, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","892    -7523.463379   0.922933     -5144.76123  ...  0.517045  0.833599  5.665646\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  30%|                      | 151/500 [42:33<1:59:36, 20.56s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.670678688044713, 'Train_Acc': 0.9237686021505376, 'val_Acc': 0.8383757961783439, 'test_Acc': 0.5110645933014354, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.589511754068716, 'class_Acc_2': 0.47328244274809156, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.441786283891547, 'class_Acc_6': nan, 'class_Acc_7': 0.751968503937008, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-5008.6606, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","909    -7345.378906   0.923769    -5008.660645  ...  0.511065  0.838376  5.670679\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  31%|                      | 154/500 [43:44<2:02:16, 21.20s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.637022143725745, 'Train_Acc': 0.9199188940092166, 'val_Acc': 0.8363853503184714, 'test_Acc': 0.5269138755980861, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5497287522603979, 'class_Acc_2': 0.5070883315158125, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.4864433811802233, 'class_Acc_6': nan, 'class_Acc_7': 0.7342519685039371, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5256.8457, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","926    -7664.668457   0.919919    -5256.845703  ...  0.526914  0.836385  5.637022\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  31%|                      | 157/500 [44:54<2:01:57, 21.34s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.618232825401876, 'Train_Acc': 0.9261942857142857, 'val_Acc': 0.8355891719745223, 'test_Acc': 0.49700956937799046, 'class_Acc_0': 0.0, 'class_Acc_1': 0.650994575045208, 'class_Acc_2': 0.47982551799345685, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3835725677830941, 'class_Acc_6': nan, 'class_Acc_7': 0.7303149606299213, 'class_Acc_8': 0.27777777777777773, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5225.3755, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","943    -7686.321777   0.926194    -5225.375488  ...   0.49701  0.835589  5.618233\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  32%|                     | 160/500 [46:04<2:00:48, 21.32s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.6200152957884955, 'Train_Acc': 0.9217620890937019, 'val_Acc': 0.8379777070063694, 'test_Acc': 0.5290071770334929, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5605786618444846, 'class_Acc_2': 0.5038167938931298, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.48963317384370014, 'class_Acc_6': nan, 'class_Acc_7': 0.7283464566929134, 'class_Acc_8': 0.38888888888888895, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5518.9287, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","960    -7871.655762   0.921762    -5518.928711  ...  0.529007  0.837978  5.620015\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  32%|                     | 162/500 [46:57<2:10:00, 23.08s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.596060077253109, 'Train_Acc': 0.9184597235023041, 'val_Acc': 0.8332006369426752, 'test_Acc': 0.5433612440191388, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5985533453887883, 'class_Acc_2': 0.5147219193020719, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.5342902711323764, 'class_Acc_6': nan, 'class_Acc_7': 0.6515748031496064, 'class_Acc_8': 0.38888888888888895, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6081.474, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","977    -8252.124023    0.91846    -6081.474121  ...  0.543361  0.833201  5.59606\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  33%|                     | 165/500 [48:07<2:03:08, 22.05s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.5737872984911565, 'Train_Acc': 0.9257478955453148, 'val_Acc': 0.839171974522293, 'test_Acc': 0.5197368421052632, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5605786618444846, 'class_Acc_2': 0.5310796074154852, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.4665071770334928, 'class_Acc_6': nan, 'class_Acc_7': 0.6850393700787403, 'class_Acc_8': 0.27777777777777773, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-5347.442, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","994    -7812.881348   0.925748    -5347.441895  ...  0.519737  0.839172  5.573787\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  34%|                     | 168/500 [49:16<1:58:24, 21.40s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.56250872944754, 'Train_Acc': 0.9302983102918586, 'val_Acc': 0.8328025477707006, 'test_Acc': 0.5110645933014354, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5641952983725136, 'class_Acc_2': 0.5976008724100327, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.39712918660287083, 'class_Acc_6': nan, 'class_Acc_7': 0.673228346456693, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-5364.469, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1012    -7858.701172   0.930298    -5364.469238  ...  0.511065  0.832803  5.562509\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  34%|                     | 171/500 [50:25<1:56:35, 21.26s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.544757757066185, 'Train_Acc': 0.9267702611367128, 'val_Acc': 0.839968152866242, 'test_Acc': 0.5188397129186603, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5334538878842676, 'class_Acc_2': 0.46455834242093785, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.5143540669856459, 'class_Acc_6': nan, 'class_Acc_7': 0.7007874015748032, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-5408.7847, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1030     -7914.69873    0.92677    -5408.784668  ...   0.51884  0.839968  5.544758\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  35%|                    | 174/500 [51:35<1:54:47, 21.13s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.5259130227218645, 'Train_Acc': 0.9316648233486944, 'val_Acc': 0.8379777070063694, 'test_Acc': 0.5143540669856459, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5786618444846292, 'class_Acc_2': 0.5256270447110141, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.4513556618819776, 'class_Acc_6': nan, 'class_Acc_7': 0.6673228346456693, 'class_Acc_8': 0.38888888888888895, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5436.2876, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1048       -8022.375   0.931665    -5436.287598  ...  0.514354  0.837978  5.525913\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  35%|                    | 177/500 [52:44<1:54:03, 21.19s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.510082591150964, 'Train_Acc': 0.9305783102918587, 'val_Acc': 0.8383757961783439, 'test_Acc': 0.506877990430622, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5515370705244123, 'class_Acc_2': 0.49291166848418755, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.4513556618819776, 'class_Acc_6': nan, 'class_Acc_7': 0.702755905511811, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-5469.3965, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1066    -8010.943848   0.930578    -5469.396484  ...  0.506878  0.838376  5.510083\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  36%|                    | 180/500 [53:55<1:54:28, 21.47s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.491195120723076, 'Train_Acc': 0.9301206758832565, 'val_Acc': 0.8419585987261147, 'test_Acc': 0.5146531100478469, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5153707052441229, 'class_Acc_2': 0.47546346782987997, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.5159489633173844, 'class_Acc_6': nan, 'class_Acc_7': 0.6791338582677166, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5516.2637, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1084    -8090.397461   0.930121    -5516.263672  ...  0.514653  0.841959  5.491195\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  37%|                    | 183/500 [55:04<1:52:12, 21.24s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.488767852064601, 'Train_Acc': 0.9374839938556068, 'val_Acc': 0.8423566878980892, 'test_Acc': 0.4772727272727273, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5768535262206148, 'class_Acc_2': 0.4329334787350054, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.40350877192982454, 'class_Acc_6': nan, 'class_Acc_7': 0.7185039370078741, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5533.579, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1102    -8108.795898   0.937484    -5533.579102  ...  0.477273  0.842357  5.488768\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  37%|                    | 186/500 [56:14<1:50:59, 21.21s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.479816990693565, 'Train_Acc': 0.9319749923195084, 'val_Acc': 0.839968152866242, 'test_Acc': 0.49700956937799046, 'class_Acc_0': 0.0, 'class_Acc_1': 0.589511754068716, 'class_Acc_2': 0.47546346782987997, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.4338118022328548, 'class_Acc_6': nan, 'class_Acc_7': 0.687007874015748, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5561.7075, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1120    -8090.053711   0.931975     -5561.70752  ...   0.49701  0.839968  5.479817\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  38%|                    | 189/500 [57:23<1:49:24, 21.11s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.4830879447820395, 'Train_Acc': 0.9353878955453149, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.48564593301435405, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5732368896925859, 'class_Acc_2': 0.47001090512540883, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.39553429027113235, 'class_Acc_6': nan, 'class_Acc_7': 0.7322834645669292, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5530.686, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1138    -8179.411133   0.935388    -5530.686035  ...  0.485646  0.841162  5.483088\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  38%|                   | 192/500 [58:34<1:49:41, 21.37s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.476916337724799, 'Train_Acc': 0.9343574807987711, 'val_Acc': 0.8395700636942676, 'test_Acc': 0.48235645933014354, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5533453887884268, 'class_Acc_2': 0.5147219193020719, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3620414673046252, 'class_Acc_6': nan, 'class_Acc_7': 0.7342519685039371, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5562.652, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1156    -8136.646484   0.934357    -5562.651855  ...  0.482356  0.83957  5.476916\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  39%|                   | 195/500 [59:43<1:47:19, 21.11s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.4570041405458625, 'Train_Acc': 0.9353639938556069, 'val_Acc': 0.839968152866242, 'test_Acc': 0.4644138755980861, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.4773960216998191, 'class_Acc_2': 0.4460196292257361, 'class_Acc_3': 0.08823529411764706, 'class_Acc_4': nan, 'class_Acc_5': 0.430622009569378, 'class_Acc_6': nan, 'class_Acc_7': 0.6456692913385828, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6395.565, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1175    -8797.836914   0.935364    -6395.564941  ...  0.464414  0.839968  5.457004\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  40%|                  | 198/500 [1:00:53<1:47:15, 21.31s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.412716408405241, 'Train_Acc': 0.9358439938556068, 'val_Acc': 0.8423566878980892, 'test_Acc': 0.49700956937799046, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5641952983725136, 'class_Acc_2': 0.48636859323882214, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.4449760765550239, 'class_Acc_6': nan, 'class_Acc_7': 0.6535433070866142, 'class_Acc_8': 0.4444444444444444, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-6514.9775, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1193    -8968.962891   0.935844    -6514.977539  ...   0.49701  0.842357  5.412716\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  40%|                  | 201/500 [1:02:01<1:45:07, 21.09s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.398954215428115, 'Train_Acc': 0.940279262672811, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.458133971291866, 'class_Acc_0': 0.0, 'class_Acc_1': 0.6419529837251357, 'class_Acc_2': 0.3827699018538713, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3963317384370016, 'class_Acc_6': nan, 'class_Acc_7': 0.6318897637795274, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6526.7056, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1211    -8961.116211   0.940279    -6526.705566  ...  0.458134  0.841162  5.398954\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  41%|                 | 205/500 [1:03:28<1:37:20, 19.80s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.399782168343833, 'Train_Acc': 0.9368263594470047, 'val_Acc': 0.8407643312101911, 'test_Acc': 0.4880382775119617, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5587703435804702, 'class_Acc_2': 0.46455834242093785, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.456140350877193, 'class_Acc_6': nan, 'class_Acc_7': 0.6220472440944882, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5983.02, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1230     -8627.03418   0.936826     -5983.02002  ...  0.488038  0.840764  5.399782\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  42%|                 | 208/500 [1:04:38<1:41:41, 20.90s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.38003786292177, 'Train_Acc': 0.9246854070660523, 'val_Acc': 0.839171974522293, 'test_Acc': 0.5080741626794258, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5117540687160941, 'class_Acc_2': 0.42420937840785167, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.5295055821371611, 'class_Acc_6': nan, 'class_Acc_7': 0.702755905511811, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6008.675, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1248     -8687.75293   0.924685    -6008.674805  ...  0.508074  0.839172  5.380038\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  42%|                 | 211/500 [1:05:47<1:41:17, 21.03s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.371927164776045, 'Train_Acc': 0.9414041167434716, 'val_Acc': 0.8423566878980892, 'test_Acc': 0.4611244019138756, 'class_Acc_0': 0.0, 'class_Acc_1': 0.6256781193490054, 'class_Acc_2': 0.45801526717557245, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3492822966507177, 'class_Acc_6': nan, 'class_Acc_7': 0.6397637795275591, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.13513513513513514, 'Unlab_loss(mb)': array(-5749.386, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1267    -8533.369141   0.941404     -5749.38623  ...  0.461124  0.842357  5.371927\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  43%|                 | 214/500 [1:06:57<1:40:06, 21.00s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.356721102689799, 'Train_Acc': 0.9438649462365591, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.4623205741626794, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5913200723327305, 'class_Acc_2': 0.47764449291166844, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3524720893141946, 'class_Acc_6': nan, 'class_Acc_7': 0.6515748031496064, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-5867.38, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1286    -8613.761719   0.943865    -5867.379883  ...  0.462321  0.841162  5.356721\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  43%|                 | 217/500 [1:08:07<1:39:56, 21.19s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.333972356667449, 'Train_Acc': 0.9406103840245775, 'val_Acc': 0.8415605095541401, 'test_Acc': 0.4644138755980861, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5804701627486437, 'class_Acc_2': 0.42966194111232275, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.386762360446571, 'class_Acc_6': nan, 'class_Acc_7': 0.6791338582677166, 'class_Acc_8': 0.27777777777777773, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-5900.7896, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1304    -8670.083008    0.94061    -5900.789551  ...  0.464414  0.841561  5.333972\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  44%|                | 220/500 [1:09:16<1:38:21, 21.08s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.307597853137551, 'Train_Acc': 0.93698955453149, 'val_Acc': 0.8423566878980892, 'test_Acc': 0.4820574162679426, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5515370705244123, 'class_Acc_2': 0.45038167938931295, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.441786283891547, 'class_Acc_6': nan, 'class_Acc_7': 0.655511811023622, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5773.069, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1323    -8625.483398    0.93699    -5773.068848  ...  0.482057  0.842357  5.307598\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  45%|                | 223/500 [1:10:27<1:38:11, 21.27s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.312664896804111, 'Train_Acc': 0.9446009216589862, 'val_Acc': 0.8407643312101911, 'test_Acc': 0.44766746411483255, 'class_Acc_0': 0.0, 'class_Acc_1': 0.6057866184448463, 'class_Acc_2': 0.41221374045801523, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3652312599681021, 'class_Acc_6': nan, 'class_Acc_7': 0.6299212598425198, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-5888.7173, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1342    -8753.205078   0.944601    -5888.717285  ...  0.447667  0.840764  5.312665\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  45%|                | 226/500 [1:11:36<1:36:47, 21.19s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.292990096221258, 'Train_Acc': 0.9443928725038402, 'val_Acc': 0.8387738853503185, 'test_Acc': 0.45424641148325356, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5605786618444846, 'class_Acc_2': 0.43402399127589963, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3771929824561403, 'class_Acc_6': nan, 'class_Acc_7': 0.6456692913385828, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6796.0386, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1361    -9392.865234   0.944393    -6796.038574  ...  0.454246  0.838774  5.29299\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  46%|                | 230/500 [1:13:03<1:29:22, 19.86s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.273375173118131, 'Train_Acc': 0.9423271889400922, 'val_Acc': 0.8375796178343949, 'test_Acc': 0.45962918660287083, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5985533453887883, 'class_Acc_2': 0.44383860414394766, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3748006379585327, 'class_Acc_6': nan, 'class_Acc_7': 0.6299212598425198, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6246.6094, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1380    -9049.587891   0.942327    -6246.609375  ...  0.459629  0.83758  5.273375\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  47%|                | 233/500 [1:14:13<1:32:56, 20.89s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.243042181144336, 'Train_Acc': 0.940959262672811, 'val_Acc': 0.8423566878980892, 'test_Acc': 0.4569377990430622, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5479204339963833, 'class_Acc_2': 0.4187568157033806, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.4074960127591707, 'class_Acc_6': nan, 'class_Acc_7': 0.6338582677165356, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6006.4575, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1399    -8941.149414   0.940959     -6006.45752  ...  0.456938  0.842357  5.243042\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  47%|               | 236/500 [1:15:23<1:32:34, 21.04s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.272722860809604, 'Train_Acc': 0.945767311827957, 'val_Acc': 0.8371815286624203, 'test_Acc': 0.4479665071770335, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.6184448462929476, 'class_Acc_2': 0.420937840785169, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.35406698564593303, 'class_Acc_6': nan, 'class_Acc_7': 0.6259842519685039, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6051.0273, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1418    -8903.105469   0.945767    -6051.027344  ...  0.447967  0.837182  5.272723\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  48%|               | 239/500 [1:16:34<1:33:21, 21.46s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.234572218120262, 'Train_Acc': 0.9436328725038402, 'val_Acc': 0.8359872611464968, 'test_Acc': 0.4548444976076555, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5985533453887883, 'class_Acc_2': 0.4078516902944384, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.37958532695374797, 'class_Acc_6': nan, 'class_Acc_7': 0.6496062992125985, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-5937.778, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1437     -8861.19043   0.943633    -5937.777832  ...  0.454844  0.835987  5.234572\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  48%|               | 242/500 [1:17:43<1:31:21, 21.25s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.22018401196296, 'Train_Acc': 0.9460281413210445, 'val_Acc': 0.839968152866242, 'test_Acc': 0.42613636363636365, 'class_Acc_0': 0.0, 'class_Acc_1': 0.6238698010849908, 'class_Acc_2': 0.44383860414394766, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.2894736842105263, 'class_Acc_6': nan, 'class_Acc_7': 0.5964566929133859, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6108.688, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1456    -8966.949219   0.946028    -6108.687988  ...  0.426136  0.839968  5.220184\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  49%|               | 245/500 [1:18:53<1:30:30, 21.30s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.21361416096214, 'Train_Acc': 0.9445096774193549, 'val_Acc': 0.8383757961783439, 'test_Acc': 0.4363038277511962, 'class_Acc_0': 0.0, 'class_Acc_1': 0.620253164556962, 'class_Acc_2': 0.4416575790621592, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3181818181818182, 'class_Acc_6': nan, 'class_Acc_7': 0.5984251968503937, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6967.093, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1475    -9646.522461    0.94451    -6967.092773  ...  0.436304  0.838376  5.213614\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  50%|               | 249/500 [1:20:20<1:24:01, 20.09s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.209569261096522, 'Train_Acc': 0.9471113364055299, 'val_Acc': 0.8379777070063694, 'test_Acc': 0.45245215311004783, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5497287522603979, 'class_Acc_2': 0.45583424209378404, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.37799043062200954, 'class_Acc_6': nan, 'class_Acc_7': 0.610236220472441, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6374.942, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1494    -9244.055664   0.947111    -6374.941895  ...  0.452452  0.837978  5.209569\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  50%|               | 252/500 [1:21:29<1:26:22, 20.90s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.236039333780334, 'Train_Acc': 0.9468777265745009, 'val_Acc': 0.839171974522293, 'test_Acc': 0.4485645933014354, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5587703435804702, 'class_Acc_2': 0.4133042529989094, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.4059011164274322, 'class_Acc_6': nan, 'class_Acc_7': 0.578740157480315, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6009.743, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1513     -9013.55957   0.946878    -6009.743164  ...  0.448565  0.839172  5.236039\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  51%|              | 255/500 [1:22:39<1:26:34, 21.20s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.196400911830075, 'Train_Acc': 0.9439768970814132, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.4623205741626794, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5135623869801085, 'class_Acc_2': 0.42857142857142855, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.4513556618819776, 'class_Acc_6': nan, 'class_Acc_7': 0.5866141732283464, 'class_Acc_8': 0.05555555555555555, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6195.5864, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1532    -9175.261719   0.943977    -6195.586426  ...  0.462321  0.841162  5.196401\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  52%|              | 258/500 [1:23:51<1:27:19, 21.65s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.195333918622751, 'Train_Acc': 0.9492489708141322, 'val_Acc': 0.8395700636942676, 'test_Acc': 0.4318181818181818, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.6148282097649186, 'class_Acc_2': 0.39803707742639033, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.35007974481658694, 'class_Acc_6': nan, 'class_Acc_7': 0.5728346456692914, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6019.532, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1551    -9061.541992   0.949249    -6019.532227  ...  0.431818  0.83957  5.195334\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  52%|              | 261/500 [1:25:00<1:24:47, 21.29s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.171899751567791, 'Train_Acc': 0.9489161904761906, 'val_Acc': 0.8407643312101911, 'test_Acc': 0.4270334928229665, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5840867992766726, 'class_Acc_2': 0.3936750272628135, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3349282296650718, 'class_Acc_6': nan, 'class_Acc_7': 0.6220472440944882, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6207.965, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1570    -9211.057617   0.948916    -6207.964844  ...  0.427033  0.840764   5.1719\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  53%|              | 265/500 [1:26:27<1:18:25, 20.02s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.140880399306802, 'Train_Acc': 0.9436296774193549, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.4751794258373206, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.4918625678119348, 'class_Acc_2': 0.4689203925845147, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.4473684210526316, 'class_Acc_6': nan, 'class_Acc_7': 0.6279527559055119, 'class_Acc_8': 0.05555555555555555, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-6528.256, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1590    -9424.387695    0.94363    -6528.255859  ...  0.475179  0.841162  5.14088\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  54%|              | 268/500 [1:27:37<1:20:49, 20.90s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.1343814620270685, 'Train_Acc': 0.9490489708141322, 'val_Acc': 0.8439490445859873, 'test_Acc': 0.4410885167464115, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5135623869801085, 'class_Acc_2': 0.4165757906215921, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.39712918660287083, 'class_Acc_6': nan, 'class_Acc_7': 0.6003937007874016, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6234.468, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1609     -9288.97168   0.949049    -6234.467773  ...  0.441089  0.843949  5.134381\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  54%|             | 271/500 [1:28:48<1:21:30, 21.35s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.1231094677655395, 'Train_Acc': 0.9474745314900154, 'val_Acc': 0.8435509554140127, 'test_Acc': 0.4536483253588517, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5063291139240507, 'class_Acc_2': 0.395856052344602, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.4449760765550239, 'class_Acc_6': nan, 'class_Acc_7': 0.612204724409449, 'class_Acc_8': 0.05555555555555555, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6363.505, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1628    -9412.120117   0.947475    -6363.504883  ...  0.453648  0.843551  5.123109\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  55%|             | 274/500 [1:29:58<1:19:39, 21.15s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.112649224278156, 'Train_Acc': 0.9519242396313364, 'val_Acc': 0.8387738853503185, 'test_Acc': 0.42045454545454547, 'class_Acc_0': 0.0, 'class_Acc_1': 0.566003616636528, 'class_Acc_2': 0.43729552889858225, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.30940988835725675, 'class_Acc_6': nan, 'class_Acc_7': 0.5846456692913387, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6325.815, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1648    -9298.638672   0.951924    -6325.814941  ...  0.420455  0.838774  5.112649\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  56%|             | 278/500 [1:31:24<1:13:39, 19.91s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.104421119309441, 'Train_Acc': 0.9457496774193549, 'val_Acc': 0.8419585987261147, 'test_Acc': 0.46620813397129185, 'class_Acc_0': 0.0, 'class_Acc_1': 0.4918625678119348, 'class_Acc_2': 0.440567066521265, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.4609250398724083, 'class_Acc_6': nan, 'class_Acc_7': 0.5846456692913387, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6609.7734, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1668    -9589.652344    0.94575    -6609.773438  ...  0.466208  0.841959  5.104421\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  56%|             | 281/500 [1:32:35<1:16:22, 20.93s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.088152760288792, 'Train_Acc': 0.9504185560675884, 'val_Acc': 0.8379777070063694, 'test_Acc': 0.43600478468899523, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5714285714285714, 'class_Acc_2': 0.38604143947655395, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3835725677830941, 'class_Acc_6': nan, 'class_Acc_7': 0.5866141732283464, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6319.2773, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1687    -9407.397461   0.950419    -6319.277344  ...  0.436005  0.837978  5.088153\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  57%|             | 284/500 [1:33:46<1:17:45, 21.60s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.082042439593152, 'Train_Acc': 0.9494602150537635, 'val_Acc': 0.8423566878980892, 'test_Acc': 0.44886363636363635, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.48282097649186256, 'class_Acc_2': 0.4078516902944384, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.41626794258373206, 'class_Acc_6': nan, 'class_Acc_7': 0.6456692913385828, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.13513513513513514, 'Unlab_loss(mb)': array(-6452.995, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1706    -9557.922852    0.94946    -6452.995117  ...  0.448864  0.842357  5.082042\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  57%|            | 287/500 [1:34:54<1:14:33, 21.00s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.0558670580350435, 'Train_Acc': 0.9523034101382488, 'val_Acc': 0.8383757961783439, 'test_Acc': 0.4192583732057416, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5497287522603979, 'class_Acc_2': 0.40348964013086147, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3189792663476874, 'class_Acc_6': nan, 'class_Acc_7': 0.6259842519685039, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6449.0166, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1726    -9478.180664   0.952303    -6449.016602  ...  0.419258  0.838376  5.055867\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  58%|            | 291/500 [1:36:21<1:09:37, 19.99s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.125590273935297, 'Train_Acc': 0.9532713364055299, 'val_Acc': 0.8419585987261147, 'test_Acc': 0.43720095693779903, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.4990958408679928, 'class_Acc_2': 0.4231188658669574, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3700159489633174, 'class_Acc_6': nan, 'class_Acc_7': 0.6358267716535433, 'class_Acc_8': 0.27777777777777773, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6570.5, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1746    -9593.883789   0.953271         -6570.5  ...  0.437201  0.841959  5.12559\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  59%|            | 294/500 [1:37:30<1:11:10, 20.73s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.06788998633641, 'Train_Acc': 0.9519481413210445, 'val_Acc': 0.8435509554140127, 'test_Acc': 0.4267344497607656, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.488245931283906, 'class_Acc_2': 0.3609596510359869, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.38118022328548645, 'class_Acc_6': nan, 'class_Acc_7': 0.6712598425196852, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6478.119, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1766    -9614.613281   0.951948    -6478.119141  ...  0.426734  0.843551  5.06789\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  59%|            | 297/500 [1:38:39<1:09:50, 20.64s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.0359381890872426, 'Train_Acc': 0.949887311827957, 'val_Acc': 0.8439490445859873, 'test_Acc': 0.43989234449760767, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5117540687160941, 'class_Acc_2': 0.3969465648854961, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.4059011164274322, 'class_Acc_6': nan, 'class_Acc_7': 0.6023622047244095, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6489.8247, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1786    -9618.666016   0.949887    -6489.824707  ...  0.439892  0.843949  5.035938\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  60%|            | 300/500 [1:39:49<1:10:40, 21.20s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.040849786120165, 'Train_Acc': 0.9512634101382489, 'val_Acc': 0.8415605095541401, 'test_Acc': 0.44348086124401914, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5099457504520795, 'class_Acc_2': 0.4133042529989094, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.4074960127591707, 'class_Acc_6': nan, 'class_Acc_7': 0.5885826771653544, 'class_Acc_8': 0.3333333333333333, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7338.6772, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1805   -10196.732422   0.951263    -7338.677246  ...  0.443481  0.841561  5.04085\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  61%|           | 304/500 [1:41:14<1:04:26, 19.73s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.051556818749471, 'Train_Acc': 0.9520281413210445, 'val_Acc': 0.8395700636942676, 'test_Acc': 0.4333133971291866, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5280289330922242, 'class_Acc_2': 0.40239912758996726, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.37081339712918665, 'class_Acc_6': nan, 'class_Acc_7': 0.6161417322834646, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6398.6074, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1825    -9528.509766   0.952028    -6398.607422  ...  0.433313  0.83957  5.051557\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  61%|           | 307/500 [1:42:23<1:06:14, 20.59s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.028033187695392, 'Train_Acc': 0.9540666052227342, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.41626794258373206, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5714285714285714, 'class_Acc_2': 0.3871319520174482, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3317384370015949, 'class_Acc_6': nan, 'class_Acc_7': 0.5826771653543308, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6370.52, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1845    -9583.648438   0.954067     -6370.52002  ...  0.416268  0.841162  5.028033\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  62%|           | 310/500 [1:43:33<1:06:56, 21.14s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.018838824573478, 'Train_Acc': 0.9522378494623656, 'val_Acc': 0.8379777070063694, 'test_Acc': 0.4366028708133971, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5207956600361664, 'class_Acc_2': 0.4274809160305344, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.37400318979266345, 'class_Acc_6': nan, 'class_Acc_7': 0.5905511811023623, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6531.432, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1864    -9681.069336   0.952238    -6531.432129  ...  0.436603  0.837978  5.018839\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  63%|           | 314/500 [1:45:01<1:02:21, 20.12s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.019308921492725, 'Train_Acc': 0.9550217511520737, 'val_Acc': 0.8419585987261147, 'test_Acc': 0.4123803827751196, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5678119349005425, 'class_Acc_2': 0.3882224645583424, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.32854864433811803, 'class_Acc_6': nan, 'class_Acc_7': 0.5629921259842521, 'class_Acc_8': 0.27777777777777773, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6784.4565, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1884    -9939.945312   0.955022    -6784.456543  ...   0.41238  0.841959  5.019309\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  63%|           | 317/500 [1:46:10<1:03:36, 20.85s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.001651874569762, 'Train_Acc': 0.9543338248847926, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.42942583732057416, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5280289330922242, 'class_Acc_2': 0.3882224645583424, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3891547049441787, 'class_Acc_6': nan, 'class_Acc_7': 0.5748031496062992, 'class_Acc_8': 0.05555555555555555, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6613.746, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1904     -9764.65918   0.954334    -6613.746094  ...  0.429426  0.841162  5.001652\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  64%|          | 320/500 [1:47:19<1:02:50, 20.94s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.9880561644676344, 'Train_Acc': 0.9543417511520736, 'val_Acc': 0.839171974522293, 'test_Acc': 0.4249401913875598, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5822784810126582, 'class_Acc_2': 0.37513631406761166, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.35964912280701755, 'class_Acc_6': nan, 'class_Acc_7': 0.5826771653543308, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6593.7734, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1924    -9792.376953   0.954342    -6593.773438  ...   0.42494  0.839172  4.988056\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  65%|           | 324/500 [1:48:46<59:08, 20.16s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.977521719868123, 'Train_Acc': 0.9552234101382489, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.416866028708134, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5515370705244123, 'class_Acc_2': 0.3696837513631407, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3444976076555024, 'class_Acc_6': nan, 'class_Acc_7': 0.610236220472441, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6867.7983, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1944   -10022.702148   0.955223     -6867.79834  ...  0.416866  0.840366  4.977522\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  65%|          | 327/500 [1:49:56<1:00:22, 20.94s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.975937432198709, 'Train_Acc': 0.9558921658986176, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.40879186602870815, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5641952983725136, 'class_Acc_2': 0.36205016357688113, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3293460925039872, 'class_Acc_6': nan, 'class_Acc_7': 0.594488188976378, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6664.274, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1964    -9910.230469   0.955892    -6664.273926  ...  0.408792  0.840366  4.975937\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  66%|           | 330/500 [1:51:05<59:39, 21.06s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.973391113021723, 'Train_Acc': 0.9546682642089094, 'val_Acc': 0.839968152866242, 'test_Acc': 0.41537081339712917, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5949367088607596, 'class_Acc_2': 0.35877862595419846, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3333333333333333, 'class_Acc_6': nan, 'class_Acc_7': 0.6023622047244095, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6628.8086, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1984    -9760.805664   0.954668    -6628.808594  ...  0.415371  0.839968  4.973391\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  67%|          | 334/500 [1:52:32<54:59, 19.88s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.96288648975525, 'Train_Acc': 0.9541609216589861, 'val_Acc': 0.8415605095541401, 'test_Acc': 0.42613636363636365, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5497287522603979, 'class_Acc_2': 0.401308615049073, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3508771929824561, 'class_Acc_6': nan, 'class_Acc_7': 0.5984251968503937, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-6907.1396, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2004   -10080.581055   0.954161    -6907.139648  ...  0.426136  0.841561  4.962886\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  67%|          | 337/500 [1:53:42<56:27, 20.78s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.950085154217467, 'Train_Acc': 0.9567338248847925, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.41208133971291866, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5551537070524412, 'class_Acc_2': 0.3609596510359869, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.34051036682615626, 'class_Acc_6': nan, 'class_Acc_7': 0.5964566929133859, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-6730.359, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2024   -10012.177734   0.956734    -6730.358887  ...  0.412081  0.840366  4.950085\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  68%|          | 340/500 [1:54:52<56:18, 21.11s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.94226750350192, 'Train_Acc': 0.9559131182795699, 'val_Acc': 0.8443471337579618, 'test_Acc': 0.4267344497607656, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5135623869801085, 'class_Acc_2': 0.38167938931297707, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.38995215311004783, 'class_Acc_6': nan, 'class_Acc_7': 0.578740157480315, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-6699.797, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2044    -9906.414062   0.955913    -6699.796875  ...  0.426734  0.844347  4.942268\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  69%|          | 344/500 [1:56:19<51:50, 19.94s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.936822879492627, 'Train_Acc': 0.9547753609831029, 'val_Acc': 0.8407643312101911, 'test_Acc': 0.41866028708133973, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5135623869801085, 'class_Acc_2': 0.3784078516902944, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3676236044657098, 'class_Acc_6': nan, 'class_Acc_7': 0.5885826771653544, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-6958.49, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2064   -10214.755859   0.954775    -6958.490234  ...   0.41866  0.840764  4.936823\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  69%|         | 347/500 [1:57:28<52:53, 20.74s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.937629464366562, 'Train_Acc': 0.9564874347158219, 'val_Acc': 0.839968152866242, 'test_Acc': 0.40938995215311, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5840867992766726, 'class_Acc_2': 0.346782988004362, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.35167464114832536, 'class_Acc_6': nan, 'class_Acc_7': 0.547244094488189, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6747.4204, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2084   -10063.380859   0.956487     -6747.42041  ...   0.40939  0.839968  4.937629\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  70%|         | 350/500 [1:58:37<51:47, 20.72s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.914400054810895, 'Train_Acc': 0.9561898003072197, 'val_Acc': 0.8419585987261147, 'test_Acc': 0.41537081339712917, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5551537070524412, 'class_Acc_2': 0.3784078516902944, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.34529505582137154, 'class_Acc_6': nan, 'class_Acc_7': 0.5767716535433072, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6748.0557, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","2104   -10086.771484    0.95619    -6748.055664  ...  0.415371  0.841959   4.9144\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  71%|         | 354/500 [2:00:06<48:47, 20.05s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.904029979763568, 'Train_Acc': 0.9575418740399385, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.40938995215311, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5696202531645569, 'class_Acc_2': 0.401308615049073, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.31738437001594894, 'class_Acc_6': nan, 'class_Acc_7': 0.5551181102362205, 'class_Acc_8': 0.05555555555555555, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7022.215, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","2124   -10197.702148   0.957542    -7022.214844  ...   0.40939  0.841162  4.90403\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  71%|         | 357/500 [2:01:15<49:27, 20.75s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.908643363466098, 'Train_Acc': 0.9560666052227342, 'val_Acc': 0.8439490445859873, 'test_Acc': 0.416866028708134, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5388788426763109, 'class_Acc_2': 0.3729552889858233, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.36682615629984056, 'class_Acc_6': nan, 'class_Acc_7': 0.5649606299212598, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6804.683, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2144   -10153.591797   0.956067    -6804.683105  ...  0.416866  0.843949  4.908643\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  72%|         | 360/500 [2:02:24<48:37, 20.84s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.88575842552908, 'Train_Acc': 0.9586571428571429, 'val_Acc': 0.8415605095541401, 'test_Acc': 0.4061004784688995, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5678119349005425, 'class_Acc_2': 0.3631406761177753, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3389154704944179, 'class_Acc_6': nan, 'class_Acc_7': 0.547244094488189, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6803.688, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2164   -10124.226562   0.958657    -6803.687988  ...    0.4061  0.841561  4.885758\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  73%|        | 364/500 [2:03:50<44:47, 19.76s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.8814695542852915, 'Train_Acc': 0.9572698003072198, 'val_Acc': 0.8427547770700637, 'test_Acc': 0.4201555023923445, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5352622061482821, 'class_Acc_2': 0.395856052344602, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.36682615629984056, 'class_Acc_6': nan, 'class_Acc_7': 0.5492125984251969, 'class_Acc_8': 0.05555555555555555, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-7069.1904, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","2184   -10358.081055    0.95727     -7069.19043  ...  0.420156  0.842755  4.88147\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  73%|        | 367/500 [2:05:00<45:54, 20.71s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.89135614803555, 'Train_Acc': 0.95915311827957, 'val_Acc': 0.8431528662420382, 'test_Acc': 0.4138755980861244, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5443037974683544, 'class_Acc_2': 0.3576881134133042, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3636363636363636, 'class_Acc_6': nan, 'class_Acc_7': 0.5688976377952757, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6852.9326, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2204    -10203.69043   0.959153    -6852.932617  ...  0.413876  0.843153  4.891356\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  74%|        | 370/500 [2:06:09<45:05, 20.81s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.865056080431428, 'Train_Acc': 0.9583963133640553, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.40879186602870815, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5678119349005425, 'class_Acc_2': 0.36423118865866955, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3373205741626794, 'class_Acc_6': nan, 'class_Acc_7': 0.5649606299212598, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6852.414, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2224   -10193.132812   0.958396    -6852.414062  ...  0.408792  0.841162  4.865056\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  75%|        | 374/500 [2:07:36<41:47, 19.90s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.876111106884072, 'Train_Acc': 0.9582442396313364, 'val_Acc': 0.8415605095541401, 'test_Acc': 0.4117822966507177, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5587703435804702, 'class_Acc_2': 0.3522355507088331, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3588516746411483, 'class_Acc_6': nan, 'class_Acc_7': 0.5629921259842521, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-7084.7495, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2244   -10410.671875   0.958244    -7084.749512  ...  0.411782  0.841561  4.876111\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  75%|       | 377/500 [2:08:45<42:37, 20.80s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.863649077064727, 'Train_Acc': 0.9587595084485407, 'val_Acc': 0.8407643312101911, 'test_Acc': 0.4072966507177033, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5551537070524412, 'class_Acc_2': 0.3456924754634678, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3588516746411483, 'class_Acc_6': nan, 'class_Acc_7': 0.5511811023622049, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6912.148, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2264   -10293.383789    0.95876    -6912.147949  ...  0.407297  0.840764  4.863649\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  76%|       | 380/500 [2:09:57<42:43, 21.36s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.8523575932705825, 'Train_Acc': 0.9591435330261135, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.40669856459330145, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5515370705244123, 'class_Acc_2': 0.36532170119956375, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.34688995215311, 'class_Acc_6': nan, 'class_Acc_7': 0.5413385826771654, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.1081081081081081, 'Unlab_loss(mb)': array(-6876.7983, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2284   -10308.577148   0.959144     -6876.79834  ...  0.406699  0.840366  4.852358\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  77%|       | 384/500 [2:11:22<37:57, 19.63s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.86083835772237, 'Train_Acc': 0.9581082642089094, 'val_Acc': 0.8415605095541401, 'test_Acc': 0.4105861244019139, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5171790235081374, 'class_Acc_2': 0.3685932388222464, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3604465709728868, 'class_Acc_6': nan, 'class_Acc_7': 0.5649606299212598, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.08108108108108109, 'Unlab_loss(mb)': array(-6782.871, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2305   -10231.724609   0.958108    -6782.871094  ...  0.410586  0.841561  4.860838\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  77%|       | 387/500 [2:12:30<38:32, 20.46s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.85047603152536, 'Train_Acc': 0.9594827035330261, 'val_Acc': 0.8419585987261147, 'test_Acc': 0.4069976076555024, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5696202531645569, 'class_Acc_2': 0.346782988004362, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3444976076555024, 'class_Acc_6': nan, 'class_Acc_7': 0.5649606299212598, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6748.5503, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2325   -10214.273438   0.959483    -6748.550293  ...  0.406998  0.841959  4.850476\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  78%|       | 390/500 [2:13:39<38:10, 20.83s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.836537493500105, 'Train_Acc': 0.9589595084485407, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.4144736842105263, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5551537070524412, 'class_Acc_2': 0.35877862595419846, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.35964912280701755, 'class_Acc_6': nan, 'class_Acc_7': 0.5708661417322834, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7783.95, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2345   -10942.961914    0.95896    -7783.950195  ...  0.414474  0.840366  4.836537\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  79%|      | 394/500 [2:15:06<35:09, 19.90s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.833838780266879, 'Train_Acc': 0.9579386789554533, 'val_Acc': 0.8419585987261147, 'test_Acc': 0.4105861244019139, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5461121157323688, 'class_Acc_2': 0.3718647764449291, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.35167464114832536, 'class_Acc_6': nan, 'class_Acc_7': 0.5531496062992126, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6846.019, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2365    -10284.12793   0.957939    -6846.019043  ...  0.410586  0.841959  4.833839\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  79%|      | 397/500 [2:16:16<35:39, 20.77s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.830535656708907, 'Train_Acc': 0.9597915821812596, 'val_Acc': 0.839968152866242, 'test_Acc': 0.4072966507177033, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5515370705244123, 'class_Acc_2': 0.3500545256270447, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.35406698564593303, 'class_Acc_6': nan, 'class_Acc_7': 0.5590551181102362, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6791.0493, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2385   -10274.983398   0.959792    -6791.049316  ...  0.407297  0.839968  4.830536\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  80%|      | 400/500 [2:17:25<34:48, 20.88s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.819326827318146, 'Train_Acc': 0.959162703533026, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.4040071770334928, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5388788426763109, 'class_Acc_2': 0.3609596510359869, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3444976076555024, 'class_Acc_6': nan, 'class_Acc_7': 0.5531496062992126, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7824.344, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2405   -11016.152344   0.959163    -7824.344238  ...  0.404007  0.841162  4.819327\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  81%|      | 404/500 [2:18:51<31:42, 19.82s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.824308164003924, 'Train_Acc': 0.9575946543778802, 'val_Acc': 0.8407643312101911, 'test_Acc': 0.4084928229665072, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5081374321880651, 'class_Acc_2': 0.3762268266085059, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3524720893141946, 'class_Acc_6': nan, 'class_Acc_7': 0.5728346456692914, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6987.0254, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2426   -10436.328125   0.957595    -6987.025391  ...  0.408493  0.840764  4.824308\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  81%|      | 407/500 [2:20:02<32:29, 20.96s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.818315719758564, 'Train_Acc': 0.9598570199692781, 'val_Acc': 0.8407643312101911, 'test_Acc': 0.39952153110047844, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5443037974683544, 'class_Acc_2': 0.3391494002181026, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3437001594896332, 'class_Acc_6': nan, 'class_Acc_7': 0.5669291338582678, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6949.132, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2446   -10440.676758   0.959857    -6949.131836  ...  0.399522  0.840764  4.818316\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  82%|     | 411/500 [2:21:28<29:36, 19.96s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.807868860649002, 'Train_Acc': 0.9599482642089094, 'val_Acc': 0.8423566878980892, 'test_Acc': 0.40131578947368424, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5406871609403254, 'class_Acc_2': 0.3413304252998909, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3508771929824561, 'class_Acc_6': nan, 'class_Acc_7': 0.5551181102362205, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7222.4526, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2466    -10617.24707   0.959948    -7222.452637  ...  0.401316  0.842357  4.807869\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  83%|     | 414/500 [2:22:37<29:36, 20.66s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.808447206659046, 'Train_Acc': 0.959186728110599, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.402811004784689, 'class_Acc_0': 0.08695652173913043, 'class_Acc_1': 0.5334538878842676, 'class_Acc_2': 0.3380588876772082, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3636363636363636, 'class_Acc_6': nan, 'class_Acc_7': 0.5433070866141733, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6843.8613, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2487   -10280.266602   0.959187    -6843.861328  ...  0.402811  0.841162  4.808447\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  84%|     | 418/500 [2:24:02<26:47, 19.60s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.797370107723679, 'Train_Acc': 0.9588538248847925, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.4019138755980861, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5406871609403254, 'class_Acc_2': 0.34896401308615044, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.35007974481658694, 'class_Acc_6': nan, 'class_Acc_7': 0.5492125984251969, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7242.5303, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","2508   -10630.453125   0.958854    -7242.530273  ...  0.401914  0.840366  4.79737\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  84%|     | 421/500 [2:25:14<27:37, 20.98s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.795281205529058, 'Train_Acc': 0.958962703533026, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.40311004784689, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5569620253164557, 'class_Acc_2': 0.3456924754634678, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.35406698564593303, 'class_Acc_6': nan, 'class_Acc_7': 0.5354330708661418, 'class_Acc_8': 0.1111111111111111, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7049.0054, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2528   -10535.918945   0.958963    -7049.005371  ...   0.40311  0.840366  4.795281\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  85%|    | 424/500 [2:26:23<26:34, 20.98s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.7944447993220844, 'Train_Acc': 0.9602250691244238, 'val_Acc': 0.839968152866242, 'test_Acc': 0.39413875598086123, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5678119349005425, 'class_Acc_2': 0.33696837513631406, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3293460925039872, 'class_Acc_6': nan, 'class_Acc_7': 0.5393700787401575, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7871.865, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2549   -11122.112305   0.960225    -7871.865234  ...  0.394139  0.839968  4.794445\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  86%|    | 428/500 [2:27:49<23:40, 19.73s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.792215008939877, 'Train_Acc': 0.9598490937019969, 'val_Acc': 0.839968152866242, 'test_Acc': 0.39952153110047844, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5479204339963833, 'class_Acc_2': 0.3391494002181026, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.34529505582137154, 'class_Acc_6': nan, 'class_Acc_7': 0.5531496062992126, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7055.443, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2570   -10528.854492   0.959849    -7055.442871  ...  0.399522  0.839968  4.792215\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  86%|    | 431/500 [2:28:58<23:48, 20.70s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.791626565943056, 'Train_Acc': 0.9602667281105991, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.3953349282296651, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5623869801084991, 'class_Acc_2': 0.3456924754634678, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.33253588516746413, 'class_Acc_6': nan, 'class_Acc_7': 0.531496062992126, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7001.594, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2590   -10526.404297   0.960267    -7001.594238  ...  0.395335  0.840366  4.791627\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  87%|    | 436/500 [2:30:19<16:18, 15.29s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.784852661883883, 'Train_Acc': 0.9593946543778802, 'val_Acc': 0.8407643312101911, 'test_Acc': 0.402811004784689, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5406871609403254, 'class_Acc_2': 0.3522355507088331, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3508771929824561, 'class_Acc_6': nan, 'class_Acc_7': 0.547244094488189, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7074.899, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2618   -10574.704102   0.959395    -7074.898926  ...  0.402811  0.840764  4.784853\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  88%|   | 440/500 [2:31:24<14:50, 14.85s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.781697001295584, 'Train_Acc': 0.9597114592933949, 'val_Acc': 0.8395700636942676, 'test_Acc': 0.39952153110047844, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5497287522603979, 'class_Acc_2': 0.33696837513631406, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3492822966507177, 'class_Acc_6': nan, 'class_Acc_7': 0.5452755905511811, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7899.3447, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","2645   -11178.036133   0.959711    -7899.344727  ...  0.399522  0.83957  4.781697\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  89%|   | 445/500 [2:32:42<12:56, 14.13s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.781054785973834, 'Train_Acc': 0.9602714592933949, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.39712918660287083, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5551537070524412, 'class_Acc_2': 0.3336968375136314, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.3460925039872408, 'class_Acc_6': nan, 'class_Acc_7': 0.5393700787401575, 'class_Acc_8': 0.16666666666666666, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7078.0776, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2672   -10595.378906   0.960271    -7078.077637  ...  0.397129  0.841162  4.781055\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  90%|   | 449/500 [2:33:47<12:14, 14.40s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.776277502346411, 'Train_Acc': 0.9602586789554532, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.39593301435406697, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5461121157323688, 'class_Acc_2': 0.34023991275899673, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.34051036682615626, 'class_Acc_6': nan, 'class_Acc_7': 0.5413385826771654, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7915.7046, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2699   -11185.230469   0.960259     -7915.70459  ...  0.395933  0.840366  4.776278\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  91%|   | 454/500 [2:35:07<11:00, 14.35s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.772923659040907, 'Train_Acc': 0.9599386789554533, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.39952153110047844, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5497287522603979, 'class_Acc_2': 0.34351145038167935, 'class_Acc_3': 0.02941176470588235, 'class_Acc_4': nan, 'class_Acc_5': 0.35007974481658694, 'class_Acc_6': nan, 'class_Acc_7': 0.531496062992126, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6963.2183, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2725   -10533.644531   0.959939    -6963.218262  ...  0.399522  0.841162  4.772924\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  92%|  | 458/500 [2:36:11<10:09, 14.52s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.770163424632435, 'Train_Acc': 0.9599690937019969, 'val_Acc': 0.8407643312101911, 'test_Acc': 0.39892344497607657, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5370705244122965, 'class_Acc_2': 0.3391494002181026, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.35406698564593303, 'class_Acc_6': nan, 'class_Acc_7': 0.5374015748031497, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7047.0776, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2752   -10561.772461   0.959969    -7047.077637  ...  0.398923  0.840764  4.770163\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  93%|  | 463/500 [2:37:28<08:33, 13.87s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.7728067218452095, 'Train_Acc': 0.9599818740399385, 'val_Acc': 0.8407643312101911, 'test_Acc': 0.39922248803827753, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5497287522603979, 'class_Acc_2': 0.34023991275899673, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.34848484848484845, 'class_Acc_6': nan, 'class_Acc_7': 0.5374015748031497, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7096.1104, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2780   -10614.788086   0.959982    -7096.110352  ...  0.399222  0.840764  4.772807\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  93%|  | 467/500 [2:38:34<07:59, 14.54s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.767508856364654, 'Train_Acc': 0.9599082642089094, 'val_Acc': 0.8411624203821656, 'test_Acc': 0.3980263157894737, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5569620253164557, 'class_Acc_2': 0.3347873500545256, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.34688995215311, 'class_Acc_6': nan, 'class_Acc_7': 0.5354330708661418, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7928.5547, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2807   -11184.005859   0.959908    -7928.554688  ...  0.398026  0.841162  4.767509\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  94%| | 472/500 [2:39:53<06:42, 14.36s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.76910230176626, 'Train_Acc': 0.9605899231950845, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.3986244019138756, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5497287522603979, 'class_Acc_2': 0.3380588876772082, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.35167464114832536, 'class_Acc_6': nan, 'class_Acc_7': 0.5295275590551182, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6970.019, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2833   -10532.470703    0.96059    -6970.019043  ...  0.398624  0.840366  4.769102\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  95%| | 476/500 [2:40:58<05:50, 14.59s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.765476544258714, 'Train_Acc': 0.9603835330261136, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.39683014354066987, 'class_Acc_0': 0.043478260869565216, 'class_Acc_1': 0.5388788426763109, 'class_Acc_2': 0.34242093784078514, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.35007974481658694, 'class_Acc_6': nan, 'class_Acc_7': 0.5255905511811023, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7055.8213, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2860    -10562.96582   0.960384    -7055.821289  ...   0.39683  0.840366  4.765477\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  96%| | 481/500 [2:42:16<04:28, 14.11s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.766841515982784, 'Train_Acc': 0.9602522887864824, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.39473684210526316, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5406871609403254, 'class_Acc_2': 0.3336968375136314, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3476874003189792, 'class_Acc_6': nan, 'class_Acc_7': 0.5334645669291339, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6974.3086, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2887   -10528.139648   0.960252    -6974.308594  ...  0.394737  0.840366  4.766842\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  97%| | 485/500 [2:43:21<03:38, 14.54s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.7642531651631685, 'Train_Acc': 0.9600218740399385, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.3944377990430622, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5388788426763109, 'class_Acc_2': 0.3358778625954198, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3476874003189792, 'class_Acc_6': nan, 'class_Acc_7': 0.5295275590551182, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7058.807, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2914   -10528.433594   0.960022    -7058.807129  ...  0.394438  0.840366  4.764253\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  98%|| 490/500 [2:44:38<02:20, 14.06s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.764191878801569, 'Train_Acc': 0.9604090937019969, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.3953349282296651, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5424954792043399, 'class_Acc_2': 0.3336968375136314, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.34848484848484845, 'class_Acc_6': nan, 'class_Acc_7': 0.5334645669291339, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6980.4937, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2941   -10551.685547   0.960409    -6980.493652  ...  0.395335  0.840366  4.764192\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  99%|| 494/500 [2:45:43<01:27, 14.53s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.763877932956896, 'Train_Acc': 0.9603995084485407, 'val_Acc': 0.8403662420382165, 'test_Acc': 0.39503588516746413, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5424954792043399, 'class_Acc_2': 0.3336968375136314, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3492822966507177, 'class_Acc_6': nan, 'class_Acc_7': 0.5295275590551182, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-6934.655, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2967   -10490.705078     0.9604    -6934.654785  ...  0.395036  0.840366  4.763878\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train: 100%|| 499/500 [2:47:00<00:14, 14.02s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.76423790227618, 'Train_Acc': 0.9600986789554532, 'val_Acc': 0.839968152866242, 'test_Acc': 0.395633971291866, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5424954792043399, 'class_Acc_2': 0.33696837513631406, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.34848484848484845, 'class_Acc_6': nan, 'class_Acc_7': 0.5295275590551182, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405, 'Unlab_loss(mb)': array(-7311.4053, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2994   -10776.066406   0.960099    -7311.405273  ...  0.395634  0.839968  4.764238\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train: 100%|| 500/500 [2:47:27<00:00, 20.10s/it]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.764566406566903, 'Train_Acc': 0.9597738248847926, 'val_Acc': 0.839968152866242, 'test_Acc': 0.3953349282296651, 'class_Acc_0': 0.0, 'class_Acc_1': 0.5424954792043399, 'class_Acc_2': 0.3347873500545256, 'class_Acc_3': 0.0588235294117647, 'class_Acc_4': nan, 'class_Acc_5': 0.3492822966507177, 'class_Acc_6': nan, 'class_Acc_7': 0.5295275590551182, 'class_Acc_8': 0.2222222222222222, 'class_Acc_9': 0.05405405405405405}\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2999             NaN   0.959774             NaN  ...  0.395335  0.839968  4.764566\n","\n","[1 rows x 17 columns]\n"]}],"source":["!python3 experiments/train_flows/flowgmm_tabular_new.py --num_classes 10 --metric_name \"Seq-Well\" --trainer_config \"{'unlab_weight':.6}\" --net_config \"{'k':1024,'coupling_layers':7,'nperlayer':1}\" --network RealNVPTabularWPrior --trainer SemiFlow --num_epochs 500 --dataset AG_News --lr 3e-4 --train 200"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["with open(\"/home/anunay18021/SingleCellClassification/tmp/metrics_\" + batch_name + \".pkl\", \"rb\") as f:\n","  D = pickle.load(f)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["rev = list(mapping.keys())\n","new_D = {}\n","for i in D:\n","  try:\n","    new_D[reverse_mapping[int(i.split(\"_\")[-1])]] = D[i]\n","  except:\n","    continue"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["plt.rcParams[\"figure.figsize\"] = (20,5.5)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 2000x550 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.bar(range(len(new_D)), list(new_D.values()))\n","plt.xticks(range(len(new_D)), list(new_D.keys()))\n","plt.show()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["classes_labeled = {}\n","for i in D:\n","  try:\n","        classes_labeled[reverse_mapping[int(i.split(\"_\")[-1])]] = D[i]\n","  except:\n","        classes_labeled[i] = D[i]"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["df = pd.DataFrame(columns = list(classes_labeled.keys()))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_340255/3840281218.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df.append(classes_labeled, ignore_index = True)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>val_bpd</th>\n","      <th>Train_Acc</th>\n","      <th>val_Acc</th>\n","      <th>test_Acc</th>\n","      <th>Plasmacytoid dendritic cell</th>\n","      <th>CD4+ T cell</th>\n","      <th>CD14+ monocyte</th>\n","      <th>Unassigned</th>\n","      <th>CD16+ monocyte</th>\n","      <th>Cytotoxic T cell</th>\n","      <th>Natural killer cell</th>\n","      <th>B cell</th>\n","      <th>Megakaryocyte</th>\n","      <th>Dendritic cell</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4.764566</td>\n","      <td>0.959774</td>\n","      <td>0.839968</td>\n","      <td>0.395335</td>\n","      <td>0.0</td>\n","      <td>0.542495</td>\n","      <td>0.334787</td>\n","      <td>0.058824</td>\n","      <td>NaN</td>\n","      <td>0.349282</td>\n","      <td>NaN</td>\n","      <td>0.529528</td>\n","      <td>0.222222</td>\n","      <td>0.054054</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    val_bpd  Train_Acc   val_Acc  test_Acc  Plasmacytoid dendritic cell  \\\n","0  4.764566   0.959774  0.839968  0.395335                          0.0   \n","\n","   CD4+ T cell  CD14+ monocyte  Unassigned  CD16+ monocyte  Cytotoxic T cell  \\\n","0     0.542495        0.334787    0.058824             NaN          0.349282   \n","\n","   Natural killer cell    B cell  Megakaryocyte  Dendritic cell  \n","0                  NaN  0.529528       0.222222        0.054054  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df.append(classes_labeled, ignore_index = True)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1fTsVaFW9rVur8hpaEbz5dsxiGXSEy9Sk","timestamp":1679851239019}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
