{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"gAHHs5T1xpkh"},"source":["# Feed Forward Neural Network "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nRJ9MX8tDYBO"},"source":["You need to have these three files to run all the cells in this notebook\n","1. ITClust train dataset\n","2. ITClust test dataset\n","3. FlowGMM codebase zip "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"p-_nnfyDDDxq"},"outputs":[],"source":["all_batches_file = '/home/anunay18021/SingleCellClassification/dataset/adata_pbmc_batches_raw.h5ad'"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n","/home/anunay18021/.venv/lib/python3.8/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n","/home/anunay18021/.venv/lib/python3.8/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n","/home/anunay18021/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.14.0 pynndescent==0.5.10\n"]},{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n"]}],"source":["# Call Libraries\n","import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","from torch import distributions\n","import sys\n","sys.path.insert(0, '')\n","from scripts.utils import *\n","import numpy as np\n","torch.manual_seed(0)\n","np.random.seed(0)\n","import scanpy as sc\n","sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n","sc.logging.print_header()\n","import os\n","from numpy.random import seed\n","# from tensorflow import set_random_seed\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","import pickle\n","import sys\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from pylab import rcParams\n","rcParams['figure.dpi'] = 100\n","\n","# from flow_ssl.realnvp.realnvp_toy import ToyRealNVP\n","from flow_ssl.realnvp.realnvp import RealNVPTabular\n","from flow_ssl.data import make_circles_ssl, make_moons_ssl, make_dataset_from_img, make_dataset_from_npz\n","from flow_ssl.distributions import SSLGaussMixture\n","from flow_ssl import FlowLoss\n","\n","from itertools import chain\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/anndata/_core/anndata.py:117: ImplicitModificationWarning: Transforming to str index.\n","  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n","  utils.warn_names_duplicates(\"var\")\n"]}],"source":["adata = sc.read(all_batches_file)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","____Create unique index____ \n","normalizing counts per cell\n","    finished (0:00:02)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 500x550 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["____Filtering the data____\n","pre filtering: (30495, 33694)\n","filtered out 2035 cells that have less than 200 genes expressed\n","filtered out 9096 genes that are detected in less than 3 cells\n","post filtering: (28460, 24598)\n","____Log normalizing____\n","normalizing counts per cell\n","    finished (0:00:04)\n","____Selecting highly variable genes____\n","pre: (28460, 24598)\n","If you pass `n_top_genes`, all cutoffs are ignored.\n","extracting highly variable genes\n","    finished (0:00:08)\n","--> added\n","    'highly_variable', boolean vector (adata.var)\n","    'means', float vector (adata.var)\n","    'dispersions', float vector (adata.var)\n","    'dispersions_norm', float vector (adata.var)\n","pre: (28460, 24598)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1280x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["post: (28460, 3000)\n","____Scaling the data____\n"]},{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n","  view_to_actual(adata)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>gene_symbols</th>\n","      <th>SCYL3</th>\n","      <th>FUCA2</th>\n","      <th>TMEM176A</th>\n","      <th>HSPB6</th>\n","      <th>PDK4</th>\n","      <th>SLC22A16</th>\n","      <th>ARX</th>\n","      <th>SLC25A13</th>\n","      <th>SLC4A1</th>\n","      <th>THSD7A</th>\n","      <th>...</th>\n","      <th>CH17-262H11.1</th>\n","      <th>TRBJ1-5</th>\n","      <th>RP11-328P23.4</th>\n","      <th>CH17-212P11.4</th>\n","      <th>CH17-224D4.1</th>\n","      <th>RP11-596C23.6</th>\n","      <th>CTC-490G23.6</th>\n","      <th>PRNCR1</th>\n","      <th>RP1-273N12.4</th>\n","      <th>TRBV6-2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_ACAGAC</th>\n","      <td>-0.210501</td>\n","      <td>2.240501</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>2.772827</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_ACAGGA</th>\n","      <td>1.656750</td>\n","      <td>2.347928</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_ACGTTG</th>\n","      <td>-0.210501</td>\n","      <td>-0.162299</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_AGACCA</th>\n","      <td>-0.210501</td>\n","      <td>-0.162299</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_CAACTC</th>\n","      <td>-0.210501</td>\n","      <td>-0.162299</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 3000 columns</p>\n","</div>"],"text/plain":["gene_symbols               SCYL3     FUCA2  TMEM176A     HSPB6      PDK4  \\\n","pbmc1_Celseq2_1_ACAGAC -0.210501  2.240501 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_ACAGGA  1.656750  2.347928 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_ACGTTG -0.210501 -0.162299 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_AGACCA -0.210501 -0.162299 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_CAACTC -0.210501 -0.162299 -0.133715 -0.017045 -0.092075   \n","\n","gene_symbols            SLC22A16       ARX  SLC25A13    SLC4A1    THSD7A  ...  \\\n","pbmc1_Celseq2_1_ACAGAC -0.022733 -0.017383 -0.148193  2.772827 -0.018138  ...   \n","pbmc1_Celseq2_1_ACAGGA -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","pbmc1_Celseq2_1_ACGTTG -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","pbmc1_Celseq2_1_AGACCA -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","pbmc1_Celseq2_1_CAACTC -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","\n","gene_symbols            CH17-262H11.1   TRBJ1-5  RP11-328P23.4  CH17-212P11.4  \\\n","pbmc1_Celseq2_1_ACAGAC      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_ACAGGA      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_ACGTTG      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_AGACCA      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_CAACTC      -0.016476 -0.037941      -0.019149      -0.009174   \n","\n","gene_symbols            CH17-224D4.1  RP11-596C23.6  CTC-490G23.6    PRNCR1  \\\n","pbmc1_Celseq2_1_ACAGAC     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_ACAGGA     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_ACGTTG     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_AGACCA     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_CAACTC     -0.018344      -0.035799     -0.009078 -0.125148   \n","\n","gene_symbols            RP1-273N12.4   TRBV6-2  \n","pbmc1_Celseq2_1_ACAGAC     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_ACAGGA     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_ACGTTG     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_AGACCA     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_CAACTC     -0.020136 -0.046757  \n","\n","[5 rows x 3000 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["\n","print(\"\\n____Create unique index____ \")\n","adata.var_names_make_unique()\n","sc.pl.highest_expr_genes(adata, n_top=20, )\n","        \n","print(\"____Filtering the data____\")\n","print(\"pre filtering:\",adata.shape)\n","sc.pp.filter_cells(adata, min_genes=200)\n","sc.pp.filter_genes(adata, min_cells=3)\n","print(\"post filtering:\",adata.shape)\n","\n","print(\"____Log normalizing____\")\n","sc.pp.normalize_total(adata, target_sum=1e4)\n","sc.pp.log1p(adata)\n","\n","print(\"____Selecting highly variable genes____\")\n","print(\"pre:\",adata.shape)\n","sc.pp.highly_variable_genes(adata, min_mean=0.001 , max_mean=3, min_disp=0.3, n_top_genes=3000)\n","print(\"pre:\",adata.shape)\n","adata.raw = adata\n","adata = adata[:, adata.var.highly_variable]\n","\n","sc.pl.highly_variable_genes(adata)\n","print(\"post:\",adata.shape)\n","\n","print(\"____Scaling the data____\")\n","sc.pp.scale(adata, max_value=10)\n","adata.to_df().head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["all_batches = list(set(adata.obs.Method.values))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["['10x Chromium (v2) A',\n"," '10x Chromium (v2)',\n"," 'Drop-seq',\n"," '10x Chromium (v3)',\n"," 'inDrops',\n"," 'Seq-Well',\n"," 'CEL-Seq2',\n"," '10x Chromium (v2) B']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["all_batches"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["batch_name = '10x Chromium (v2) A'"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["mapping = {}\n","reverse_mapping = {}\n","cnt = 0\n","for i in set(adata.obs.CellType.values):\n","    mapping[i] = cnt\n","    reverse_mapping[cnt] = i\n","    cnt += 1"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["total_classes = len(set(adata.obs.CellType.values))"]},{"cell_type":"markdown","metadata":{},"source":["# One vs all for batch '10x Chromium (v2) B'"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["train_df = adata[adata.obs['Method'] != batch_name].to_df()\n","test_df = adata[adata.obs['Method'] == batch_name].to_df()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Taking common genes...\n","Common columns 3000\n"]}],"source":["print(\"Taking common genes...\")\n","final_columns = list(set(train_df.columns).intersection(set(test_df.columns)))\n","print('Common columns', len(final_columns))\n","final_columns = [i for i in final_columns if i != 'CellType'] \n","train_df = train_df[final_columns]\n","test_df = test_df[final_columns]\n","\n","y_train = adata[adata.obs['Method'] != batch_name].obs.CellType.to_list()\n","y_test = adata[adata.obs['Method'] == batch_name].obs.CellType.to_list()\n","\n","X_train = train_df.to_numpy()\n","X_test = test_df.to_numpy()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["y_test_lab = convert_y_to_mapping(y_test, mapping)\n","y_test_lab = np.array(y_test_lab)\n","\n","y_train_lab = convert_y_to_mapping(y_train, mapping)\n","y_train_lab = np.array(y_train_lab)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["with open('/home/anunay18021/SingleCellClassification/dataset/np/X_train_'+batch_name+'.pkl', 'wb') as fh:\n","        pickle.dump(X_train, fh)\n","\n","with open('/home/anunay18021/SingleCellClassification/dataset/np/X_test_'+batch_name+'.pkl', 'wb') as fh:\n","    pickle.dump(X_test, fh)\n","\n","with open('/home/anunay18021/SingleCellClassification/dataset/np/y_test_'+batch_name+'.pkl', 'wb') as fh:\n","    pickle.dump(y_test_lab, fh)\n","\n","with open('/home/anunay18021/SingleCellClassification/dataset/np/y_train_'+batch_name+'.pkl', 'wb') as fh:\n","    pickle.dump(y_train_lab, fh)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["25468"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["len(y_train_lab)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/anunay18021/SingleCellClassification/flowgmm\n"]}],"source":["%cd flowgmm"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n0Zfu1blzejB","outputId":"ecf9742d-4067-4ad6-e529-2bcf3bf0669b"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'num_classes': 10, 'metric_name': '10x Chromium (v2) A', 'dataset': <class 'flow_ssl.data.nlp_datasets.AG_News'>, 'network': <function RealNVPTabularWPrior at 0x7f5b92d25dc0>, 'num_epochs': 500, 'bs': 5000, 'lr': 0.0003, 'optim': <class 'torch.optim.adamw.AdamW'>, 'device': 'cuda', 'trainer': SemiFlow, 'split': {'train': 200, 'val': 5000}, 'net_config': {'k': 1024, 'coupling_layers': 7, 'nperlayer': 1}, 'opt_config': {'weight_decay': 1e-05}, 'trainer_config': {'log_dir': '/home/anunay18021/tb-experiments/UCI/', 'log_args': {'minPeriod': 0.1, 'timeFrac': 0.3}, 'unlab_weight': 0.6}, 'save': False}\n","10x Chromium (v2) A\n","25468\n","25468\n","2992\n","Pairwise dists: [[ 0.         43.03319633 43.19063312 44.10315511 43.63976106 42.76184562\n","  42.39393215 43.45752568 43.28177566 42.80092231]\n"," [43.03319633  0.         43.05466491 42.61303257 42.80212408 42.71560445\n","  42.62616041 43.53154249 42.90157358 42.74580782]\n"," [43.19063312 43.05466491  0.         43.51487988 43.46331196 43.32742353\n","  43.08420323 43.46167224 43.34185889 43.72584377]\n"," [44.10315511 42.61303257 43.51487988  0.         44.10530447 44.38754315\n","  43.82581141 45.16452993 43.7617526  43.95851144]\n"," [43.63976106 42.80212408 43.46331196 44.10530447  0.         43.91374922\n","  43.04915736 43.55866449 43.36174098 43.75866687]\n"," [42.76184562 42.71560445 43.32742353 44.38754315 43.91374922  0.\n","  42.68236699 43.88923659 43.64791819 43.37630718]\n"," [42.39393215 42.62616041 43.08420323 43.82581141 43.04915736 42.68236699\n","   0.         43.27263119 42.5191743  42.87393157]\n"," [43.45752568 43.53154249 43.46167224 45.16452993 43.55866449 43.88923659\n","  43.27263119  0.         44.3407483  43.2649238 ]\n"," [43.28177566 42.90157358 43.34185889 43.7617526  43.36174098 43.64791819\n","  42.5191743  44.3407483   0.         43.19963539]\n"," [42.80092231 42.74580782 43.72584377 43.95851144 43.75866687 43.37630718\n","  42.87393157 43.2649238  43.19963539  0.        ]]\n","10 10x Chromium (v2) A\n","train:   0%|                                            | 0/500 [00:00<?, ?it/s]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 10.024352862595704, 'Train_Acc': 0.11885450188291681, 'val_Acc': 0.1154299175500589, 'test_Acc': 0.09391711229946524, 'class_Acc_0': 0.18627450980392163, 'class_Acc_1': 0.1090909090909091, 'class_Acc_2': 0.12181818181818181, 'class_Acc_3': 0.0, 'class_Acc_4': 0.0008517887563884156, 'class_Acc_5': 0.07807308970099668, 'class_Acc_6': 0.4756944444444445, 'class_Acc_7': nan, 'class_Acc_8': 0.15384615384615383, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(4079.7852, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","   Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc    val_bpd\n","0     6694.723633   0.118855     4079.785156  ...  0.093917  0.11543  10.024353\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   0%|▏                                 | 2/500 [00:20<1:21:47,  9.85s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 8.901007726331304, 'Train_Acc': 0.19733477576172542, 'val_Acc': 0.19866509619159795, 'test_Acc': 0.1089572192513369, 'class_Acc_0': 0.0196078431372549, 'class_Acc_1': 0.0, 'class_Acc_2': 0.003636363636363636, 'class_Acc_3': 0.0, 'class_Acc_4': 0.0, 'class_Acc_5': 0.05647840531561462, 'class_Acc_6': 1.0, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(1840.2896, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","16     3106.389648   0.197335     1840.289551  ...  0.108957  0.198665  8.901008\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   1%|▎                                 | 5/500 [01:12<2:01:41, 14.75s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 8.69739911150483, 'Train_Acc': 0.3339885655597398, 'val_Acc': 0.3380447585394582, 'test_Acc': 0.30213903743315507, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.00909090909090909, 'class_Acc_3': 0.0, 'class_Acc_4': 0.008517887563884156, 'class_Acc_5': 1.0, 'class_Acc_6': 0.9965277777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(1683.0432, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","32     2548.430176   0.333989     1683.043213  ...  0.302139  0.338045  8.697399\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   2%|▌                                 | 8/500 [02:04<2:06:27, 15.42s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 8.3076604704039, 'Train_Acc': 0.5895556453269428, 'val_Acc': 0.5924617196702002, 'test_Acc': 0.6587566844919787, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.003636363636363636, 'class_Acc_3': 0.0, 'class_Acc_4': 0.9914821124361158, 'class_Acc_5': 1.0, 'class_Acc_6': 0.704861111111111, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(950.1628, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","50     1456.157959   0.589556      950.162781  ...  0.658757  0.592462  8.30766\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   2%|▋                                | 11/500 [02:57<2:10:19, 15.99s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 8.077660966457792, 'Train_Acc': 0.6299795549469359, 'val_Acc': 0.6226933647428347, 'test_Acc': 0.6968582887700535, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.07272727272727272, 'class_Acc_3': 0.0, 'class_Acc_4': 0.985519591141397, 'class_Acc_5': 1.0, 'class_Acc_6': 0.9930555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-92.00435, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","69      402.891418    0.62998      -92.004349  ...  0.696858  0.622693  8.077661\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   3%|▉                                | 14/500 [03:49<2:08:16, 15.84s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.954967505015673, 'Train_Acc': 0.6739883738445738, 'val_Acc': 0.6654888103651354, 'test_Acc': 0.7403074866310161, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.31090909090909086, 'class_Acc_3': 0.2413793103448275, 'class_Acc_4': 0.9787052810902896, 'class_Acc_5': 1.0, 'class_Acc_6': 0.9930555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-973.701, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","89     -410.327057   0.673988     -973.700989  ...  0.740307  0.665489  7.954968\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   4%|█▏                               | 18/500 [04:54<1:59:06, 14.83s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.765748130994128, 'Train_Acc': 0.7589022389592606, 'val_Acc': 0.7353749509226541, 'test_Acc': 0.7817513368983957, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.6272727272727272, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.9267461669505962, 'class_Acc_5': 1.0, 'class_Acc_6': 0.9791666666666667, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-747.65283, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","109     -579.827515   0.758902     -747.652832  ...  0.781751  0.735375  7.765748\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   4%|█▍                               | 21/500 [05:47<2:05:31, 15.72s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.609663611411526, 'Train_Acc': 0.7892647997261212, 'val_Acc': 0.7769925402434237, 'test_Acc': 0.7613636363636364, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.7818181818181817, 'class_Acc_3': 0.96551724137931, 'class_Acc_4': 0.7964224872231687, 'class_Acc_5': 1.0, 'class_Acc_6': 0.982638888888889, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-1059.5184, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","129    -1032.729736   0.789265    -1059.518433  ...  0.761364  0.776993  7.609664\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   5%|█▌                               | 24/500 [06:39<2:05:42, 15.85s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.44234553362607, 'Train_Acc': 0.810043300239644, 'val_Acc': 0.7930899096976836, 'test_Acc': 0.7824197860962567, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.8472727272727273, 'class_Acc_3': 0.96551724137931, 'class_Acc_4': 0.8262350936967632, 'class_Acc_5': 0.9966777408637874, 'class_Acc_6': 0.9618055555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-2111.661, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","149         -1996.0   0.810043    -2111.660889  ...   0.78242  0.79309  7.442346\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   6%|█▊                               | 28/500 [07:45<2:00:16, 15.29s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.332186996964521, 'Train_Acc': 0.8140988154741526, 'val_Acc': 0.790341578327444, 'test_Acc': 0.7911096256684492, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.8090909090909092, 'class_Acc_3': 0.96551724137931, 'class_Acc_4': 0.8739352640545144, 'class_Acc_5': 0.9966777408637874, 'class_Acc_6': 0.9305555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-1680.71, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","169    -1930.054077   0.814099    -1680.709961  ...   0.79111  0.790342  7.332187\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   6%|██                               | 31/500 [08:38<2:04:06, 15.88s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.209302030318255, 'Train_Acc': 0.8214119821978774, 'val_Acc': 0.7981939536709854, 'test_Acc': 0.7907754010695187, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.8654545454545454, 'class_Acc_3': 0.96551724137931, 'class_Acc_4': 0.8424190800681431, 'class_Acc_5': 0.9966777408637874, 'class_Acc_6': 0.9444444444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.006024096385542167, 'Unlab_loss(mb)': array(-1931.0603, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","189    -2305.396973   0.821412    -1931.060303  ...  0.790775  0.798194  7.209302\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   7%|██▏                              | 34/500 [09:30<2:03:49, 15.94s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.103657903407455, 'Train_Acc': 0.8241409517288599, 'val_Acc': 0.7950530035335689, 'test_Acc': 0.7891042780748663, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.8654545454545454, 'class_Acc_3': 0.9310344827586206, 'class_Acc_4': 0.8415672913117547, 'class_Acc_5': 0.9966777408637874, 'class_Acc_6': 0.9375, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-2815.5435, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","209    -3052.508789   0.824141    -2815.543457  ...  0.789104  0.795053  7.103658\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   8%|██▌                              | 38/500 [10:35<1:55:12, 14.96s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.991810939224499, 'Train_Acc': 0.8264505580280725, 'val_Acc': 0.7993718099725167, 'test_Acc': 0.7997994652406417, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.8054545454545455, 'class_Acc_3': 0.9310344827586206, 'class_Acc_4': 0.8986371379897785, 'class_Acc_5': 0.9966777408637874, 'class_Acc_6': 0.9305555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-1994.4425, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","230    -2718.813477   0.826451    -1994.442505  ...  0.799799  0.799372  6.991811\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   8%|██▋                              | 41/500 [11:28<2:00:28, 15.75s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.904503233817891, 'Train_Acc': 0.8199755426223896, 'val_Acc': 0.7938751472320377, 'test_Acc': 0.7459893048128342, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.9200000000000002, 'class_Acc_3': 0.8965517241379309, 'class_Acc_4': 0.7095400340715502, 'class_Acc_5': 0.9950166112956811, 'class_Acc_6': 0.9305555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-3208.2153, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","251    -3725.595459   0.819976    -3208.215332  ...  0.745989  0.793875  6.904503\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   9%|██▉                              | 45/500 [12:32<1:53:14, 14.93s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.84894902553642, 'Train_Acc': 0.8296552550496405, 'val_Acc': 0.7970160973694542, 'test_Acc': 0.7710561497326203, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.9036363636363636, 'class_Acc_3': 0.8965517241379309, 'class_Acc_4': 0.7751277683134581, 'class_Acc_5': 0.9933554817275747, 'class_Acc_6': 0.9548611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.0, 'class_Acc_9': 0.006024096385542167, 'Unlab_loss(mb)': array(-2323.8127, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","272    -3290.900146   0.829655    -2323.812744  ...  0.771056  0.797016  6.848949\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  10%|███▏                             | 48/500 [13:25<1:57:57, 15.66s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.769345555854348, 'Train_Acc': 0.8331406641561109, 'val_Acc': 0.8025127601099332, 'test_Acc': 0.803475935828877, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.7999999999999999, 'class_Acc_3': 0.8965517241379309, 'class_Acc_4': 0.9156729131175468, 'class_Acc_5': 0.9933554817275747, 'class_Acc_6': 0.9131944444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.03846153846153846, 'class_Acc_9': 0.006024096385542167, 'Unlab_loss(mb)': array(-3495.012, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","293    -4185.908691   0.833141    -3495.011963  ...  0.803476  0.802513  6.769346\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  10%|███▍                             | 52/500 [14:31<1:52:52, 15.12s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.695464377317939, 'Train_Acc': 0.8392992399863061, 'val_Acc': 0.8040832351786416, 'test_Acc': 0.8014705882352942, 'class_Acc_0': 0.0, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8418181818181818, 'class_Acc_3': 0.8965517241379309, 'class_Acc_4': 0.8867120954003406, 'class_Acc_5': 0.9916943521594686, 'class_Acc_6': 0.9305555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.03846153846153846, 'class_Acc_9': 0.006024096385542167, 'Unlab_loss(mb)': array(-2659.5361, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","314    -3748.967529   0.839299    -2659.536133  ...  0.801471  0.804083  6.695464\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  11%|███▋                             | 55/500 [15:23<1:55:24, 15.56s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.640253466586888, 'Train_Acc': 0.8409352550496405, 'val_Acc': 0.806438947781704, 'test_Acc': 0.7974598930481284, 'class_Acc_0': 0.0, 'class_Acc_1': 0.0, 'class_Acc_2': 0.8436363636363636, 'class_Acc_3': 0.8965517241379309, 'class_Acc_4': 0.8739352640545144, 'class_Acc_5': 0.9916943521594686, 'class_Acc_6': 0.9340277777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.11538461538461538, 'class_Acc_9': 0.006024096385542167, 'Unlab_loss(mb)': array(-3756.824, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","335    -4637.893555   0.840935    -3756.823975  ...   0.79746  0.806439  6.640253\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  12%|███▉                             | 59/500 [16:28<1:48:22, 14.74s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.550621340898741, 'Train_Acc': 0.8412531187949333, 'val_Acc': 0.8021201413427562, 'test_Acc': 0.7830882352941176, 'class_Acc_0': 0.00980392156862745, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8818181818181818, 'class_Acc_3': 0.8620689655172413, 'class_Acc_4': 0.8211243611584327, 'class_Acc_5': 0.9900332225913621, 'class_Acc_6': 0.9305555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.07692307692307691, 'class_Acc_9': 0.006024096385542167, 'Unlab_loss(mb)': array(-2975.6174, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","356    -4221.384766   0.841253    -2975.617432  ...  0.783088  0.80212  6.550621\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  12%|████                             | 62/500 [17:21<1:54:28, 15.68s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.513872183455418, 'Train_Acc': 0.8436218007531667, 'val_Acc': 0.8080094228504122, 'test_Acc': 0.7754010695187166, 'class_Acc_0': 0.029411764705882356, 'class_Acc_1': 0.0, 'class_Acc_2': 0.9072727272727272, 'class_Acc_3': 0.8620689655172413, 'class_Acc_4': 0.7955706984667803, 'class_Acc_5': 0.9900332225913621, 'class_Acc_6': 0.9027777777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.07692307692307691, 'class_Acc_9': 0.006024096385542167, 'Unlab_loss(mb)': array(-4024.7385, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","377    -5038.412109   0.843622    -4024.738525  ...  0.775401  0.808009  6.513872\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  13%|████▎                            | 66/500 [18:28<1:49:07, 15.09s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.469765962263138, 'Train_Acc': 0.8476185279014036, 'val_Acc': 0.8087946603847664, 'test_Acc': 0.7867647058823529, 'class_Acc_0': 0.029411764705882356, 'class_Acc_1': 0.0, 'class_Acc_2': 0.8727272727272727, 'class_Acc_3': 0.8275862068965517, 'class_Acc_4': 0.8356047700170358, 'class_Acc_5': 0.9900332225913621, 'class_Acc_6': 0.923611111111111, 'class_Acc_7': nan, 'class_Acc_8': 0.11538461538461538, 'class_Acc_9': 0.006024096385542167, 'Unlab_loss(mb)': array(-3153.8066, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","398    -4556.223633   0.847619    -3153.806641  ...  0.786765  0.808795  6.469766\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  14%|████▌                            | 70/500 [19:32<1:44:39, 14.60s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.431352210883479, 'Train_Acc': 0.8496448613488532, 'val_Acc': 0.806438947781704, 'test_Acc': 0.7827540106951871, 'class_Acc_0': 0.00980392156862745, 'class_Acc_1': 0.0, 'class_Acc_2': 0.8509090909090907, 'class_Acc_3': 0.8275862068965517, 'class_Acc_4': 0.84412265758092, 'class_Acc_5': 0.9867109634551495, 'class_Acc_6': 0.8993055555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.15384615384615383, 'class_Acc_9': 0.006024096385542167, 'Unlab_loss(mb)': array(-3789.9612, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","420    -5020.683594   0.849645    -3789.961182  ...  0.782754  0.806439  6.431352\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  15%|████▊                            | 73/500 [20:25<1:51:02, 15.60s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.368765803532257, 'Train_Acc': 0.8504963916466964, 'val_Acc': 0.8056537102473498, 'test_Acc': 0.7977941176470589, 'class_Acc_0': 0.0196078431372549, 'class_Acc_1': 0.0, 'class_Acc_2': 0.8436363636363636, 'class_Acc_3': 0.8275862068965517, 'class_Acc_4': 0.8722316865417375, 'class_Acc_5': 0.9850498338870431, 'class_Acc_6': 0.951388888888889, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.006024096385542167, 'Unlab_loss(mb)': array(-3710.4204, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","441    -5097.286133   0.850496     -3710.42041  ...  0.797794  0.805654  6.368766\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  15%|█████                            | 77/500 [21:29<1:44:45, 14.86s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.324886294915167, 'Train_Acc': 0.8531173159876754, 'val_Acc': 0.8087946603847664, 'test_Acc': 0.786096256684492, 'class_Acc_0': 0.0392156862745098, 'class_Acc_1': 0.0, 'class_Acc_2': 0.8672727272727272, 'class_Acc_3': 0.8275862068965517, 'class_Acc_4': 0.8347529812606472, 'class_Acc_5': 0.9850498338870431, 'class_Acc_6': 0.923611111111111, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.006024096385542167, 'Unlab_loss(mb)': array(-3996.6863, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","462     -5418.65332   0.853117    -3996.686279  ...  0.786096  0.808795  6.324886\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  16%|█████▎                           | 80/500 [22:21<1:48:25, 15.49s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.299517380824171, 'Train_Acc': 0.8532005888394386, 'val_Acc': 0.8040832351786416, 'test_Acc': 0.7650401069518716, 'class_Acc_0': 0.0392156862745098, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8981818181818181, 'class_Acc_3': 0.8275862068965517, 'class_Acc_4': 0.772572402044293, 'class_Acc_5': 0.9800664451827243, 'class_Acc_6': 0.9027777777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.01807228915662651, 'Unlab_loss(mb)': array(-3877.824, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","483    -5321.978027   0.853201    -3877.823975  ...   0.76504  0.804083  6.299517\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  17%|█████▍                           | 83/500 [23:16<1:53:02, 16.26s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.260859892879987, 'Train_Acc': 0.8570542553919891, 'val_Acc': 0.811935610522183, 'test_Acc': 0.7847593582887701, 'class_Acc_0': 0.0392156862745098, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8581818181818179, 'class_Acc_3': 0.8275862068965517, 'class_Acc_4': 0.8517887563884157, 'class_Acc_5': 0.9734219269102992, 'class_Acc_6': 0.8715277777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.012048192771084335, 'Unlab_loss(mb)': array(-4536.1216, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","503    -5914.478516   0.857054    -4536.121582  ...  0.784759  0.811936  6.26086\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  17%|█████▋                           | 87/500 [24:20<1:44:15, 15.15s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.230442367993639, 'Train_Acc': 0.8582949674768915, 'val_Acc': 0.8138987043580683, 'test_Acc': 0.7914438502673797, 'class_Acc_0': 0.049019607843137254, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8509090909090907, 'class_Acc_3': 0.8275862068965517, 'class_Acc_4': 0.8620102214650767, 'class_Acc_5': 0.9850498338870431, 'class_Acc_6': 0.8888888888888887, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.01807228915662651, 'Unlab_loss(mb)': array(-3678.0742, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","524    -5453.699707   0.858295    -3678.074219  ...  0.791444  0.813899  6.230442\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  18%|█████▉                           | 90/500 [25:11<1:45:37, 15.46s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.180605402364442, 'Train_Acc': 0.8582264977747347, 'val_Acc': 0.8146839418924224, 'test_Acc': 0.7937834224598931, 'class_Acc_0': 0.049019607843137254, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8509090909090907, 'class_Acc_3': 0.7931034482758621, 'class_Acc_4': 0.8688245315161838, 'class_Acc_5': 0.9800664451827243, 'class_Acc_6': 0.8923611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.02409638554216867, 'Unlab_loss(mb)': array(-4689.843, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","545    -6158.837891   0.858226    -4689.842773  ...  0.793783  0.814684  6.180605\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  19%|██████▏                          | 94/500 [26:17<1:42:03, 15.08s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.162363786869816, 'Train_Acc': 0.862103649435125, 'val_Acc': 0.8115429917550059, 'test_Acc': 0.7774064171122995, 'class_Acc_0': 0.0392156862745098, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8818181818181818, 'class_Acc_3': 0.7931034482758621, 'class_Acc_4': 0.8143100511073254, 'class_Acc_5': 0.9734219269102992, 'class_Acc_6': 0.9097222222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.02409638554216867, 'Unlab_loss(mb)': array(-3817.4575, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","566    -5687.933594   0.862104     -3817.45752  ...  0.777406  0.811543  6.162364\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  19%|██████▍                          | 97/500 [27:08<1:44:07, 15.50s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.12359981093718, 'Train_Acc': 0.8622942553919891, 'val_Acc': 0.8107577542206518, 'test_Acc': 0.7881016042780749, 'class_Acc_0': 0.05882352941176471, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8545454545454545, 'class_Acc_3': 0.7931034482758621, 'class_Acc_4': 0.8551959114139692, 'class_Acc_5': 0.9700996677740863, 'class_Acc_6': 0.8993055555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.01807228915662651, 'Unlab_loss(mb)': array(-4827.1787, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","587     -6389.81543   0.862294    -4827.178711  ...  0.788102  0.810758   6.1236\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  20%|██████▍                         | 101/500 [28:14<1:39:50, 15.01s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.134937318205938, 'Train_Acc': 0.8669123313933584, 'val_Acc': 0.8103651354534747, 'test_Acc': 0.7750668449197861, 'class_Acc_0': 0.029411764705882356, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8527272727272727, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.823679727427598, 'class_Acc_5': 0.9717607973421928, 'class_Acc_6': 0.8958333333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.030120481927710843, 'Unlab_loss(mb)': array(-3886.7527, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","608    -5769.979004   0.866912    -3886.752686  ...  0.775067  0.810365  6.134937\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  21%|██████▋                         | 104/500 [29:06<1:44:13, 15.79s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.0487346458173, 'Train_Acc': 0.8646906949674769, 'val_Acc': 0.8127208480565371, 'test_Acc': 0.7700534759358288, 'class_Acc_0': 0.05882352941176471, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8727272727272727, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.7989778534923337, 'class_Acc_5': 0.9734219269102992, 'class_Acc_6': 0.90625, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.02409638554216867, 'Unlab_loss(mb)': array(-4973.762, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","629    -6631.015625   0.864691    -4973.762207  ...  0.770053  0.812721  6.048735\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  22%|██████▉                         | 108/500 [30:11<1:37:43, 14.96s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.027138952203525, 'Train_Acc': 0.8643104827114002, 'val_Acc': 0.8131134668237142, 'test_Acc': 0.776403743315508, 'class_Acc_0': 0.0784313725490196, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8709090909090909, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.8211243611584327, 'class_Acc_5': 0.9684385382059801, 'class_Acc_6': 0.8923611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.01807228915662651, 'Unlab_loss(mb)': array(-4118.103, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","650    -6110.738281    0.86431    -4118.103027  ...  0.776404  0.813113  6.027139\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  22%|███████▏                        | 112/500 [31:16<1:35:00, 14.69s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.988597344793629, 'Train_Acc': 0.8656561040739473, 'val_Acc': 0.8111503729878288, 'test_Acc': 0.7807486631016043, 'class_Acc_0': 0.05882352941176471, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8636363636363635, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.8356047700170358, 'class_Acc_5': 0.9684385382059801, 'class_Acc_6': 0.8923611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.01807228915662651, 'Unlab_loss(mb)': array(-4687.995, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","672    -6559.588379   0.865656    -4687.995117  ...  0.780749  0.81115  5.988597\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  23%|███████▎                        | 115/500 [32:09<1:40:13, 15.62s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.969514274598641, 'Train_Acc': 0.8675353919890448, 'val_Acc': 0.8162544169611308, 'test_Acc': 0.7643716577540107, 'class_Acc_0': 0.08823529411764706, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8836363636363637, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.7904599659284498, 'class_Acc_5': 0.9667774086378738, 'class_Acc_6': 0.8715277777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.01807228915662651, 'Unlab_loss(mb)': array(-4564.6523, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","693     -6502.77832   0.867535    -4564.652344  ...  0.764372  0.816254  5.969514\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  24%|███████▌                        | 119/500 [33:15<1:36:36, 15.21s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.936833146165068, 'Train_Acc': 0.866609270797672, 'val_Acc': 0.8131134668237142, 'test_Acc': 0.786096256684492, 'class_Acc_0': 0.049019607843137254, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8254545454545453, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.8764906303236797, 'class_Acc_5': 0.9601328903654485, 'class_Acc_6': 0.8750000000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.01807228915662651, 'Unlab_loss(mb)': array(-4789.8384, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","714     -6723.94873   0.866609    -4789.838379  ...  0.786096  0.813113  5.936833\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  24%|███████▊                        | 122/500 [34:06<1:37:17, 15.44s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.916359039931305, 'Train_Acc': 0.8696622252653201, 'val_Acc': 0.8154691794267765, 'test_Acc': 0.7667112299465241, 'class_Acc_0': 0.06862745098039216, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8727272727272727, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.797274275979557, 'class_Acc_5': 0.9684385382059801, 'class_Acc_6': 0.8576388888888887, 'class_Acc_7': nan, 'class_Acc_8': 0.3846153846153846, 'class_Acc_9': 0.04216867469879518, 'Unlab_loss(mb)': array(-4684.9077, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","735    -6691.290039   0.869662    -4684.907715  ...  0.766711  0.815469  5.916359\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  25%|████████                        | 126/500 [35:11<1:33:34, 15.01s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.892423310928536, 'Train_Acc': 0.8696492707976721, 'val_Acc': 0.8138987043580683, 'test_Acc': 0.7767379679144385, 'class_Acc_0': 0.05882352941176471, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8509090909090907, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.8304940374787051, 'class_Acc_5': 0.9684385382059801, 'class_Acc_6': 0.8819444444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.030120481927710843, 'Unlab_loss(mb)': array(-4878.837, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","756    -6906.885742   0.869649    -4878.836914  ...  0.776738  0.813899  5.892423\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  26%|████████▎                       | 129/500 [36:04<1:36:30, 15.61s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.866636311140875, 'Train_Acc': 0.8718647860321808, 'val_Acc': 0.8146839418924224, 'test_Acc': 0.7757352941176471, 'class_Acc_0': 0.0784313725490196, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8309090909090909, 'class_Acc_3': 0.7931034482758621, 'class_Acc_4': 0.8475298126064735, 'class_Acc_5': 0.9352159468438538, 'class_Acc_6': 0.8923611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.03614457831325302, 'Unlab_loss(mb)': array(-4793.092, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","777     -6752.30127   0.871865    -4793.091797  ...  0.775735  0.814684  5.866636\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  27%|████████▌                       | 133/500 [37:08<1:30:02, 14.72s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.851212811618455, 'Train_Acc': 0.8730247860321807, 'val_Acc': 0.8142913231252454, 'test_Acc': 0.7810828877005348, 'class_Acc_0': 0.09803921568627451, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8145454545454545, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.8671209540034072, 'class_Acc_5': 0.9485049833887044, 'class_Acc_6': 0.8784722222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.030120481927710843, 'Unlab_loss(mb)': array(-4767.4585, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","799    -6878.258301   0.873025    -4767.458496  ...  0.781083  0.814291  5.851213\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  27%|████████▋                       | 136/500 [38:02<1:36:30, 15.91s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.806869898271028, 'Train_Acc': 0.8715721191372818, 'val_Acc': 0.8182175107970161, 'test_Acc': 0.7834224598930482, 'class_Acc_0': 0.05882352941176471, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8345454545454544, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.8543441226575808, 'class_Acc_5': 0.9667774086378738, 'class_Acc_6': 0.8784722222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.060240963855421686, 'Unlab_loss(mb)': array(-4911.8374, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","819    -7016.381836   0.871572    -4911.837402  ...  0.783422  0.818218  5.80687\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  28%|████████▉                       | 140/500 [39:08<1:30:13, 15.04s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.7972197618622685, 'Train_Acc': 0.8748701951386512, 'val_Acc': 0.817432273262662, 'test_Acc': 0.767379679144385, 'class_Acc_0': 0.0784313725490196, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8563636363636363, 'class_Acc_3': 0.7931034482758621, 'class_Acc_4': 0.8168654173764905, 'class_Acc_5': 0.9451827242524917, 'class_Acc_6': 0.8611111111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.34615384615384615, 'class_Acc_9': 0.04216867469879518, 'Unlab_loss(mb)': array(-4899.6016, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","841    -7038.827148    0.87487    -4899.601562  ...   0.76738  0.817432  5.79722\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  29%|█████████▏                      | 143/500 [39:59<1:31:42, 15.41s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.766361726576067, 'Train_Acc': 0.8758817254364943, 'val_Acc': 0.817824892029839, 'test_Acc': 0.7717245989304813, 'class_Acc_0': 0.11764705882352942, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.84, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.8253833049403747, 'class_Acc_5': 0.9551495016611296, 'class_Acc_6': 0.8750000000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.03614457831325302, 'Unlab_loss(mb)': array(-5591.9297, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","863    -7625.635254   0.875882    -5591.929688  ...  0.771725  0.817825  5.766362\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  29%|█████████▍                      | 147/500 [41:09<1:34:50, 16.12s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.73512681538807, 'Train_Acc': 0.8793657103731598, 'val_Acc': 0.8190027483313702, 'test_Acc': 0.766042780748663, 'class_Acc_0': 0.10784313725490197, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8618181818181816, 'class_Acc_3': 0.7931034482758621, 'class_Acc_4': 0.8023850085178875, 'class_Acc_5': 0.9451827242524917, 'class_Acc_6': 0.8750000000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.060240963855421686, 'Unlab_loss(mb)': array(-5209.8965, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","882    -7386.039551   0.879366    -5209.896484  ...  0.766043  0.819003  5.735127\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  30%|█████████▌                      | 149/500 [42:01<1:59:19, 20.40s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.731241353988072, 'Train_Acc': 0.8807657103731599, 'val_Acc': 0.8186101295641932, 'test_Acc': 0.7737299465240641, 'class_Acc_0': 0.11764705882352942, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8672727272727272, 'class_Acc_3': 0.7931034482758621, 'class_Acc_4': 0.8057921635434412, 'class_Acc_5': 0.9568106312292358, 'class_Acc_6': 0.8888888888888887, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.08433734939759036, 'Unlab_loss(mb)': array(-5120.8096, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","898    -7401.131836   0.880766     -5120.80957  ...   0.77373  0.81861  5.731241\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  30%|█████████▋                      | 152/500 [43:11<2:01:58, 21.03s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.713305818080979, 'Train_Acc': 0.8825819376925711, 'val_Acc': 0.8197879858657244, 'test_Acc': 0.7663770053475936, 'class_Acc_0': 0.09803921568627451, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8672727272727272, 'class_Acc_3': 0.7931034482758621, 'class_Acc_4': 0.7938671209540034, 'class_Acc_5': 0.9468438538205981, 'class_Acc_6': 0.8888888888888887, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.09036144578313253, 'Unlab_loss(mb)': array(-4798.6816, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","914    -7189.364746   0.882582    -4798.681641  ...  0.766377  0.819788  5.713306\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  31%|█████████▉                      | 155/500 [44:20<2:01:06, 21.06s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.6939038709547525, 'Train_Acc': 0.8750431496062993, 'val_Acc': 0.8142913231252454, 'test_Acc': 0.7807486631016043, 'class_Acc_0': 0.09803921568627451, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8036363636363636, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.8688245315161838, 'class_Acc_5': 0.9485049833887044, 'class_Acc_6': 0.8888888888888887, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.03614457831325302, 'Unlab_loss(mb)': array(-5304.184, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","930    -7555.310547   0.875043    -5304.184082  ...  0.780749  0.814291  5.693904\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  31%|██████████                      | 157/500 [45:11<2:09:35, 22.67s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.686185546411456, 'Train_Acc': 0.8805454981170832, 'val_Acc': 0.8158617981939537, 'test_Acc': 0.7767379679144385, 'class_Acc_0': 0.14705882352941177, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.7945454545454544, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.858603066439523, 'class_Acc_5': 0.9352159468438538, 'class_Acc_6': 0.9027777777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.05421686746987952, 'Unlab_loss(mb)': array(-5744.5215, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","947    -7888.785156   0.880545    -5744.521484  ...  0.776738  0.815862  5.686186\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  32%|██████████▏                     | 160/500 [46:20<2:02:22, 21.60s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.659787091889668, 'Train_Acc': 0.8819588770968847, 'val_Acc': 0.822928936003141, 'test_Acc': 0.7657085561497327, 'class_Acc_0': 0.09803921568627451, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8545454545454545, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.8117546848381602, 'class_Acc_5': 0.9352159468438538, 'class_Acc_6': 0.8784722222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.060240963855421686, 'Unlab_loss(mb)': array(-5263.5327, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","964    -7577.290039   0.881959    -5263.532715  ...  0.765709  0.822929  5.659787\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  33%|██████████▍                     | 163/500 [47:28<1:59:02, 21.19s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.673929682973279, 'Train_Acc': 0.8893534679904143, 'val_Acc': 0.8217510797016098, 'test_Acc': 0.7733957219251337, 'class_Acc_0': 0.23529411764705885, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8618181818181816, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.8091993185689949, 'class_Acc_5': 0.9435215946843855, 'class_Acc_6': 0.8645833333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.10843373493975904, 'Unlab_loss(mb)': array(-5204.69, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","981    -7514.808594   0.889353    -5204.689941  ...  0.773396  0.821751  5.67393\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  33%|██████████▌                     | 166/500 [48:38<1:59:18, 21.43s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.6521049286478515, 'Train_Acc': 0.8910327559055118, 'val_Acc': 0.8241067923046722, 'test_Acc': 0.7697192513368984, 'class_Acc_0': 0.17647058823529413, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8327272727272728, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.8253833049403747, 'class_Acc_5': 0.930232558139535, 'class_Acc_6': 0.8541666666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.12650602409638556, 'Unlab_loss(mb)': array(-4940.511, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","998    -7419.927734   0.891033     -4940.51123  ...  0.769719  0.824107  5.652105\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  34%|██████████▊                     | 169/500 [49:47<1:56:08, 21.05s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.619904463747593, 'Train_Acc': 0.8864294830537487, 'val_Acc': 0.8193953670985473, 'test_Acc': 0.7637032085561497, 'class_Acc_0': 0.12745098039215688, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8745454545454545, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.7913117546848382, 'class_Acc_5': 0.9435215946843855, 'class_Acc_6': 0.8680555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.08433734939759036, 'Unlab_loss(mb)': array(-5273.091, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1015     -7701.71582   0.886429     -5273.09082  ...  0.763703  0.819395  5.619904\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  34%|███████████                     | 172/500 [50:57<1:56:36, 21.33s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.596902353801233, 'Train_Acc': 0.882481013351592, 'val_Acc': 0.8186101295641932, 'test_Acc': 0.7449866310160428, 'class_Acc_0': 0.11764705882352942, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.88, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.752129471890971, 'class_Acc_5': 0.9385382059800664, 'class_Acc_6': 0.8541666666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.04819277108433734, 'Unlab_loss(mb)': array(-5493.798, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1032    -7873.943359   0.882481    -5493.797852  ...  0.744987  0.81861  5.596902\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  35%|███████████▏                    | 174/500 [51:49<2:03:53, 22.80s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.591206009563451, 'Train_Acc': 0.8898273467990414, 'val_Acc': 0.8248920298390263, 'test_Acc': 0.767379679144385, 'class_Acc_0': 0.19607843137254902, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8618181818181816, 'class_Acc_3': 0.7931034482758621, 'class_Acc_4': 0.8057921635434412, 'class_Acc_5': 0.9269102990033221, 'class_Acc_6': 0.8611111111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.09638554216867468, 'Unlab_loss(mb)': array(-5961.633, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1049    -8246.466797   0.889827    -5961.632812  ...   0.76738  0.824892  5.591206\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  35%|███████████▎                    | 177/500 [52:58<1:57:37, 21.85s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.582689083810183, 'Train_Acc': 0.8891214378637454, 'val_Acc': 0.8205732234000785, 'test_Acc': 0.7476604278074866, 'class_Acc_0': 0.11764705882352942, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8781818181818182, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.7529812606473595, 'class_Acc_5': 0.930232558139535, 'class_Acc_6': 0.8784722222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.0783132530120482, 'Unlab_loss(mb)': array(-5423.9526, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1066    -7877.570312   0.889121    -5423.952637  ...   0.74766  0.820573  5.582689\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  36%|███████████▌                    | 180/500 [54:09<1:55:39, 21.69s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.543218083989507, 'Train_Acc': 0.8876774529270799, 'val_Acc': 0.8225363172359639, 'test_Acc': 0.7657085561497327, 'class_Acc_0': 0.11764705882352942, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8472727272727273, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.8117546848381602, 'class_Acc_5': 0.9368770764119602, 'class_Acc_6': 0.8680555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.0783132530120482, 'Unlab_loss(mb)': array(-5481.4067, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1083    -7898.120117   0.887677    -5481.406738  ...  0.765709  0.822536  5.543218\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  37%|███████████▋                    | 183/500 [55:18<1:52:28, 21.29s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.538109713121255, 'Train_Acc': 0.890053680246491, 'val_Acc': 0.8248920298390263, 'test_Acc': 0.7520053475935828, 'class_Acc_0': 0.17647058823529413, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8527272727272727, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7853492333901192, 'class_Acc_5': 0.915282392026578, 'class_Acc_6': 0.8715277777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.06626506024096386, 'Unlab_loss(mb)': array(-5496.8364, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1101    -7939.268555   0.890054    -5496.836426  ...  0.752005  0.824892  5.53811\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  37%|███████████▉                    | 186/500 [56:28<1:51:24, 21.29s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.550811252859499, 'Train_Acc': 0.8899743923313933, 'val_Acc': 0.8217510797016098, 'test_Acc': 0.7556818181818182, 'class_Acc_0': 0.1568627450980392, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.8581818181818179, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7717206132879045, 'class_Acc_5': 0.9435215946843855, 'class_Acc_6': 0.8750000000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.08433734939759036, 'Unlab_loss(mb)': array(-5166.047, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1118    -7684.978516   0.889974    -5166.046875  ...  0.755682  0.821751  5.550811\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  38%|████████████                    | 189/500 [57:37<1:50:03, 21.23s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.543243913490565, 'Train_Acc': 0.8929275590551182, 'val_Acc': 0.8197879858657244, 'test_Acc': 0.7794117647058824, 'class_Acc_0': 0.18627450980392163, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8218181818181817, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.836456558773424, 'class_Acc_5': 0.9385382059800664, 'class_Acc_6': 0.9097222222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.12650602409638556, 'Unlab_loss(mb)': array(-5435.8433, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1135    -7986.793457   0.892928    -5435.843262  ...  0.779412  0.819788  5.543244\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  38%|████████████▎                   | 192/500 [58:48<1:50:45, 21.58s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.511411166759908, 'Train_Acc': 0.8845800890106129, 'val_Acc': 0.8182175107970161, 'test_Acc': 0.7740641711229946, 'class_Acc_0': 0.12745098039215688, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8036363636363636, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.8500851788756388, 'class_Acc_5': 0.9418604651162791, 'class_Acc_6': 0.8923611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.06626506024096386, 'Unlab_loss(mb)': array(-5677.1406, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1152    -8162.856445    0.88458    -5677.140625  ...  0.774064  0.818218  5.511411\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  39%|████████████▍                   | 195/500 [59:58<1:48:02, 21.25s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.487180746631436, 'Train_Acc': 0.8918998014378637, 'val_Acc': 0.8197879858657244, 'test_Acc': 0.7640374331550802, 'class_Acc_0': 0.10784313725490197, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8363636363636362, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7998296422487223, 'class_Acc_5': 0.9435215946843855, 'class_Acc_6': 0.8993055555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.12048192771084337, 'Unlab_loss(mb)': array(-5740.479, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1170    -8251.661133     0.8919    -5740.479004  ...  0.764037  0.819788  5.487181\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  39%|███████████▊                  | 197/500 [1:00:50<1:56:20, 23.04s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.4838900681967, 'Train_Acc': 0.8987790893529614, 'val_Acc': 0.828818217510797, 'test_Acc': 0.7533422459893048, 'class_Acc_0': 0.19607843137254902, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8509090909090907, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7691652470187392, 'class_Acc_5': 0.9318936877076411, 'class_Acc_6': 0.8750000000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.15384615384615383, 'class_Acc_9': 0.15060240963855423, 'Unlab_loss(mb)': array(-6200.235, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1187    -8592.013672   0.898779    -6200.234863  ...  0.753342  0.828818  5.48389\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  40%|████████████                  | 200/500 [1:01:56<1:45:53, 21.18s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.467986844395547, 'Train_Acc': 0.8946551044162958, 'val_Acc': 0.8237141735374951, 'test_Acc': 0.7560160427807486, 'class_Acc_0': 0.12745098039215688, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.838181818181818, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7793867120954002, 'class_Acc_5': 0.9451827242524917, 'class_Acc_6': 0.8784722222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.11445783132530121, 'Unlab_loss(mb)': array(-6241.1123, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1205    -8646.279297   0.894655    -6241.112305  ...  0.756016  0.823714  5.467987\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  41%|████████████▏                 | 203/500 [1:03:06<1:44:40, 21.15s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.441499395501935, 'Train_Acc': 0.8974543923313933, 'val_Acc': 0.8241067923046722, 'test_Acc': 0.7443181818181818, 'class_Acc_0': 0.1568627450980392, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8709090909090909, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7453151618398636, 'class_Acc_5': 0.9318936877076411, 'class_Acc_6': 0.8437500000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.13253012048192772, 'Unlab_loss(mb)': array(-6275.097, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1223     -8727.46875   0.897454    -6275.097168  ...  0.744318  0.824107  5.441499\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  41%|████████████▎                 | 206/500 [1:04:15<1:43:45, 21.18s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.460400485121289, 'Train_Acc': 0.8941214378637454, 'val_Acc': 0.8241067923046722, 'test_Acc': 0.7456550802139037, 'class_Acc_0': 0.17647058823529413, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8781818181818182, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7572402044293015, 'class_Acc_5': 0.9219269102990033, 'class_Acc_6': 0.8437500000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.15384615384615383, 'class_Acc_9': 0.09638554216867468, 'Unlab_loss(mb)': array(-6272.124, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1241    -8663.342773   0.894121    -6272.124023  ...  0.745655  0.824107   5.4604\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  42%|████████████▌                 | 209/500 [1:05:23<1:40:39, 20.75s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.443233729091128, 'Train_Acc': 0.8923440739472783, 'val_Acc': 0.8217510797016098, 'test_Acc': 0.7703877005347594, 'class_Acc_0': 0.16666666666666669, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8309090909090909, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.8245315161839865, 'class_Acc_5': 0.9435215946843855, 'class_Acc_6': 0.8784722222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.08433734939759036, 'Unlab_loss(mb)': array(-6299.383, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1259    -8744.220703   0.892344    -6299.382812  ...  0.770388  0.821751  5.443234\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  42%|████████████▋                 | 212/500 [1:06:32<1:41:05, 21.06s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.420571629304144, 'Train_Acc': 0.8885073467990414, 'val_Acc': 0.8146839418924224, 'test_Acc': 0.7733957219251337, 'class_Acc_0': 0.1568627450980392, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.7345454545454546, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.8833049403747871, 'class_Acc_5': 0.925249169435216, 'class_Acc_6': 0.9097222222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.15384615384615383, 'class_Acc_9': 0.060240963855421686, 'Unlab_loss(mb)': array(-6301.633, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1277    -8773.099609   0.888507    -6301.632812  ...  0.773396  0.814684  5.420572\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  43%|████████████▉                 | 215/500 [1:07:40<1:38:41, 20.78s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.395938973400111, 'Train_Acc': 0.8971682711400205, 'val_Acc': 0.8252846486062034, 'test_Acc': 0.7687165775401069, 'class_Acc_0': 0.19607843137254902, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8036363636363636, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.8347529812606472, 'class_Acc_5': 0.9235880398671096, 'class_Acc_6': 0.8819444444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.12048192771084337, 'Unlab_loss(mb)': array(-6389.7197, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1295    -8852.142578   0.897168    -6389.719727  ...  0.768717  0.825285  5.395939\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  44%|█████████████                 | 218/500 [1:08:49<1:38:21, 20.93s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.393216309174996, 'Train_Acc': 0.9028508319068812, 'val_Acc': 0.8272477424420888, 'test_Acc': 0.7426470588235294, 'class_Acc_0': 0.17647058823529413, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8454545454545455, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.7427597955706985, 'class_Acc_5': 0.9186046511627907, 'class_Acc_6': 0.8854166666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.17469879518072287, 'Unlab_loss(mb)': array(-6367.6577, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1313     -8888.90918   0.902851    -6367.657715  ...  0.742647  0.827248  5.393216\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  44%|█████████████▎                | 221/500 [1:09:58<1:37:49, 21.04s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.372509267804423, 'Train_Acc': 0.896861937692571, 'val_Acc': 0.8280329799764429, 'test_Acc': 0.7566844919786097, 'class_Acc_0': 0.1568627450980392, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8363636363636362, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.8049403747870528, 'class_Acc_5': 0.925249169435216, 'class_Acc_6': 0.8298611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.10843373493975904, 'Unlab_loss(mb)': array(-6430.7417, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1331    -8924.635742   0.896862    -6430.741699  ...  0.756684  0.828033  5.372509\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  45%|█████████████▍                | 224/500 [1:11:07<1:37:05, 21.11s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.354626799781322, 'Train_Acc': 0.9032000136939404, 'val_Acc': 0.8303886925795053, 'test_Acc': 0.7566844919786097, 'class_Acc_0': 0.16666666666666669, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8272727272727272, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7921635434412266, 'class_Acc_5': 0.930232558139535, 'class_Acc_6': 0.8472222222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.17469879518072287, 'Unlab_loss(mb)': array(-6472.3794, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1349    -9004.149414     0.9032    -6472.379395  ...  0.756684  0.830389  5.354627\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  45%|█████████████▌                | 227/500 [1:12:15<1:35:27, 20.98s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.35196988337708, 'Train_Acc': 0.9023776651831565, 'val_Acc': 0.82842559874362, 'test_Acc': 0.7469919786096256, 'class_Acc_0': 0.23529411764705885, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8509090909090907, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7572402044293015, 'class_Acc_5': 0.9235880398671096, 'class_Acc_6': 0.8645833333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.13855421686746988, 'Unlab_loss(mb)': array(-6483.858, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1367    -9061.890625   0.902378     -6483.85791  ...  0.746992  0.828426  5.35197\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  46%|█████████████▊                | 230/500 [1:13:24<1:34:18, 20.96s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.331690437655834, 'Train_Acc': 0.9037138925025676, 'val_Acc': 0.8280329799764429, 'test_Acc': 0.7566844919786097, 'class_Acc_0': 0.21568627450980393, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8272727272727272, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.788756388415673, 'class_Acc_5': 0.9335548172757475, 'class_Acc_6': 0.8541666666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.14457831325301207, 'Unlab_loss(mb)': array(-6521.981, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1385      -9116.4375   0.903714    -6521.980957  ...  0.756684  0.828033  5.33169\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  47%|█████████████▉                | 233/500 [1:14:35<1:35:11, 21.39s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.337806159065332, 'Train_Acc': 0.9044414378637454, 'val_Acc': 0.8292108362779741, 'test_Acc': 0.7627005347593583, 'class_Acc_0': 0.2254901960784314, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8254545454545453, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7981260647359455, 'class_Acc_5': 0.9335548172757475, 'class_Acc_6': 0.8645833333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.34615384615384615, 'class_Acc_9': 0.15060240963855423, 'Unlab_loss(mb)': array(-6522.6733, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1403    -9106.042969   0.904441     -6522.67334  ...  0.762701  0.829211  5.337806\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  47%|██████████████▏               | 236/500 [1:15:43<1:32:30, 21.02s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.435439324926533, 'Train_Acc': 0.8982555289284492, 'val_Acc': 0.8264625049077345, 'test_Acc': 0.7473262032085561, 'class_Acc_0': 0.18627450980392163, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8290909090909091, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7930153321976149, 'class_Acc_5': 0.8870431893687708, 'class_Acc_6': 0.8750000000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.15384615384615383, 'class_Acc_9': 0.09638554216867468, 'Unlab_loss(mb)': array(-6220.391, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1421    -8626.730469   0.898256    -6220.391113  ...  0.747326  0.826463  5.435439\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  48%|██████████████▎               | 239/500 [1:16:53<1:32:25, 21.25s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.288704277554868, 'Train_Acc': 0.9043844984594316, 'val_Acc': 0.8303886925795053, 'test_Acc': 0.7476604278074866, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8472727272727273, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7751277683134581, 'class_Acc_5': 0.9036544850498339, 'class_Acc_6': 0.8472222222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.12650602409638556, 'Unlab_loss(mb)': array(-6582.07, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1439    -9123.129883   0.904384    -6582.069824  ...   0.74766  0.830389  5.288704\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  48%|██████████████▌               | 242/500 [1:18:01<1:30:19, 21.00s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.310685887395808, 'Train_Acc': 0.9016162410133516, 'val_Acc': 0.8296034550451512, 'test_Acc': 0.7556818181818182, 'class_Acc_0': 0.18627450980392163, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8254545454545453, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.8023850085178875, 'class_Acc_5': 0.9186046511627907, 'class_Acc_6': 0.8611111111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.09638554216867468, 'Unlab_loss(mb)': array(-6549.9556, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1457    -9197.525391   0.901616    -6549.955566  ...  0.755682  0.829603  5.310686\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  49%|██████████████▋               | 245/500 [1:19:12<1:30:26, 21.28s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.287248432949804, 'Train_Acc': 0.9084872714823691, 'val_Acc': 0.8327444051825678, 'test_Acc': 0.7516711229946524, 'class_Acc_0': 0.2450980392156863, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8363636363636362, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7751277683134581, 'class_Acc_5': 0.915282392026578, 'class_Acc_6': 0.8819444444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.15384615384615383, 'class_Acc_9': 0.14457831325301207, 'Unlab_loss(mb)': array(-6605.918, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1475    -9274.739258   0.908487    -6605.917969  ...  0.751671  0.832744  5.287248\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  50%|██████████████▉               | 248/500 [1:20:21<1:29:29, 21.31s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.261445465834218, 'Train_Acc': 0.9094800136939404, 'val_Acc': 0.8315665488810365, 'test_Acc': 0.7449866310160428, 'class_Acc_0': 0.2254901960784314, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8345454545454544, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7649063032367972, 'class_Acc_5': 0.9186046511627907, 'class_Acc_6': 0.8437500000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.16265060240963855, 'Unlab_loss(mb)': array(-6677.935, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1493    -9332.295898    0.90948    -6677.935059  ...  0.744987  0.831567  5.261445\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  50%|███████████████               | 251/500 [1:21:29<1:27:03, 20.98s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.263995776843185, 'Train_Acc': 0.9053593016090381, 'val_Acc': 0.8307813113466823, 'test_Acc': 0.7580213903743316, 'class_Acc_0': 0.2450980392156863, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.810909090909091, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7955706984667803, 'class_Acc_5': 0.9285714285714286, 'class_Acc_6': 0.8888888888888887, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.11445783132530121, 'Unlab_loss(mb)': array(-6660.4873, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1511    -9369.111328   0.905359    -6660.487305  ...  0.758021  0.830781  5.263996\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  51%|███████████████▏              | 254/500 [1:22:39<1:26:51, 21.19s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.2655157255736, 'Train_Acc': 0.9089232865457036, 'val_Acc': 0.8276403612092658, 'test_Acc': 0.767379679144385, 'class_Acc_0': 0.2450980392156863, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.7999999999999999, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.8262350936967632, 'class_Acc_5': 0.930232558139535, 'class_Acc_6': 0.8645833333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.14457831325301207, 'Unlab_loss(mb)': array(-6681.606, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1529    -9378.595703   0.908923    -6681.605957  ...   0.76738  0.82764  5.265516\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  51%|███████████████▍              | 257/500 [1:23:48<1:27:04, 21.50s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.240300497013896, 'Train_Acc': 0.9085924683327627, 'val_Acc': 0.8296034550451512, 'test_Acc': 0.7526737967914439, 'class_Acc_0': 0.20588235294117646, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8254545454545453, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7810902896081771, 'class_Acc_5': 0.9335548172757475, 'class_Acc_6': 0.8472222222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.15060240963855423, 'Unlab_loss(mb)': array(-6704.0913, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1547    -9429.472656   0.908592    -6704.091309  ...  0.752674  0.829603   5.2403\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  52%|███████████████▋              | 261/500 [1:25:13<1:18:40, 19.75s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.236748001363895, 'Train_Acc': 0.9006753166723724, 'val_Acc': 0.8241067923046722, 'test_Acc': 0.7647058823529411, 'class_Acc_0': 0.19607843137254902, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.7854545454545454, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.8475298126064735, 'class_Acc_5': 0.9335548172757475, 'class_Acc_6': 0.8437500000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.15384615384615383, 'class_Acc_9': 0.07228915662650603, 'Unlab_loss(mb)': array(-6255.152, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1566    -9086.441406   0.900675    -6255.151855  ...  0.764706  0.824107  5.236748\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  53%|███████████████▊              | 264/500 [1:26:23<1:21:13, 20.65s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.24437310488974, 'Train_Acc': 0.9082541047586442, 'val_Acc': 0.8276403612092658, 'test_Acc': 0.7640374331550802, 'class_Acc_0': 0.18627450980392163, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.7945454545454544, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.8228279386712094, 'class_Acc_5': 0.9335548172757475, 'class_Acc_6': 0.8680555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.13855421686746988, 'Unlab_loss(mb)': array(-6225.3477, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1584    -9134.878906   0.908254    -6225.347656  ...  0.764037  0.82764  5.244373\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  53%|████████████████              | 267/500 [1:27:32<1:21:31, 21.00s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.201686801814686, 'Train_Acc': 0.9079171653543308, 'val_Acc': 0.8307813113466823, 'test_Acc': 0.7600267379679144, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.810909090909091, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.8117546848381602, 'class_Acc_5': 0.9102990033222592, 'class_Acc_6': 0.8784722222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.12048192771084337, 'Unlab_loss(mb)': array(-6129.633, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1603    -9086.223633   0.907917    -6129.632812  ...  0.760027  0.830781  5.201687\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  54%|████████████████▏             | 270/500 [1:28:41<1:20:52, 21.10s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.212554916605133, 'Train_Acc': 0.9054508319068812, 'val_Acc': 0.8225363172359639, 'test_Acc': 0.767379679144385, 'class_Acc_0': 0.21568627450980393, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.7509090909090909, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.8534923339011925, 'class_Acc_5': 0.9186046511627907, 'class_Acc_6': 0.8958333333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.11445783132530121, 'Unlab_loss(mb)': array(-6112.8726, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1621    -9065.599609   0.905451    -6112.872559  ...   0.76738  0.822536  5.212555\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  55%|████████████████▍             | 273/500 [1:29:51<1:20:16, 21.22s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.182392164524672, 'Train_Acc': 0.9144948168435467, 'val_Acc': 0.8319591676482135, 'test_Acc': 0.7546791443850267, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8036363636363636, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7981260647359455, 'class_Acc_5': 0.9053156146179402, 'class_Acc_6': 0.8680555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.18072289156626506, 'Unlab_loss(mb)': array(-5932.4893, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1640     -8968.34668   0.914495    -5932.489258  ...  0.754679  0.831959  5.182392\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  55%|████████████████▌             | 276/500 [1:31:01<1:19:17, 21.24s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.211954263298722, 'Train_Acc': 0.913261650119822, 'val_Acc': 0.8307813113466823, 'test_Acc': 0.7586898395721925, 'class_Acc_0': 0.2647058823529412, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8163636363636363, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7896081771720612, 'class_Acc_5': 0.925249169435216, 'class_Acc_6': 0.8750000000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.1686746987951807, 'Unlab_loss(mb)': array(-6200.8276, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1659     -9127.06543   0.913262    -6200.827637  ...   0.75869  0.830781  5.211954\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  56%|████████████████▋             | 279/500 [1:32:10<1:17:44, 21.11s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.285300888570062, 'Train_Acc': 0.9120439986306059, 'val_Acc': 0.8264625049077345, 'test_Acc': 0.7459893048128342, 'class_Acc_0': 0.14705882352941177, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8309090909090909, 'class_Acc_3': 0.7586206896551724, 'class_Acc_4': 0.7623509369676321, 'class_Acc_5': 0.9352159468438538, 'class_Acc_6': 0.8611111111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.07692307692307691, 'class_Acc_9': 0.1686746987951807, 'Unlab_loss(mb)': array(-6061.548, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1678    -8916.961914   0.912044    -6061.547852  ...  0.745989  0.826463  5.285301\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  56%|████████████████▉             | 282/500 [1:33:19<1:16:10, 20.97s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.162613811123944, 'Train_Acc': 0.9122919685039369, 'val_Acc': 0.8292108362779741, 'test_Acc': 0.7433155080213903, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8309090909090909, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7640545144804088, 'class_Acc_5': 0.915282392026578, 'class_Acc_6': 0.8437500000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.15384615384615383, 'class_Acc_9': 0.13855421686746988, 'Unlab_loss(mb)': array(-6880.49, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1697    -9683.492188   0.912292    -6880.490234  ...  0.743316  0.829211  5.162614\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  57%|█████████████████▏            | 286/500 [1:34:47<1:11:53, 20.16s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.164201620998047, 'Train_Acc': 0.9077985895241356, 'val_Acc': 0.8276403612092658, 'test_Acc': 0.7195855614973262, 'class_Acc_0': 0.19607843137254902, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.8527272727272727, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7001703577512777, 'class_Acc_5': 0.9169435215946843, 'class_Acc_6': 0.8472222222222223, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.12048192771084337, 'Unlab_loss(mb)': array(-6413.693, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1716    -9362.949219   0.907799    -6413.692871  ...  0.719586  0.82764  5.164202\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  58%|█████████████████▎            | 289/500 [1:35:57<1:13:30, 20.90s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.148399367064664, 'Train_Acc': 0.9093409380349196, 'val_Acc': 0.8307813113466823, 'test_Acc': 0.7616978609625669, 'class_Acc_0': 0.23529411764705885, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.7763636363636363, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.838160136286201, 'class_Acc_5': 0.9019933554817275, 'class_Acc_6': 0.8611111111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.14457831325301207, 'Unlab_loss(mb)': array(-6239.487, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1735    -9305.088867   0.909341    -6239.486816  ...  0.761698  0.830781  5.148399\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  58%|█████████████████▌            | 292/500 [1:37:05<1:12:05, 20.80s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.1756328189115495, 'Train_Acc': 0.9157802259500171, 'val_Acc': 0.8319591676482135, 'test_Acc': 0.732620320855615, 'class_Acc_0': 0.2647058823529412, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8290909090909091, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7453151618398636, 'class_Acc_5': 0.893687707641196, 'class_Acc_6': 0.8506944444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.12650602409638556, 'Unlab_loss(mb)': array(-5954.812, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1754    -9018.182617    0.91578    -5954.812012  ...   0.73262  0.831959  5.175633\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  59%|█████████████████▋            | 295/500 [1:38:15<1:12:12, 21.13s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.119544292178655, 'Train_Acc': 0.9166757411845259, 'val_Acc': 0.8335296427169219, 'test_Acc': 0.7489973262032086, 'class_Acc_0': 0.23529411764705885, 'class_Acc_1': 0.03636363636363636, 'class_Acc_2': 0.7854545454545454, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.8040885860306644, 'class_Acc_5': 0.9119601328903656, 'class_Acc_6': 0.8090277777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.15384615384615383, 'class_Acc_9': 0.19277108433734935, 'Unlab_loss(mb)': array(-6405.906, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1773    -9364.130859   0.916676    -6405.905762  ...  0.748997  0.83353  5.119544\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  60%|█████████████████▉            | 298/500 [1:39:26<1:11:52, 21.35s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.116569203284114, 'Train_Acc': 0.9211089079082505, 'val_Acc': 0.8382410679230468, 'test_Acc': 0.7466577540106952, 'class_Acc_0': 0.27450980392156865, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.8036363636363636, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7742759795570698, 'class_Acc_5': 0.9102990033222592, 'class_Acc_6': 0.8437500000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.21686746987951808, 'Unlab_loss(mb)': array(-6413.2764, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1791    -9394.242188   0.921109    -6413.276367  ...  0.746658  0.838241  5.116569\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  60%|██████████████████            | 301/500 [1:40:35<1:10:16, 21.19s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.112254267725621, 'Train_Acc': 0.9171604382060938, 'val_Acc': 0.8311739301138594, 'test_Acc': 0.7456550802139037, 'class_Acc_0': 0.21568627450980393, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8163636363636363, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7810902896081771, 'class_Acc_5': 0.9003322259136213, 'class_Acc_6': 0.8298611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.18674698795180722, 'Unlab_loss(mb)': array(-6421.6616, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1810    -9438.001953    0.91716    -6421.661621  ...  0.745655  0.831174  5.112254\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  61%|██████████████████▏           | 304/500 [1:41:45<1:09:31, 21.28s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.091156261634496, 'Train_Acc': 0.916114317014721, 'val_Acc': 0.8347074990184531, 'test_Acc': 0.74298128342246, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8181818181818182, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7742759795570698, 'class_Acc_5': 0.8970099667774086, 'class_Acc_6': 0.8402777777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.1566265060240964, 'Unlab_loss(mb)': array(-7032.657, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1829    -9918.174805   0.916114    -7032.657227  ...  0.742981  0.834707  5.091156\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  62%|██████████████████▍           | 308/500 [1:43:11<1:03:34, 19.87s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.079800908528646, 'Train_Acc': 0.9125171653543308, 'val_Acc': 0.8307813113466823, 'test_Acc': 0.7436497326203209, 'class_Acc_0': 0.20588235294117646, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8072727272727274, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7904599659284498, 'class_Acc_5': 0.8970099667774086, 'class_Acc_6': 0.8333333333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.13253012048192772, 'Unlab_loss(mb)': array(-6589.434, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1848    -9621.996094   0.912517    -6589.434082  ...   0.74365  0.830781  5.079801\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  62%|██████████████████▋           | 311/500 [1:44:21<1:05:40, 20.85s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.090477415383974, 'Train_Acc': 0.9159150290996233, 'val_Acc': 0.8335296427169219, 'test_Acc': 0.7446524064171123, 'class_Acc_0': 0.29411764705882354, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8036363636363636, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7827938671209538, 'class_Acc_5': 0.8970099667774086, 'class_Acc_6': 0.8506944444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.13855421686746988, 'Unlab_loss(mb)': array(-6356.4805, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1867    -9505.466797   0.915915    -6356.480469  ...  0.744652  0.83353  5.090477\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  63%|██████████████████▊           | 314/500 [1:45:30<1:05:06, 21.00s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.073056356175218, 'Train_Acc': 0.9227773776104075, 'val_Acc': 0.833922261484099, 'test_Acc': 0.7309491978609626, 'class_Acc_0': 0.2450980392156863, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8290909090909091, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7223168654173764, 'class_Acc_5': 0.9053156146179402, 'class_Acc_6': 0.8437500000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.24096385542168675, 'Unlab_loss(mb)': array(-6178.194, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1886    -9334.857422   0.922777    -6178.193848  ...  0.730949  0.833922  5.073056\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  63%|███████████████████           | 317/500 [1:46:40<1:04:26, 21.13s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.058036266496588, 'Train_Acc': 0.9189672714823691, 'val_Acc': 0.8335296427169219, 'test_Acc': 0.7195855614973262, 'class_Acc_0': 0.2450980392156863, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8327272727272728, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7044293015332198, 'class_Acc_5': 0.9003322259136213, 'class_Acc_6': 0.8333333333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.18072289156626506, 'Unlab_loss(mb)': array(-6531.991, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1905    -9601.492188   0.918967    -6531.991211  ...  0.719586  0.83353  5.058036\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  64%|███████████████████▏          | 320/500 [1:47:49<1:03:08, 21.05s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.049050652705947, 'Train_Acc': 0.919999014036289, 'val_Acc': 0.8327444051825678, 'test_Acc': 0.7456550802139037, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.01818181818181818, 'class_Acc_2': 0.7818181818181817, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7896081771720612, 'class_Acc_5': 0.8970099667774086, 'class_Acc_6': 0.8715277777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.1686746987951807, 'Unlab_loss(mb)': array(-6550.978, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1924    -9498.881836   0.919999    -6550.978027  ...  0.745655  0.832744  5.049051\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  65%|███████████████████▍          | 323/500 [1:48:57<1:01:49, 20.96s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.03635286998604, 'Train_Acc': 0.919811968503937, 'val_Acc': 0.8335296427169219, 'test_Acc': 0.7269385026737968, 'class_Acc_0': 0.20588235294117646, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8218181818181817, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7385008517887565, 'class_Acc_5': 0.8953488372093024, 'class_Acc_6': 0.8229166666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.1686746987951807, 'Unlab_loss(mb)': array(-6581.9766, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1942    -9717.414062   0.919812    -6581.976562  ...  0.726939  0.83353  5.036353\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  65%|███████████████████▌          | 326/500 [1:50:08<1:01:45, 21.29s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.046003006394799, 'Train_Acc': 0.9225629989729546, 'val_Acc': 0.8351001177856302, 'test_Acc': 0.7446524064171123, 'class_Acc_0': 0.2450980392156863, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8090909090909092, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7717206132879045, 'class_Acc_5': 0.9053156146179402, 'class_Acc_6': 0.8576388888888887, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.17469879518072287, 'Unlab_loss(mb)': array(-7149.4756, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1961   -10103.958008   0.922563    -7149.475586  ...  0.744652   0.8351  5.046003\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  66%|█████████████████████           | 330/500 [1:51:34<56:24, 19.91s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.023177711123859, 'Train_Acc': 0.9186051352276619, 'val_Acc': 0.8335296427169219, 'test_Acc': 0.7299465240641712, 'class_Acc_0': 0.2450980392156863, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.8218181818181817, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7385008517887565, 'class_Acc_5': 0.9019933554817275, 'class_Acc_6': 0.8368055555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.14457831325301207, 'Unlab_loss(mb)': array(-6700.6084, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","1980     -9758.28125   0.918605    -6700.608398  ...  0.729947  0.83353  5.023178\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  67%|█████████████████████▎          | 333/500 [1:52:43<57:50, 20.78s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.024930829804731, 'Train_Acc': 0.9188072714823691, 'val_Acc': 0.8366705928543384, 'test_Acc': 0.7466577540106952, 'class_Acc_0': 0.20588235294117646, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.7890909090909091, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7879045996592844, 'class_Acc_5': 0.9119601328903656, 'class_Acc_6': 0.8680555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.14457831325301207, 'Unlab_loss(mb)': array(-6507.4136, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1999    -9672.982422   0.918807    -6507.413574  ...  0.746658  0.836671  5.024931\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  67%|█████████████████████▌          | 336/500 [1:53:53<57:39, 21.10s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.015619529487118, 'Train_Acc': 0.922754317014721, 'val_Acc': 0.8390263054574009, 'test_Acc': 0.7503342245989305, 'class_Acc_0': 0.2843137254901961, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7799999999999999, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.803236797274276, 'class_Acc_5': 0.8953488372093024, 'class_Acc_6': 0.8402777777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.18072289156626506, 'Unlab_loss(mb)': array(-6284.1396, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","2018    -9520.999023   0.922754    -6284.139648  ...  0.750334  0.839026  5.01562\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  68%|█████████████████████▋          | 339/500 [1:55:03<56:48, 21.17s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.99913161970748, 'Train_Acc': 0.9221827867168777, 'val_Acc': 0.8362779740871613, 'test_Acc': 0.7449866310160428, 'class_Acc_0': 0.29411764705882354, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.7890909090909091, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7853492333901192, 'class_Acc_5': 0.8953488372093024, 'class_Acc_6': 0.8402777777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.18674698795180722, 'Unlab_loss(mb)': array(-6655.415, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2037    -9795.511719   0.922183    -6655.415039  ...  0.744987  0.836278  4.999132\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  68%|█████████████████████▉          | 342/500 [1:56:13<56:14, 21.36s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.031986745052725, 'Train_Acc': 0.926621362547073, 'val_Acc': 0.8390263054574009, 'test_Acc': 0.7286096256684492, 'class_Acc_0': 0.27450980392156865, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.8072727272727274, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7214650766609879, 'class_Acc_5': 0.8903654485049833, 'class_Acc_6': 0.8541666666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.27710843373493976, 'Unlab_loss(mb)': array(-6603.3887, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2056     -9766.80957   0.926621    -6603.388672  ...   0.72861  0.839026  5.031987\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  69%|██████████████████████          | 345/500 [1:57:21<54:30, 21.10s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.981739677390825, 'Train_Acc': 0.9215027867168778, 'val_Acc': 0.8358853553199843, 'test_Acc': 0.7366310160427807, 'class_Acc_0': 0.27450980392156865, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7745454545454544, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7759795570698467, 'class_Acc_5': 0.8853820598006644, 'class_Acc_6': 0.8576388888888887, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.1686746987951807, 'Unlab_loss(mb)': array(-7256.6426, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","2075   -10259.642578   0.921503    -7256.642578  ...  0.736631  0.835885  4.98174\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  70%|██████████████████████▎         | 349/500 [1:58:47<49:28, 19.66s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.9858254348308435, 'Train_Acc': 0.9216303320780556, 'val_Acc': 0.8358853553199843, 'test_Acc': 0.7312834224598931, 'class_Acc_0': 0.20588235294117646, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8054545454545455, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7512776831345827, 'class_Acc_5': 0.898671096345515, 'class_Acc_6': 0.8402777777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.34615384615384615, 'class_Acc_9': 0.1566265060240964, 'Unlab_loss(mb)': array(-6583.095, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2095    -9806.304688    0.92163    -6583.095215  ...  0.731283  0.835885  4.985825\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  70%|██████████████████████▌         | 352/500 [1:59:59<52:00, 21.09s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.00120596345605, 'Train_Acc': 0.9259420746319754, 'val_Acc': 0.8354927365528072, 'test_Acc': 0.741644385026738, 'class_Acc_0': 0.23529411764705885, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7799999999999999, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7734241908006814, 'class_Acc_5': 0.9102990033222592, 'class_Acc_6': 0.8645833333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.18072289156626506, 'Unlab_loss(mb)': array(-6321.88, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2114    -9625.099609   0.925942    -6321.879883  ...  0.741644  0.835493  5.001206\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  71%|██████████████████████▋         | 355/500 [2:01:06<50:32, 20.91s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.968520608376847, 'Train_Acc': 0.9250696199931531, 'val_Acc': 0.8374558303886925, 'test_Acc': 0.7369652406417112, 'class_Acc_0': 0.29411764705882354, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7872727272727272, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.768313458262351, 'class_Acc_5': 0.888704318936877, 'class_Acc_6': 0.8506944444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.18674698795180722, 'Unlab_loss(mb)': array(-6718.632, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2133    -9916.484375    0.92507    -6718.631836  ...  0.736965  0.837456  4.968521\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  72%|██████████████████████▉         | 358/500 [2:02:16<49:59, 21.12s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.96879017444243, 'Train_Acc': 0.9273136049298185, 'val_Acc': 0.8386336866902238, 'test_Acc': 0.7249331550802139, 'class_Acc_0': 0.2647058823529412, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.8127272727272726, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7214650766609879, 'class_Acc_5': 0.8953488372093024, 'class_Acc_6': 0.8402777777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.23493975903614456, 'Unlab_loss(mb)': array(-6729.176, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","2152    -9935.385742   0.927314    -6729.175781  ...  0.724933  0.838634  4.96879\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  72%|███████████████████████         | 361/500 [2:03:25<48:40, 21.01s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.955292851257967, 'Train_Acc': 0.9214505443341321, 'val_Acc': 0.8335296427169219, 'test_Acc': 0.7376336898395722, 'class_Acc_0': 0.20588235294117646, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.7981818181818181, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7708688245315162, 'class_Acc_5': 0.9069767441860466, 'class_Acc_6': 0.8437500000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.13253012048192772, 'Unlab_loss(mb)': array(-7325.6455, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","2171   -10401.323242   0.921451    -7325.645508  ...  0.737634  0.83353  4.955293\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  73%|███████████████████████▎        | 365/500 [2:04:52<44:59, 20.00s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.954492136725182, 'Train_Acc': 0.9244837110578569, 'val_Acc': 0.8358853553199843, 'test_Acc': 0.7202540106951871, 'class_Acc_0': 0.20588235294117646, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8236363636363635, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.717206132879046, 'class_Acc_5': 0.8903654485049833, 'class_Acc_6': 0.8437500000000001, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.17469879518072287, 'Unlab_loss(mb)': array(-6841.686, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2190   -10041.955078   0.924484    -6841.686035  ...  0.720254  0.835885  4.954492\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  74%|███████████████████████▌        | 368/500 [2:06:02<45:46, 20.81s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.952295220253411, 'Train_Acc': 0.9221510441629578, 'val_Acc': 0.8347074990184531, 'test_Acc': 0.7393048128342246, 'class_Acc_0': 0.2254901960784314, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.7818181818181817, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7844974446337307, 'class_Acc_5': 0.8953488372093024, 'class_Acc_6': 0.8333333333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.1923076923076923, 'class_Acc_9': 0.17469879518072287, 'Unlab_loss(mb)': array(-6650.42, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2209    -9921.976562   0.922151    -6650.419922  ...  0.739305  0.834707  4.952295\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  74%|███████████████████████▋        | 371/500 [2:07:11<45:27, 21.14s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.946899437482482, 'Train_Acc': 0.9182472714823691, 'val_Acc': 0.8327444051825678, 'test_Acc': 0.7362967914438503, 'class_Acc_0': 0.21568627450980393, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.810909090909091, 'class_Acc_3': 0.7241379310344828, 'class_Acc_4': 0.7717206132879045, 'class_Acc_5': 0.8953488372093024, 'class_Acc_6': 0.8298611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.12650602409638556, 'Unlab_loss(mb)': array(-6438.799, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2228    -9790.330078   0.918247    -6438.798828  ...  0.736297  0.832744  4.946899\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  75%|███████████████████████▉        | 374/500 [2:08:21<44:34, 21.23s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.937735365320899, 'Train_Acc': 0.9324300445053064, 'val_Acc': 0.8390263054574009, 'test_Acc': 0.7292780748663101, 'class_Acc_0': 0.303921568627451, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.7981818181818181, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7265758091993185, 'class_Acc_5': 0.893687707641196, 'class_Acc_6': 0.8333333333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.30120481927710846, 'Unlab_loss(mb)': array(-6789.9487, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2247   -10039.399414    0.93243     -6789.94873  ...  0.729278  0.839026  4.937735\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  75%|████████████████████████▏       | 377/500 [2:09:31<43:44, 21.33s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.937017305191498, 'Train_Acc': 0.9275637110578568, 'val_Acc': 0.8378484491558696, 'test_Acc': 0.7332887700534759, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.7927272727272726, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7572402044293015, 'class_Acc_5': 0.8820598006644518, 'class_Acc_6': 0.8368055555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.2469879518072289, 'Unlab_loss(mb)': array(-6795.361, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2266   -10040.616211   0.927564     -6795.36084  ...  0.733289  0.837848  4.937017\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  76%|████████████████████████▎       | 380/500 [2:10:40<42:13, 21.11s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.924219257044758, 'Train_Acc': 0.9277597261211914, 'val_Acc': 0.8390263054574009, 'test_Acc': 0.7322860962566845, 'class_Acc_0': 0.2254901960784314, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.7872727272727272, 'class_Acc_3': 0.689655172413793, 'class_Acc_4': 0.7632027257240204, 'class_Acc_5': 0.8787375415282392, 'class_Acc_6': 0.8402777777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.23493975903614456, 'Unlab_loss(mb)': array(-7391.2803, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2285   -10511.575195    0.92776    -7391.280273  ...  0.732286  0.839026  4.924219\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  77%|████████████████████████▌       | 384/500 [2:12:07<38:51, 20.10s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.922359298154966, 'Train_Acc': 0.9237366655255049, 'val_Acc': 0.8347074990184531, 'test_Acc': 0.7306149732620321, 'class_Acc_0': 0.2254901960784314, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.810909090909091, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.752129471890971, 'class_Acc_5': 0.8870431893687708, 'class_Acc_6': 0.8368055555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.17469879518072287, 'Unlab_loss(mb)': array(-6920.8184, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2304   -10116.823242   0.923737    -6920.818359  ...  0.730615  0.834707  4.922359\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  77%|████████████████████████▊       | 387/500 [2:13:16<39:04, 20.75s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.913336114180969, 'Train_Acc': 0.9247597261211914, 'val_Acc': 0.8351001177856302, 'test_Acc': 0.7292780748663101, 'class_Acc_0': 0.23529411764705885, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8018181818181818, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.75809199318569, 'class_Acc_5': 0.8853820598006644, 'class_Acc_6': 0.8229166666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.1566265060240964, 'Unlab_loss(mb)': array(-6737.819, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","2323   -10042.386719    0.92476    -6737.818848  ...  0.729278   0.8351  4.913336\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  78%|████████████████████████▉       | 390/500 [2:14:27<38:58, 21.26s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.910087937016154, 'Train_Acc': 0.9285889079082505, 'val_Acc': 0.8386336866902238, 'test_Acc': 0.7336229946524064, 'class_Acc_0': 0.2450980392156863, 'class_Acc_1': 0.05454545454545455, 'class_Acc_2': 0.7945454545454544, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7606473594548551, 'class_Acc_5': 0.8837209302325579, 'class_Acc_6': 0.8333333333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.22891566265060243, 'Unlab_loss(mb)': array(-6520.257, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2342    -9915.026367   0.928589    -6520.256836  ...  0.733623  0.838634  4.910088\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  79%|█████████████████████████▏      | 393/500 [2:15:35<37:30, 21.03s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.908907059190531, 'Train_Acc': 0.9316905443341321, 'val_Acc': 0.839418924224578, 'test_Acc': 0.7332887700534759, 'class_Acc_0': 0.2843137254901961, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.7981818181818181, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.752129471890971, 'class_Acc_5': 0.8803986710963454, 'class_Acc_6': 0.826388888888889, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.26506024096385544, 'Unlab_loss(mb)': array(-6843.108, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2361   -10138.349609   0.931691     -6843.10791  ...  0.733289  0.839419  4.908907\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  79%|█████████████████████████▎      | 396/500 [2:16:44<36:25, 21.02s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.90262626378791, 'Train_Acc': 0.9327907565902089, 'val_Acc': 0.8409893992932862, 'test_Acc': 0.7366310160427807, 'class_Acc_0': 0.3137254901960784, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.7854545454545454, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7657580919931857, 'class_Acc_5': 0.8787375415282392, 'class_Acc_6': 0.8333333333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.25903614457831325, 'Unlab_loss(mb)': array(-7438.04, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2381    -10607.96875   0.932791    -7438.040039  ...  0.736631  0.840989  4.902626\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  80%|█████████████████████████▌      | 400/500 [2:18:10<33:18, 19.99s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.885431564933878, 'Train_Acc': 0.9261128928449162, 'val_Acc': 0.8358853553199843, 'test_Acc': 0.731951871657754, 'class_Acc_0': 0.21568627450980393, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.7836363636363636, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7742759795570698, 'class_Acc_5': 0.8853820598006644, 'class_Acc_6': 0.8229166666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.17469879518072287, 'Unlab_loss(mb)': array(-6982.0957, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2400   -10289.861328   0.926113    -6982.095703  ...  0.731952  0.835885  4.885432\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  81%|█████████████████████████▊      | 403/500 [2:19:18<33:11, 20.53s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.887848032164638, 'Train_Acc': 0.9268822868880521, 'val_Acc': 0.8358853553199843, 'test_Acc': 0.7269385026737968, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.810909090909091, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7495741056218058, 'class_Acc_5': 0.8787375415282392, 'class_Acc_6': 0.826388888888889, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.1566265060240964, 'Unlab_loss(mb)': array(-6563.56, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2420    -9705.890625   0.926882    -6563.560059  ...  0.726939  0.835885  4.887848\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  81%|█████████████████████████▉      | 406/500 [2:20:31<33:28, 21.37s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.8829195285492055, 'Train_Acc': 0.930066059568641, 'val_Acc': 0.8390263054574009, 'test_Acc': 0.7219251336898396, 'class_Acc_0': 0.2450980392156863, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8054545454545455, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7350936967632027, 'class_Acc_5': 0.8754152823920266, 'class_Acc_6': 0.8194444444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.21686746987951808, 'Unlab_loss(mb)': array(-6896.7173, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","2439   -10215.239258   0.930066    -6896.717285  ...  0.721925  0.839026  4.88292\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  82%|██████████████████████████▏     | 409/500 [2:21:41<32:25, 21.37s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.885700896185815, 'Train_Acc': 0.9309867716535433, 'val_Acc': 0.8390263054574009, 'test_Acc': 0.7259358288770054, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8036363636363636, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7385008517887565, 'class_Acc_5': 0.877076411960133, 'class_Acc_6': 0.8333333333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.24096385542168675, 'Unlab_loss(mb)': array(-6904.4404, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2458   -10230.282227   0.930987     -6904.44043  ...  0.725936  0.839026  4.885701\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  83%|██████████████████████████▍     | 413/500 [2:23:06<28:58, 19.99s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.8729918424109, 'Train_Acc': 0.9284959534406024, 'val_Acc': 0.8366705928543384, 'test_Acc': 0.7259358288770054, 'class_Acc_0': 0.21568627450980393, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8072727272727274, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.747870528109029, 'class_Acc_5': 0.8820598006644518, 'class_Acc_6': 0.826388888888889, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.1686746987951807, 'Unlab_loss(mb)': array(-7006.99, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2478   -10300.324219   0.928496    -7006.990234  ...  0.725936  0.836671  4.872992\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  83%|██████████████████████████▌     | 416/500 [2:24:16<29:05, 20.78s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.875272587354285, 'Train_Acc': 0.9297622868880521, 'val_Acc': 0.8378484491558696, 'test_Acc': 0.7299465240641712, 'class_Acc_0': 0.2254901960784314, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8090909090909092, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7572402044293015, 'class_Acc_5': 0.8853820598006644, 'class_Acc_6': 0.8159722222222222, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.18072289156626506, 'Unlab_loss(mb)': array(-6805.542, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2497   -10208.136719   0.929762    -6805.541992  ...  0.729947  0.837848  4.875273\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  84%|██████████████████████████▊     | 419/500 [2:25:28<28:49, 21.35s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.869707034317314, 'Train_Acc': 0.9277936049298185, 'val_Acc': 0.8370632116215155, 'test_Acc': 0.733957219251337, 'class_Acc_0': 0.23529411764705885, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7781818181818181, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7836456558773423, 'class_Acc_5': 0.888704318936877, 'class_Acc_6': 0.8055555555555556, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.16265060240963855, 'Unlab_loss(mb)': array(-6604.0903, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2516   -10053.517578   0.927794    -6604.090332  ...  0.733957  0.837063  4.869707\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  84%|███████████████████████████     | 422/500 [2:26:37<27:32, 21.19s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.867757141801112, 'Train_Acc': 0.9303637110578569, 'val_Acc': 0.8386336866902238, 'test_Acc': 0.7279411764705882, 'class_Acc_0': 0.2647058823529412, 'class_Acc_1': 0.07272727272727272, 'class_Acc_2': 0.8018181818181818, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.752129471890971, 'class_Acc_5': 0.877076411960133, 'class_Acc_6': 0.8194444444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.19879518072289157, 'Unlab_loss(mb)': array(-6938.574, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2536   -10295.948242   0.930364    -6938.574219  ...  0.727941  0.838634  4.867757\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  85%|███████████████████████████▎    | 426/500 [2:28:03<24:37, 19.96s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.859636111854963, 'Train_Acc': 0.9304159534406025, 'val_Acc': 0.8378484491558696, 'test_Acc': 0.7302807486631016, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7927272727272726, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7597955706984668, 'class_Acc_5': 0.8820598006644518, 'class_Acc_6': 0.8090277777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.21084337349397592, 'Unlab_loss(mb)': array(-7034.4204, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2556   -10332.216797   0.930416     -7034.42041  ...  0.730281  0.837848  4.859636\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  86%|███████████████████████████▍    | 429/500 [2:29:13<24:35, 20.79s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.851987292150874, 'Train_Acc': 0.927896665525505, 'val_Acc': 0.8374558303886925, 'test_Acc': 0.7306149732620321, 'class_Acc_0': 0.2843137254901961, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7909090909090909, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7717206132879045, 'class_Acc_5': 0.8720930232558141, 'class_Acc_6': 0.8090277777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.1566265060240964, 'Unlab_loss(mb)': array(-6856.4316, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2575   -10242.052734   0.927897    -6856.431641  ...  0.730615  0.837456  4.851987\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  87%|███████████████████████████▋    | 433/500 [2:30:21<18:22, 16.45s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.857073120909113, 'Train_Acc': 0.9266058473125641, 'val_Acc': 0.8358853553199843, 'test_Acc': 0.7349598930481284, 'class_Acc_0': 0.2647058823529412, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7836363636363636, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7827938671209538, 'class_Acc_5': 0.8903654485049833, 'class_Acc_6': 0.8020833333333334, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.15060240963855423, 'Unlab_loss(mb)': array(-6952.3374, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2601   -10297.081055   0.926606    -6952.337402  ...   0.73496  0.835885  4.857073\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  87%|███████████████████████████▉    | 437/500 [2:31:27<16:05, 15.33s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.858214315228565, 'Train_Acc': 0.9288952413557001, 'val_Acc': 0.8374558303886925, 'test_Acc': 0.731951871657754, 'class_Acc_0': 0.303921568627451, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7854545454545454, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.768313458262351, 'class_Acc_5': 0.8787375415282392, 'class_Acc_6': 0.8229166666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.1686746987951807, 'Unlab_loss(mb)': array(-6955.434, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2626   -10350.759766   0.928895    -6955.434082  ...  0.731952  0.837456  4.858214\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  88%|████████████████████████████▎   | 442/500 [2:32:44<13:40, 14.15s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.849676725874451, 'Train_Acc': 0.9293651352276618, 'val_Acc': 0.8374558303886925, 'test_Acc': 0.7292780748663101, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7999999999999999, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.75809199318569, 'class_Acc_5': 0.877076411960133, 'class_Acc_6': 0.8229166666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.18072289156626506, 'Unlab_loss(mb)': array(-6861.3486, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2653   -10320.380859   0.929365    -6861.348633  ...  0.729278  0.837456  4.849677\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  89%|████████████████████████████▌   | 446/500 [2:33:49<13:06, 14.56s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.844928559139129, 'Train_Acc': 0.930266059568641, 'val_Acc': 0.8378484491558696, 'test_Acc': 0.7282754010695187, 'class_Acc_0': 0.2647058823529412, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7927272727272726, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7555366269165247, 'class_Acc_5': 0.8853820598006644, 'class_Acc_6': 0.8159722222222222, 'class_Acc_7': nan, 'class_Acc_8': 0.23076923076923075, 'class_Acc_9': 0.18674698795180722, 'Unlab_loss(mb)': array(-6974.1934, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2679        -10348.5   0.930266    -6974.193359  ...  0.728275  0.837848  4.844929\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  90%|████████████████████████████▊   | 450/500 [2:34:56<12:32, 15.05s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.842356880088378, 'Train_Acc': 0.9307583019513865, 'val_Acc': 0.8382410679230468, 'test_Acc': 0.7306149732620321, 'class_Acc_0': 0.2647058823529412, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7909090909090909, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7563884156729132, 'class_Acc_5': 0.877076411960133, 'class_Acc_6': 0.8298611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.22289156626506026, 'Unlab_loss(mb)': array(-6989.4336, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2704   -10392.990234   0.930758    -6989.433594  ...  0.730615  0.838241  4.842357\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  91%|█████████████████████████████   | 455/500 [2:36:12<10:32, 14.06s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.843155716111996, 'Train_Acc': 0.9324552413557001, 'val_Acc': 0.8386336866902238, 'test_Acc': 0.7262700534759359, 'class_Acc_0': 0.2647058823529412, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7999999999999999, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7427597955706985, 'class_Acc_5': 0.8754152823920266, 'class_Acc_6': 0.8298611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.2692307692307692, 'class_Acc_9': 0.22289156626506026, 'Unlab_loss(mb)': array(-6871.4824, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2731   -10307.603516   0.932455    -6871.482422  ...   0.72627  0.838634  4.843156\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  92%|█████████████████████████████▍  | 459/500 [2:37:18<10:06, 14.80s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.835893399669187, 'Train_Acc': 0.9293474837384458, 'val_Acc': 0.8370632116215155, 'test_Acc': 0.7309491978609626, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7945454545454544, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7614991482112435, 'class_Acc_5': 0.8754152823920266, 'class_Acc_6': 0.8298611111111113, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.19277108433734935, 'Unlab_loss(mb)': array(-6674.464, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2756   -10166.305664   0.929347    -6674.463867  ...  0.730949  0.837063  4.835893\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  93%|█████████████████████████████▋  | 463/500 [2:38:23<09:04, 14.70s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.840678666960573, 'Train_Acc': 0.9315629989729545, 'val_Acc': 0.8390263054574009, 'test_Acc': 0.7256016042780749, 'class_Acc_0': 0.2450980392156863, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7945454545454544, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7453151618398636, 'class_Acc_5': 0.8803986710963454, 'class_Acc_6': 0.8229166666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.21084337349397592, 'Unlab_loss(mb)': array(-6992.3296, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2782   -10351.088867   0.931563     -6992.32959  ...  0.725602  0.839026  4.840679\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  94%|█████████████████████████████▉  | 468/500 [2:39:40<07:29, 14.06s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.835457820355898, 'Train_Acc': 0.9307954536117767, 'val_Acc': 0.8370632116215155, 'test_Acc': 0.7286096256684492, 'class_Acc_0': 0.25490196078431376, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7890909090909091, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7606473594548551, 'class_Acc_5': 0.8803986710963454, 'class_Acc_6': 0.8090277777777778, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.19277108433734935, 'Unlab_loss(mb)': array(-7082.9775, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2808     -10473.4375   0.930795    -7082.977539  ...   0.72861  0.837063  4.835458\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  94%|██████████████████████████████▏ | 472/500 [2:40:48<06:55, 14.84s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.835213144536788, 'Train_Acc': 0.9308321807600137, 'val_Acc': 0.8378484491558696, 'test_Acc': 0.7302807486631016, 'class_Acc_0': 0.27450980392156865, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7836363636363636, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7623509369676321, 'class_Acc_5': 0.8803986710963454, 'class_Acc_6': 0.8159722222222222, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.20481927710843376, 'Unlab_loss(mb)': array(-6889.768, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2833   -10347.969727   0.930832    -6889.768066  ...  0.730281  0.837848  4.835213\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  95%|██████████████████████████████▍ | 476/500 [2:41:52<05:50, 14.60s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.832962690553735, 'Train_Acc': 0.9303406504621704, 'val_Acc': 0.8374558303886925, 'test_Acc': 0.7299465240641712, 'class_Acc_0': 0.2647058823529412, 'class_Acc_1': 0.1090909090909091, 'class_Acc_2': 0.7909090909090909, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7589437819420783, 'class_Acc_5': 0.8803986710963454, 'class_Acc_6': 0.8229166666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.18674698795180722, 'Unlab_loss(mb)': array(-6998.3423, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2859   -10401.001953   0.930341    -6998.342285  ...  0.729947  0.837456  4.832963\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  96%|██████████████████████████████▋ | 480/500 [2:42:57<04:50, 14.52s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.8330141147422045, 'Train_Acc': 0.9321208627182472, 'val_Acc': 0.8378484491558696, 'test_Acc': 0.7286096256684492, 'class_Acc_0': 0.27450980392156865, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7927272727272726, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7512776831345827, 'class_Acc_5': 0.8820598006644518, 'class_Acc_6': 0.8229166666666666, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.20481927710843376, 'Unlab_loss(mb)': array(-7571.884, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2885   -10810.486328   0.932121    -7571.883789  ...   0.72861  0.837848  4.833014\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  97%|███████████████████████████████ | 485/500 [2:44:15<03:33, 14.21s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.833719729748369, 'Train_Acc': 0.9314923930160903, 'val_Acc': 0.8378484491558696, 'test_Acc': 0.7306149732620321, 'class_Acc_0': 0.27450980392156865, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7909090909090909, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7597955706984668, 'class_Acc_5': 0.8820598006644518, 'class_Acc_6': 0.8194444444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.19277108433734935, 'Unlab_loss(mb)': array(-6891.974, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","2911   -10344.520508   0.931492    -6891.974121  ...  0.730615  0.837848  4.83372\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  98%|███████████████████████████████▎| 489/500 [2:45:22<02:44, 14.93s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.832818045347813, 'Train_Acc': 0.9313331051009929, 'val_Acc': 0.8378484491558696, 'test_Acc': 0.7306149732620321, 'class_Acc_0': 0.27450980392156865, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7927272727272726, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7589437819420783, 'class_Acc_5': 0.8803986710963454, 'class_Acc_6': 0.8194444444444444, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.19879518072289157, 'Unlab_loss(mb)': array(-6680.6484, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2936   -10209.775391   0.931333    -6680.648438  ...  0.730615  0.837848  4.832818\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  99%|███████████████████████████████▌| 493/500 [2:46:27<01:43, 14.77s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.832389040816611, 'Train_Acc': 0.9314192262923656, 'val_Acc': 0.8374558303886925, 'test_Acc': 0.7309491978609626, 'class_Acc_0': 0.27450980392156865, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7909090909090909, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7623509369676321, 'class_Acc_5': 0.8803986710963454, 'class_Acc_6': 0.8159722222222222, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.19277108433734935, 'Unlab_loss(mb)': array(-7008.191, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2962   -10407.821289   0.931419    -7008.190918  ...  0.730949  0.837456  4.832389\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  99%|███████████████████████████████▊| 497/500 [2:47:32<00:44, 14.67s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.831944538584775, 'Train_Acc': 0.9308552413557001, 'val_Acc': 0.8362779740871613, 'test_Acc': 0.7302807486631016, 'class_Acc_0': 0.27450980392156865, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7909090909090909, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.7614991482112435, 'class_Acc_5': 0.8803986710963454, 'class_Acc_6': 0.8125, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.19277108433734935, 'Unlab_loss(mb)': array(-7573.693, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2987   -10834.917969   0.930855    -7573.692871  ...  0.730281  0.836278  4.831945\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train: 100%|████████████████████████████████| 500/500 [2:48:15<00:00, 20.19s/it]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 4.832658606882194, 'Train_Acc': 0.9308498322492297, 'val_Acc': 0.8374558303886925, 'test_Acc': 0.7289438502673797, 'class_Acc_0': 0.27450980392156865, 'class_Acc_1': 0.09090909090909088, 'class_Acc_2': 0.7909090909090909, 'class_Acc_3': 0.6551724137931034, 'class_Acc_4': 0.75809199318569, 'class_Acc_5': 0.8803986710963454, 'class_Acc_6': 0.8125, 'class_Acc_7': nan, 'class_Acc_8': 0.30769230769230765, 'class_Acc_9': 0.19277108433734935}\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2999             NaN    0.93085             NaN  ...  0.728944  0.837456  4.832659\n","\n","[1 rows x 17 columns]\n"]}],"source":["!python3 experiments/train_flows/flowgmm_tabular_new.py --num_classes 10 --metric_name \"10x Chromium (v2) A\" --trainer_config \"{'unlab_weight':.6}\" --net_config \"{'k':1024,'coupling_layers':7,'nperlayer':1}\" --network RealNVPTabularWPrior --trainer SemiFlow --num_epochs 500 --dataset AG_News --lr 3e-4 --train 200"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["with open(\"/home/anunay18021/SingleCellClassification/tmp/metrics_\" + batch_name + \".pkl\", \"rb\") as f:\n","  D = pickle.load(f)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["rev = list(mapping.keys())\n","new_D = {}\n","for i in D:\n","  try:\n","    new_D[reverse_mapping[int(i.split(\"_\")[-1])]] = D[i]\n","  except:\n","    continue"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["plt.rcParams[\"figure.figsize\"] = (20,5.5)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 2000x550 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.bar(range(len(new_D)), list(new_D.values()))\n","plt.xticks(range(len(new_D)), list(new_D.keys()))\n","plt.show()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["classes_labeled = {}\n","for i in D:\n","  try:\n","        classes_labeled[reverse_mapping[int(i.split(\"_\")[-1])]] = D[i]\n","  except:\n","        classes_labeled[i] = D[i]"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["df = pd.DataFrame(columns = list(classes_labeled.keys()))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_339718/3840281218.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df.append(classes_labeled, ignore_index = True)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>val_bpd</th>\n","      <th>Train_Acc</th>\n","      <th>val_Acc</th>\n","      <th>test_Acc</th>\n","      <th>CD16+ monocyte</th>\n","      <th>Dendritic cell</th>\n","      <th>CD4+ T cell</th>\n","      <th>Megakaryocyte</th>\n","      <th>Cytotoxic T cell</th>\n","      <th>CD14+ monocyte</th>\n","      <th>B cell</th>\n","      <th>Unassigned</th>\n","      <th>Plasmacytoid dendritic cell</th>\n","      <th>Natural killer cell</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4.832659</td>\n","      <td>0.93085</td>\n","      <td>0.837456</td>\n","      <td>0.728944</td>\n","      <td>0.27451</td>\n","      <td>0.090909</td>\n","      <td>0.790909</td>\n","      <td>0.655172</td>\n","      <td>0.758092</td>\n","      <td>0.880399</td>\n","      <td>0.8125</td>\n","      <td>NaN</td>\n","      <td>0.307692</td>\n","      <td>0.192771</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    val_bpd  Train_Acc   val_Acc  test_Acc  CD16+ monocyte  Dendritic cell  \\\n","0  4.832659    0.93085  0.837456  0.728944         0.27451        0.090909   \n","\n","   CD4+ T cell  Megakaryocyte  Cytotoxic T cell  CD14+ monocyte  B cell  \\\n","0     0.790909       0.655172          0.758092        0.880399  0.8125   \n","\n","   Unassigned  Plasmacytoid dendritic cell  Natural killer cell  \n","0         NaN                     0.307692             0.192771  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df.append(classes_labeled, ignore_index = True)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1fTsVaFW9rVur8hpaEbz5dsxiGXSEy9Sk","timestamp":1679851239019}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
