{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"gAHHs5T1xpkh"},"source":["# Feed Forward Neural Network "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nRJ9MX8tDYBO"},"source":["You need to have these three files to run all the cells in this notebook\n","1. ITClust train dataset\n","2. ITClust test dataset\n","3. FlowGMM codebase zip "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"p-_nnfyDDDxq"},"outputs":[],"source":["all_batches_file = '/home/anunay18021/SingleCellClassification/dataset/adata_pbmc_batches_raw.h5ad'"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n","/home/anunay18021/.venv/lib/python3.8/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n","/home/anunay18021/.venv/lib/python3.8/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n","/home/anunay18021/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.14.0 pynndescent==0.5.10\n"]},{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n","  @numba.jit()\n"]}],"source":["# Call Libraries\n","import torch\n","from torch import nn\n","from torch.nn.parameter import Parameter\n","from torch import distributions\n","import sys\n","sys.path.insert(0, '')\n","from scripts.utils import *\n","import numpy as np\n","torch.manual_seed(0)\n","np.random.seed(0)\n","import scanpy as sc\n","sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n","sc.logging.print_header()\n","import os\n","from numpy.random import seed\n","# from tensorflow import set_random_seed\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","import pickle\n","import sys\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from pylab import rcParams\n","rcParams['figure.dpi'] = 100\n","\n","# from flow_ssl.realnvp.realnvp_toy import ToyRealNVP\n","from flow_ssl.realnvp.realnvp import RealNVPTabular\n","from flow_ssl.data import make_circles_ssl, make_moons_ssl, make_dataset_from_img, make_dataset_from_npz\n","from flow_ssl.distributions import SSLGaussMixture\n","from flow_ssl import FlowLoss\n","\n","from itertools import chain\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/anndata/_core/anndata.py:117: ImplicitModificationWarning: Transforming to str index.\n","  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/anndata/_core/anndata.py:1832: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n","  utils.warn_names_duplicates(\"var\")\n"]}],"source":["adata = sc.read(all_batches_file)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","____Create unique index____ \n","normalizing counts per cell\n","    finished (0:00:02)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 500x550 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["____Filtering the data____\n","pre filtering: (30495, 33694)\n","filtered out 2035 cells that have less than 200 genes expressed\n","filtered out 9096 genes that are detected in less than 3 cells\n","post filtering: (28460, 24598)\n","____Log normalizing____\n","normalizing counts per cell\n","    finished (0:00:01)\n","____Selecting highly variable genes____\n","pre: (28460, 24598)\n","If you pass `n_top_genes`, all cutoffs are ignored.\n","extracting highly variable genes\n","    finished (0:00:03)\n","--> added\n","    'highly_variable', boolean vector (adata.var)\n","    'means', float vector (adata.var)\n","    'dispersions', float vector (adata.var)\n","    'dispersions_norm', float vector (adata.var)\n","pre: (28460, 24598)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1280x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["post: (28460, 3000)\n","____Scaling the data____\n"]},{"name":"stderr","output_type":"stream","text":["/home/anunay18021/.venv/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py:843: UserWarning: Received a view of an AnnData. Making a copy.\n","  view_to_actual(adata)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>gene_symbols</th>\n","      <th>SCYL3</th>\n","      <th>FUCA2</th>\n","      <th>TMEM176A</th>\n","      <th>HSPB6</th>\n","      <th>PDK4</th>\n","      <th>SLC22A16</th>\n","      <th>ARX</th>\n","      <th>SLC25A13</th>\n","      <th>SLC4A1</th>\n","      <th>THSD7A</th>\n","      <th>...</th>\n","      <th>CH17-262H11.1</th>\n","      <th>TRBJ1-5</th>\n","      <th>RP11-328P23.4</th>\n","      <th>CH17-212P11.4</th>\n","      <th>CH17-224D4.1</th>\n","      <th>RP11-596C23.6</th>\n","      <th>CTC-490G23.6</th>\n","      <th>PRNCR1</th>\n","      <th>RP1-273N12.4</th>\n","      <th>TRBV6-2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_ACAGAC</th>\n","      <td>-0.210501</td>\n","      <td>2.240501</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>2.772827</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_ACAGGA</th>\n","      <td>1.656750</td>\n","      <td>2.347928</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_ACGTTG</th>\n","      <td>-0.210501</td>\n","      <td>-0.162299</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_AGACCA</th>\n","      <td>-0.210501</td>\n","      <td>-0.162299</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","    <tr>\n","      <th>pbmc1_Celseq2_1_CAACTC</th>\n","      <td>-0.210501</td>\n","      <td>-0.162299</td>\n","      <td>-0.133715</td>\n","      <td>-0.017045</td>\n","      <td>-0.092075</td>\n","      <td>-0.022733</td>\n","      <td>-0.017383</td>\n","      <td>-0.148193</td>\n","      <td>-0.130104</td>\n","      <td>-0.018138</td>\n","      <td>...</td>\n","      <td>-0.016476</td>\n","      <td>-0.037941</td>\n","      <td>-0.019149</td>\n","      <td>-0.009174</td>\n","      <td>-0.018344</td>\n","      <td>-0.035799</td>\n","      <td>-0.009078</td>\n","      <td>-0.125148</td>\n","      <td>-0.020136</td>\n","      <td>-0.046757</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 3000 columns</p>\n","</div>"],"text/plain":["gene_symbols               SCYL3     FUCA2  TMEM176A     HSPB6      PDK4  \\\n","pbmc1_Celseq2_1_ACAGAC -0.210501  2.240501 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_ACAGGA  1.656750  2.347928 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_ACGTTG -0.210501 -0.162299 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_AGACCA -0.210501 -0.162299 -0.133715 -0.017045 -0.092075   \n","pbmc1_Celseq2_1_CAACTC -0.210501 -0.162299 -0.133715 -0.017045 -0.092075   \n","\n","gene_symbols            SLC22A16       ARX  SLC25A13    SLC4A1    THSD7A  ...  \\\n","pbmc1_Celseq2_1_ACAGAC -0.022733 -0.017383 -0.148193  2.772827 -0.018138  ...   \n","pbmc1_Celseq2_1_ACAGGA -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","pbmc1_Celseq2_1_ACGTTG -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","pbmc1_Celseq2_1_AGACCA -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","pbmc1_Celseq2_1_CAACTC -0.022733 -0.017383 -0.148193 -0.130104 -0.018138  ...   \n","\n","gene_symbols            CH17-262H11.1   TRBJ1-5  RP11-328P23.4  CH17-212P11.4  \\\n","pbmc1_Celseq2_1_ACAGAC      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_ACAGGA      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_ACGTTG      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_AGACCA      -0.016476 -0.037941      -0.019149      -0.009174   \n","pbmc1_Celseq2_1_CAACTC      -0.016476 -0.037941      -0.019149      -0.009174   \n","\n","gene_symbols            CH17-224D4.1  RP11-596C23.6  CTC-490G23.6    PRNCR1  \\\n","pbmc1_Celseq2_1_ACAGAC     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_ACAGGA     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_ACGTTG     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_AGACCA     -0.018344      -0.035799     -0.009078 -0.125148   \n","pbmc1_Celseq2_1_CAACTC     -0.018344      -0.035799     -0.009078 -0.125148   \n","\n","gene_symbols            RP1-273N12.4   TRBV6-2  \n","pbmc1_Celseq2_1_ACAGAC     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_ACAGGA     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_ACGTTG     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_AGACCA     -0.020136 -0.046757  \n","pbmc1_Celseq2_1_CAACTC     -0.020136 -0.046757  \n","\n","[5 rows x 3000 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["\n","print(\"\\n____Create unique index____ \")\n","adata.var_names_make_unique()\n","sc.pl.highest_expr_genes(adata, n_top=20, )\n","        \n","print(\"____Filtering the data____\")\n","print(\"pre filtering:\",adata.shape)\n","sc.pp.filter_cells(adata, min_genes=200)\n","sc.pp.filter_genes(adata, min_cells=3)\n","print(\"post filtering:\",adata.shape)\n","\n","print(\"____Log normalizing____\")\n","sc.pp.normalize_total(adata, target_sum=1e4)\n","sc.pp.log1p(adata)\n","\n","print(\"____Selecting highly variable genes____\")\n","print(\"pre:\",adata.shape)\n","sc.pp.highly_variable_genes(adata, min_mean=0.001 , max_mean=3, min_disp=0.3, n_top_genes=3000)\n","print(\"pre:\",adata.shape)\n","adata.raw = adata\n","adata = adata[:, adata.var.highly_variable]\n","\n","sc.pl.highly_variable_genes(adata)\n","print(\"post:\",adata.shape)\n","\n","print(\"____Scaling the data____\")\n","sc.pp.scale(adata, max_value=10)\n","adata.to_df().head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["all_batches = list(set(adata.obs.Method.values))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["['Drop-seq',\n"," '10x Chromium (v3)',\n"," '10x Chromium (v2) B',\n"," 'Seq-Well',\n"," 'inDrops',\n"," '10x Chromium (v2)',\n"," '10x Chromium (v2) A',\n"," 'CEL-Seq2']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["all_batches"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["batch_name = 'inDrops'"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["mapping = {}\n","reverse_mapping = {}\n","cnt = 0\n","for i in set(adata.obs.CellType.values):\n","    mapping[i] = cnt\n","    reverse_mapping[cnt] = i\n","    cnt += 1"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["total_classes = len(set(adata.obs.CellType.values))"]},{"cell_type":"markdown","metadata":{},"source":["# One vs all for batch '10x Chromium (v2) B'"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["train_df = adata[adata.obs['Method'] != batch_name].to_df()\n","test_df = adata[adata.obs['Method'] == batch_name].to_df()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Taking common genes...\n","Common columns 3000\n"]}],"source":["print(\"Taking common genes...\")\n","final_columns = list(set(train_df.columns).intersection(set(test_df.columns)))\n","print('Common columns', len(final_columns))\n","final_columns = [i for i in final_columns if i != 'CellType'] \n","train_df = train_df[final_columns]\n","test_df = test_df[final_columns]\n","\n","y_train = adata[adata.obs['Method'] != batch_name].obs.CellType.to_list()\n","y_test = adata[adata.obs['Method'] == batch_name].obs.CellType.to_list()\n","\n","X_train = train_df.to_numpy()\n","X_test = test_df.to_numpy()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["y_test_lab = convert_y_to_mapping(y_test, mapping)\n","y_test_lab = np.array(y_test_lab)\n","\n","y_train_lab = convert_y_to_mapping(y_train, mapping)\n","y_train_lab = np.array(y_train_lab)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["with open('/home/anunay18021/SingleCellClassification/dataset/np/X_train_'+batch_name+'.pkl', 'wb') as fh:\n","        pickle.dump(X_train, fh)\n","\n","with open('/home/anunay18021/SingleCellClassification/dataset/np/X_test_'+batch_name+'.pkl', 'wb') as fh:\n","    pickle.dump(X_test, fh)\n","\n","with open('/home/anunay18021/SingleCellClassification/dataset/np/y_test_'+batch_name+'.pkl', 'wb') as fh:\n","    pickle.dump(y_test_lab, fh)\n","\n","with open('/home/anunay18021/SingleCellClassification/dataset/np/y_train_'+batch_name+'.pkl', 'wb') as fh:\n","    pickle.dump(y_train_lab, fh)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["22729"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["len(y_train_lab)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/anunay18021/SingleCellClassification/flowgmm\n"]}],"source":["%cd flowgmm"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n0Zfu1blzejB","outputId":"ecf9742d-4067-4ad6-e529-2bcf3bf0669b"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'num_classes': 10, 'metric_name': 'inDrops', 'dataset': <class 'flow_ssl.data.nlp_datasets.AG_News'>, 'network': <function RealNVPTabularWPrior at 0x7f4c1baaddc0>, 'num_epochs': 500, 'bs': 5000, 'lr': 0.0003, 'optim': <class 'torch.optim.adamw.AdamW'>, 'device': 'cuda', 'trainer': SemiFlow, 'split': {'train': 200, 'val': 5000}, 'net_config': {'k': 1024, 'coupling_layers': 7, 'nperlayer': 1}, 'opt_config': {'weight_decay': 1e-05}, 'trainer_config': {'log_dir': '/home/anunay18021/tb-experiments/UCI/', 'log_args': {'minPeriod': 0.1, 'timeFrac': 0.3}, 'unlab_weight': 0.6}, 'save': False}\n","inDrops\n","22729\n","22729\n","5731\n","Pairwise dists: [[ 0.         42.75355404 44.19298419 43.09285739 42.44615966 43.89102835\n","  43.18336294 43.45309643 42.41743406 43.0158847 ]\n"," [42.75355404  0.         43.12438656 43.26143816 43.78624654 43.32600374\n","  42.74876848 42.6403646  43.61332962 42.72157795]\n"," [44.19298419 43.12438656  0.         43.81121177 43.38538648 43.29929902\n","  42.68124373 43.75741537 43.02623242 43.51485872]\n"," [43.09285739 43.26143816 43.81121177  0.         43.84365394 43.88477283\n","  43.59597867 43.44700313 43.26558573 43.47797003]\n"," [42.44615966 43.78624654 43.38538648 43.84365394  0.         43.46506875\n","  42.57797117 43.43762387 43.09443056 43.72664648]\n"," [43.89102835 43.32600374 43.29929902 43.88477283 43.46506875  0.\n","  43.14136114 42.73032535 43.07570968 43.6777864 ]\n"," [43.18336294 42.74876848 42.68124373 43.59597867 42.57797117 43.14136114\n","   0.         42.99326513 43.15198033 43.19100747]\n"," [43.45309643 42.6403646  43.75741537 43.44700313 43.43762387 42.73032535\n","  42.99326513  0.         43.24372149 43.18132444]\n"," [42.41743406 43.61332962 43.02623242 43.26558573 43.09443056 43.07570968\n","  43.15198033 43.24372149  0.         42.98292261]\n"," [43.0158847  42.72157795 43.51485872 43.47797003 43.72664648 43.6777864\n","  43.19100747 43.18132444 42.98292261  0.        ]]\n","10 inDrops\n","train:   0%|                                            | 0/500 [00:00<?, ?it/s]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 10.009211843889396, 'Train_Acc': 0.09738526315789474, 'val_Acc': 0.09898812142542895, 'test_Acc': 0.08643980848153214, 'class_Acc_0': 0.31008184523809523, 'class_Acc_1': nan, 'class_Acc_2': 0.004032258064516129, 'class_Acc_3': 0.020669291338582675, 'class_Acc_4': 0.2528169014084507, 'class_Acc_5': 0.017321804754959834, 'class_Acc_6': 0.05599999999999999, 'class_Acc_7': 0.0, 'class_Acc_8': 0.19409081484553184, 'class_Acc_9': 0.225, 'Unlab_loss(mb)': array(4090.1018, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","   Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc    val_bpd\n","0     6662.768066   0.097385     4090.101807  ...   0.08644  0.098988  10.009212\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   1%|▍                                 | 7/500 [02:09<2:06:57, 15.45s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 8.528010124120378, 'Train_Acc': 0.5675052631578947, 'val_Acc': 0.5618125824901012, 'test_Acc': 0.5649942544459644, 'class_Acc_0': 0.8982514880952381, 'class_Acc_1': nan, 'class_Acc_2': 0.0, 'class_Acc_3': 0.0265748031496063, 'class_Acc_4': 0.0, 'class_Acc_5': 0.789531101696877, 'class_Acc_6': 0.0, 'class_Acc_7': 0.0, 'class_Acc_8': 0.8819199668256271, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(753.97437, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","36     1759.050415   0.567505      753.974365  ...  0.564994  0.561813  8.52801\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   3%|▉                                | 14/500 [04:15<2:01:47, 15.04s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 8.06836484097205, 'Train_Acc': 0.6155915789473684, 'val_Acc': 0.6154861416630004, 'test_Acc': 0.6078740082079342, 'class_Acc_0': 0.9737723214285714, 'class_Acc_1': nan, 'class_Acc_2': 0.0, 'class_Acc_3': 0.011811023622047244, 'class_Acc_4': 0.00352112676056338, 'class_Acc_5': 0.9297115540431048, 'class_Acc_6': 0.0, 'class_Acc_7': 0.0, 'class_Acc_8': 0.9981132075471698, 'class_Acc_9': 0.0, 'Unlab_loss(mb)': array(-220.03644, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","    Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","71      328.398132   0.615592     -220.036438  ...  0.607874  0.615486  8.068365\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   4%|█▍                               | 21/500 [06:21<2:01:22, 15.20s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.747795732532084, 'Train_Acc': 0.7290442105263157, 'val_Acc': 0.7078750549934008, 'test_Acc': 0.6462979480164158, 'class_Acc_0': 0.8798363095238095, 'class_Acc_1': nan, 'class_Acc_2': 0.0, 'class_Acc_3': 0.20928113152522607, 'class_Acc_4': 0.00352112676056338, 'class_Acc_5': 0.9400768571891567, 'class_Acc_6': 0.0, 'class_Acc_7': 0.0, 'class_Acc_8': 0.9962264150943396, 'class_Acc_9': 0.16666666666666666, 'Unlab_loss(mb)': array(-1267.7805, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","105     -793.086914   0.729044    -1267.780518  ...  0.646298  0.707875  7.747796\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   5%|█▊                               | 27/500 [08:14<2:04:06, 15.74s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.499506336873322, 'Train_Acc': 0.8023333333333332, 'val_Acc': 0.7769467663880334, 'test_Acc': 0.6615180574555403, 'class_Acc_0': 0.8831845238095237, 'class_Acc_1': nan, 'class_Acc_2': 0.0, 'class_Acc_3': 0.5868875765529309, 'class_Acc_4': 0.00352112676056338, 'class_Acc_5': 0.8164455864990625, 'class_Acc_6': 0.0, 'class_Acc_7': 0.0, 'class_Acc_8': 0.993800539083558, 'class_Acc_9': 0.8083333333333333, 'Unlab_loss(mb)': array(-1090.4218, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","138    -1247.188721   0.802333    -1090.421753  ...  0.661518  0.776947  7.499506\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   7%|██▏                              | 34/500 [10:20<1:58:10, 15.22s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.283531848415531, 'Train_Acc': 0.8197150877192984, 'val_Acc': 0.7910250769907611, 'test_Acc': 0.6526941176470589, 'class_Acc_0': 0.8781622023809523, 'class_Acc_1': nan, 'class_Acc_2': 0.0, 'class_Acc_3': 0.68082895888014, 'class_Acc_4': 0.00352112676056338, 'class_Acc_5': 0.7628944139639326, 'class_Acc_6': 0.004, 'class_Acc_7': 0.0, 'class_Acc_8': 0.9491395397055774, 'class_Acc_9': 0.8708333333333332, 'Unlab_loss(mb)': array(-1885.984, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","171    -2208.637207   0.819715    -1885.984009  ...  0.652694  0.791025  7.283532\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   8%|██▋                              | 40/500 [12:12<2:00:30, 15.72s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 7.088983870339586, 'Train_Acc': 0.8263908771929824, 'val_Acc': 0.7941047074351077, 'test_Acc': 0.6683740082079342, 'class_Acc_0': 0.8703497023809523, 'class_Acc_1': nan, 'class_Acc_2': 0.008064516129032258, 'class_Acc_3': 0.6228127734033245, 'class_Acc_4': 0.00352112676056338, 'class_Acc_5': 0.8365916614579715, 'class_Acc_6': 0.004, 'class_Acc_7': 0.0, 'class_Acc_8': 0.8996267883060336, 'class_Acc_9': 0.85, 'Unlab_loss(mb)': array(-1946.648, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","203    -2537.470215   0.826391    -1946.647949  ...  0.668374  0.794105  7.088984\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:   9%|███                              | 47/500 [14:20<1:55:15, 15.27s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.950074339940606, 'Train_Acc': 0.8323080701754386, 'val_Acc': 0.8011438627364716, 'test_Acc': 0.6575500683994528, 'class_Acc_0': 0.8552827380952381, 'class_Acc_1': nan, 'class_Acc_2': 0.008064516129032258, 'class_Acc_3': 0.6921478565179352, 'class_Acc_4': 0.00352112676056338, 'class_Acc_5': 0.7897987707479686, 'class_Acc_6': 0.004, 'class_Acc_7': 0.0, 'class_Acc_8': 0.9055567074434999, 'class_Acc_9': 0.8125, 'Unlab_loss(mb)': array(-2566.229, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","236    -3202.408203   0.832308    -2566.229004  ...   0.65755  0.801144  6.950074\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  11%|███▍                             | 53/500 [16:11<1:55:07, 15.45s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.814101271591406, 'Train_Acc': 0.8380638596491228, 'val_Acc': 0.7976242850857898, 'test_Acc': 0.6641740082079343, 'class_Acc_0': 0.8692336309523809, 'class_Acc_1': nan, 'class_Acc_2': 0.03723481546062191, 'class_Acc_3': 0.6144466316710411, 'class_Acc_4': 0.01056338028169014, 'class_Acc_5': 0.8109258166076349, 'class_Acc_6': 0.004, 'class_Acc_7': 0.0, 'class_Acc_8': 0.9042089985486211, 'class_Acc_9': 0.75, 'Unlab_loss(mb)': array(-2790.1206, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","269     -3556.38623   0.838064    -2790.120605  ...  0.664174  0.797624  6.814101\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  12%|███▉                             | 60/500 [18:17<1:51:52, 15.25s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.710200577298582, 'Train_Acc': 0.8475284210526316, 'val_Acc': 0.8015838099428069, 'test_Acc': 0.6695299589603283, 'class_Acc_0': 0.7803199404761905, 'class_Acc_1': nan, 'class_Acc_2': 0.09604766056378959, 'class_Acc_3': 0.643791921843103, 'class_Acc_4': 0.02112676056338028, 'class_Acc_5': 0.8021954649628447, 'class_Acc_6': 0.004, 'class_Acc_7': 0.0, 'class_Acc_8': 0.9012440389798881, 'class_Acc_9': 0.7083333333333334, 'Unlab_loss(mb)': array(-2816.3496, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","302    -3842.840332   0.847528    -2816.349609  ...   0.66953  0.801584  6.710201\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  13%|████▍                            | 67/500 [20:23<1:50:02, 15.25s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.629975203675137, 'Train_Acc': 0.8515754385964913, 'val_Acc': 0.7971843378794544, 'test_Acc': 0.6760418604651163, 'class_Acc_0': 0.6685267857142857, 'class_Acc_1': nan, 'class_Acc_2': 0.17193403080499856, 'class_Acc_3': 0.6364100320793235, 'class_Acc_4': 0.11408450704225352, 'class_Acc_5': 0.8303484616987291, 'class_Acc_6': 0.004, 'class_Acc_7': 0.03225806451612903, 'class_Acc_8': 0.8546962471490773, 'class_Acc_9': 0.7083333333333334, 'Unlab_loss(mb)': array(-3417.3684, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","335    -4463.293945   0.851575    -3417.368408  ...  0.676042  0.797184  6.629975\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  15%|████▊                            | 73/500 [22:14<1:51:24, 15.65s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.544146589424543, 'Train_Acc': 0.8616912280701754, 'val_Acc': 0.8051033875934888, 'test_Acc': 0.6971456908344733, 'class_Acc_0': 0.7658110119047619, 'class_Acc_1': nan, 'class_Acc_2': 0.34434030804998544, 'class_Acc_3': 0.6603419364246136, 'class_Acc_4': 0.1316901408450704, 'class_Acc_5': 0.8162372386971317, 'class_Acc_6': 0.004, 'class_Acc_7': 0.03225806451612903, 'class_Acc_8': 0.8845324486833921, 'class_Acc_9': 0.6916666666666667, 'Unlab_loss(mb)': array(-3183.5703, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","367     -4430.92334   0.861691    -3183.570312  ...  0.697146  0.805103  6.544147\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  16%|█████▏                           | 79/500 [24:09<1:52:02, 15.97s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.467749734891948, 'Train_Acc': 0.8666498245614035, 'val_Acc': 0.8103827540695117, 'test_Acc': 0.7097575923392613, 'class_Acc_0': 0.9587053571428571, 'class_Acc_1': nan, 'class_Acc_2': 0.43232345248474274, 'class_Acc_3': 0.6036198600174978, 'class_Acc_4': 0.16690140845070423, 'class_Acc_5': 0.8081015464036855, 'class_Acc_6': 0.008, 'class_Acc_7': 0.016129032258064516, 'class_Acc_8': 0.8439145759900477, 'class_Acc_9': 0.7083333333333334, 'Unlab_loss(mb)': array(-3521.2644, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","399      -4743.0625    0.86665    -3521.264404  ...  0.709758  0.810383  6.46775\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  17%|█████▋                           | 86/500 [26:13<1:44:08, 15.09s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.382435832153337, 'Train_Acc': 0.8794315789473685, 'val_Acc': 0.8156621205455346, 'test_Acc': 0.7055376196990424, 'class_Acc_0': 0.7752976190476191, 'class_Acc_1': nan, 'class_Acc_2': 0.4953865155478059, 'class_Acc_3': 0.7405037911927675, 'class_Acc_4': 0.302112676056338, 'class_Acc_5': 0.7371591198462857, 'class_Acc_6': 0.004, 'class_Acc_7': 0.04838709677419355, 'class_Acc_8': 0.8436450342110721, 'class_Acc_9': 0.7125, 'Unlab_loss(mb)': array(-3508.123, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","432    -4998.748047   0.879432    -3508.123047  ...  0.705538  0.815662  6.382436\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  18%|██████                           | 92/500 [28:06<1:47:21, 15.79s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.32053813322577, 'Train_Acc': 0.8809228070175438, 'val_Acc': 0.8156621205455346, 'test_Acc': 0.7223254445964432, 'class_Acc_0': 0.8619791666666667, 'class_Acc_1': nan, 'class_Acc_2': 0.5748328974135426, 'class_Acc_3': 0.6934419655876348, 'class_Acc_4': 0.35140845070422533, 'class_Acc_5': 0.758355614973262, 'class_Acc_6': 0.008, 'class_Acc_7': 0.06451612903225806, 'class_Acc_8': 0.7979058677171884, 'class_Acc_9': 0.6541666666666666, 'Unlab_loss(mb)': array(-3839.6365, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","464    -5334.883301   0.880923    -3839.636475  ...  0.722325  0.815662  6.320538\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  20%|██████▌                          | 99/500 [30:13<1:43:02, 15.42s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.248959419894997, 'Train_Acc': 0.8879859649122807, 'val_Acc': 0.8227012758468983, 'test_Acc': 0.7242653898768809, 'class_Acc_0': 0.8446800595238095, 'class_Acc_1': nan, 'class_Acc_2': 0.6156277244986923, 'class_Acc_3': 0.7491797900262467, 'class_Acc_4': 0.23732394366197185, 'class_Acc_5': 0.7506062342292289, 'class_Acc_6': 0.011999999999999999, 'class_Acc_7': 0.13064516129032258, 'class_Acc_8': 0.7879328218950861, 'class_Acc_9': 0.6375, 'Unlab_loss(mb)': array(-3965.6382, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","496    -5584.134766   0.887986    -3965.638184  ...  0.724265  0.822701  6.248959\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  21%|██████▋                         | 105/500 [32:04<1:42:29, 15.57s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.20675331072597, 'Train_Acc': 0.8930133333333333, 'val_Acc': 0.8213814342278927, 'test_Acc': 0.7340932968536252, 'class_Acc_0': 0.8614211309523809, 'class_Acc_1': nan, 'class_Acc_2': 0.6457425167102587, 'class_Acc_3': 0.6586832895888014, 'class_Acc_4': 0.3619718309859155, 'class_Acc_5': 0.8040286362478876, 'class_Acc_6': 0.011999999999999999, 'class_Acc_7': 0.04838709677419355, 'class_Acc_8': 0.6601492846775866, 'class_Acc_9': 0.6583333333333334, 'Unlab_loss(mb)': array(-3849.5415, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","528    -5568.928711   0.893013    -3849.541504  ...  0.734093  0.821381  6.206753\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  22%|███████▏                        | 112/500 [34:12<1:39:30, 15.39s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.223579469562641, 'Train_Acc': 0.8991459649122806, 'val_Acc': 0.8284205895292565, 'test_Acc': 0.734113269493844, 'class_Acc_0': 0.7591145833333334, 'class_Acc_1': nan, 'class_Acc_2': 0.668265039232781, 'class_Acc_3': 0.7050707203266258, 'class_Acc_4': 0.42535211267605627, 'class_Acc_5': 0.770435446906035, 'class_Acc_6': 0.008, 'class_Acc_7': 0.0967741935483871, 'class_Acc_8': 0.6214182044370724, 'class_Acc_9': 0.6583333333333334, 'Unlab_loss(mb)': array(-4239.359, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","560    -5754.864258   0.899146    -4239.358887  ...  0.734113  0.828421  6.223579\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  24%|███████▌                        | 118/500 [36:04<1:41:05, 15.88s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.117775728075987, 'Train_Acc': 0.8906287719298246, 'val_Acc': 0.8191816981962164, 'test_Acc': 0.7283893296853625, 'class_Acc_0': 0.6847098214285714, 'class_Acc_1': nan, 'class_Acc_2': 0.6070909619296715, 'class_Acc_3': 0.6196777486147564, 'class_Acc_4': 0.22676056338028167, 'class_Acc_5': 0.8241052619394866, 'class_Acc_6': 0.011999999999999999, 'class_Acc_7': 0.08064516129032258, 'class_Acc_8': 0.7365332780427121, 'class_Acc_9': 0.65, 'Unlab_loss(mb)': array(-4116.903, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","592    -5835.537109   0.890629    -4116.902832  ...  0.728389  0.819182  6.117776\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  25%|███████▉                        | 124/500 [37:56<1:39:22, 15.86s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 6.06900798638375, 'Train_Acc': 0.8981017543859648, 'val_Acc': 0.8249010118785746, 'test_Acc': 0.7207693570451437, 'class_Acc_0': 0.6847098214285714, 'class_Acc_1': nan, 'class_Acc_2': 0.637205754141238, 'class_Acc_3': 0.6549285505978419, 'class_Acc_4': 0.2971830985915493, 'class_Acc_5': 0.7602582355256152, 'class_Acc_6': 0.008, 'class_Acc_7': 0.04838709677419355, 'class_Acc_8': 0.6536802819821688, 'class_Acc_9': 0.6333333333333333, 'Unlab_loss(mb)': array(-4377.2993, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","624    -6183.084961   0.898102    -4377.299316  ...  0.720769  0.824901  6.069008\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  26%|████████▍                       | 131/500 [40:02<1:33:39, 15.23s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.997074821854374, 'Train_Acc': 0.9135305263157895, 'val_Acc': 0.8336999560052794, 'test_Acc': 0.6965054719562244, 'class_Acc_0': 0.7552083333333333, 'class_Acc_1': nan, 'class_Acc_2': 0.6488302818947981, 'class_Acc_3': 0.7249380285797609, 'class_Acc_4': 0.4746478873239437, 'class_Acc_5': 0.6273815311248465, 'class_Acc_6': 0.011999999999999999, 'class_Acc_7': 0.1467741935483871, 'class_Acc_8': 0.6458635703918724, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-4357.3013, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","657    -6327.553223   0.913531     -4357.30127  ...  0.696505   0.8337  5.997075\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  27%|████████▊                       | 137/500 [41:53<1:34:27, 15.61s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.959069059184601, 'Train_Acc': 0.9148063157894737, 'val_Acc': 0.8354597448306204, 'test_Acc': 0.7224612859097127, 'class_Acc_0': 0.7557663690476191, 'class_Acc_1': nan, 'class_Acc_2': 0.6277244986922406, 'class_Acc_3': 0.7047608632254302, 'class_Acc_4': 0.46056338028169014, 'class_Acc_5': 0.728825207769058, 'class_Acc_6': 0.008, 'class_Acc_7': 0.13064516129032258, 'class_Acc_8': 0.6418204437072361, 'class_Acc_9': 0.6333333333333333, 'Unlab_loss(mb)': array(-4613.0234, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","689     -6547.77832   0.914806    -4613.023438  ...  0.722461  0.83546  5.959069\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  29%|█████████▏                      | 144/500 [43:59<1:29:24, 15.07s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.918277937046238, 'Train_Acc': 0.9135845614035087, 'val_Acc': 0.8394192696876375, 'test_Acc': 0.7213652530779754, 'class_Acc_0': 0.7708333333333333, 'class_Acc_1': nan, 'class_Acc_2': 0.6659038070328394, 'class_Acc_3': 0.6768919510061243, 'class_Acc_4': 0.5028169014084507, 'class_Acc_5': 0.7000182304326689, 'class_Acc_6': 0.011999999999999999, 'class_Acc_7': 0.1467741935483871, 'class_Acc_8': 0.6318473978851337, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-4639.92, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","721      -6643.5625   0.913585    -4639.919922  ...  0.721365  0.839419  5.918278\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  30%|█████████▌                      | 150/500 [45:52<1:31:31, 15.69s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.8852234549155575, 'Train_Acc': 0.9215235087719298, 'val_Acc': 0.8372195336559612, 'test_Acc': 0.6874854993160056, 'class_Acc_0': 0.8430059523809523, 'class_Acc_1': nan, 'class_Acc_2': 0.5549258936355711, 'class_Acc_3': 0.7269065325167686, 'class_Acc_4': 0.5098591549295773, 'class_Acc_5': 0.6073642266824085, 'class_Acc_6': 0.016, 'class_Acc_7': 0.11451612903225805, 'class_Acc_8': 0.7138917686087498, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-4517.998, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","753    -6669.008789   0.921524    -4517.998047  ...  0.687485  0.83722  5.885223\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  31%|██████████                      | 157/500 [48:00<1:30:08, 15.77s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.84410969882762, 'Train_Acc': 0.9208049122807017, 'val_Acc': 0.8416190057193137, 'test_Acc': 0.7031013679890561, 'class_Acc_0': 0.7446056547619048, 'class_Acc_1': nan, 'class_Acc_2': 0.6115954664341762, 'class_Acc_3': 0.6951006124234471, 'class_Acc_4': 0.49577464788732395, 'class_Acc_5': 0.6720634534805658, 'class_Acc_6': 0.011999999999999999, 'class_Acc_7': 0.1967741935483871, 'class_Acc_8': 0.6700393945676965, 'class_Acc_9': 0.6125, 'Unlab_loss(mb)': array(-5052.3945, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","785     -7090.56543   0.920805    -5052.394531  ...  0.703101  0.841619  5.84411\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  33%|██████████▍                     | 163/500 [49:52<1:29:06, 15.86s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.803802292799971, 'Train_Acc': 0.9184919298245614, 'val_Acc': 0.8341399032116146, 'test_Acc': 0.7063733242134064, 'class_Acc_0': 0.7669270833333334, 'class_Acc_1': nan, 'class_Acc_2': 0.6025864574251671, 'class_Acc_3': 0.6137722368037329, 'class_Acc_4': 0.4852112676056338, 'class_Acc_5': 0.7033677107206519, 'class_Acc_6': 0.008, 'class_Acc_7': 0.2290322580645161, 'class_Acc_8': 0.7079618494712835, 'class_Acc_9': 0.5833333333333333, 'Unlab_loss(mb)': array(-4755.4165, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc  val_Acc   val_bpd\n","817    -6948.980469   0.918492    -4755.416504  ...  0.706373  0.83414  5.803802\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  34%|██████████▊                     | 169/500 [51:44<1:26:59, 15.77s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.75940936414595, 'Train_Acc': 0.9264849122807017, 'val_Acc': 0.8411790585129785, 'test_Acc': 0.7007733242134063, 'class_Acc_0': 0.6713169642857143, 'class_Acc_1': nan, 'class_Acc_2': 0.5945219412961349, 'class_Acc_3': 0.5849190726159229, 'class_Acc_4': 0.42042253521126766, 'class_Acc_5': 0.7077676111767022, 'class_Acc_6': 0.011999999999999999, 'class_Acc_7': 0.24677419354838712, 'class_Acc_8': 0.6240306862948373, 'class_Acc_9': 0.5791666666666666, 'Unlab_loss(mb)': array(-5048.367, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","849    -7208.756836   0.926485    -5048.367188  ...  0.700773  0.841179  5.759409\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  35%|███████████▎                    | 176/500 [53:51<1:23:49, 15.52s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.74460882522631, 'Train_Acc': 0.9285649122807017, 'val_Acc': 0.846018477782666, 'test_Acc': 0.6937333789329685, 'class_Acc_0': 0.6501116071428572, 'class_Acc_1': nan, 'class_Acc_2': 0.6322290031967451, 'class_Acc_3': 0.6677238261883931, 'class_Acc_4': 0.5169014084507042, 'class_Acc_5': 0.65388944834132, 'class_Acc_6': 0.02, 'class_Acc_7': 0.24677419354838712, 'class_Acc_8': 0.6226829773999585, 'class_Acc_9': 0.5791666666666666, 'Unlab_loss(mb)': array(-4983.53, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","881    -7267.013672   0.928565    -4983.529785  ...  0.693733  0.846018  5.744609\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  36%|███████████▋                    | 182/500 [55:43<1:23:32, 15.76s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.705701143342335, 'Train_Acc': 0.9272505263157894, 'val_Acc': 0.8424989001319841, 'test_Acc': 0.7016413132694939, 'class_Acc_0': 0.7513020833333333, 'class_Acc_1': nan, 'class_Acc_2': 0.5689116535890729, 'class_Acc_3': 0.6416411490230388, 'class_Acc_4': 0.5169014084507042, 'class_Acc_5': 0.6985120494478783, 'class_Acc_6': 0.016, 'class_Acc_7': 0.2290322580645161, 'class_Acc_8': 0.6565623056189094, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-4904.752, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","913    -7264.759766   0.927251    -4904.751953  ...  0.701641  0.842499  5.705701\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  38%|████████████                    | 189/500 [57:49<1:18:51, 15.22s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.6818313969740855, 'Train_Acc': 0.9241017543859649, 'val_Acc': 0.8446986361636604, 'test_Acc': 0.7017452804377564, 'class_Acc_0': 0.7434895833333333, 'class_Acc_1': nan, 'class_Acc_2': 0.5810084277826213, 'class_Acc_3': 0.5693533100029162, 'class_Acc_4': 0.42042253521126766, 'class_Acc_5': 0.713931233650485, 'class_Acc_6': 0.011999999999999999, 'class_Acc_7': 0.1967741935483871, 'class_Acc_8': 0.6562927638399336, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-5374.771, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","945    -7642.831055   0.924102    -5374.770996  ...  0.701745  0.844699  5.681831\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  39%|████████████▍                   | 195/500 [59:43<1:20:12, 15.78s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.652532759110824, 'Train_Acc': 0.9290933333333333, 'val_Acc': 0.8464584249890014, 'test_Acc': 0.6918573187414501, 'class_Acc_0': 0.5489211309523809, 'class_Acc_1': nan, 'class_Acc_2': 0.6035309503051439, 'class_Acc_3': 0.5732903178769321, 'class_Acc_4': 0.40633802816901404, 'class_Acc_5': 0.7157050836863671, 'class_Acc_6': 0.016, 'class_Acc_7': 0.1467741935483871, 'class_Acc_8': 0.6121708480199046, 'class_Acc_9': 0.6375, 'Unlab_loss(mb)': array(-5114.832, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","     Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","977      -7432.4375   0.929093    -5114.832031  ...  0.691857  0.846458  5.652533\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  40%|████████████                  | 201/500 [1:01:35<1:17:41, 15.59s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.622314356196266, 'Train_Acc': 0.9342119298245614, 'val_Acc': 0.8517377914650242, 'test_Acc': 0.6732054719562244, 'class_Acc_0': 0.6484375, 'class_Acc_1': nan, 'class_Acc_2': 0.5840961929671608, 'class_Acc_3': 0.7136191309419656, 'class_Acc_4': 0.44507042253521123, 'class_Acc_5': 0.5817085098502209, 'class_Acc_6': 0.016, 'class_Acc_7': 0.2129032258064516, 'class_Acc_8': 0.691789342732739, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-5341.9546, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1009     -7744.72168   0.934212     -5341.95459  ...  0.673205  0.851738  5.622314\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  42%|████████████▍                 | 208/500 [1:03:40<1:13:36, 15.12s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.604443394041817, 'Train_Acc': 0.9432694736842105, 'val_Acc': 0.8530576330840299, 'test_Acc': 0.6791574555403557, 'class_Acc_0': 0.7429315476190476, 'class_Acc_1': nan, 'class_Acc_2': 0.6025864574251671, 'class_Acc_3': 0.6203521434820647, 'class_Acc_4': 0.44507042253521123, 'class_Acc_5': 0.6013293747250966, 'class_Acc_6': 0.016, 'class_Acc_7': 0.2129032258064516, 'class_Acc_8': 0.7394153016794526, 'class_Acc_9': 0.5791666666666666, 'Unlab_loss(mb)': array(-5274.647, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1041    -7703.213379   0.943269    -5274.646973  ...  0.679157  0.853058  5.604443\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  43%|████████████▊                 | 214/500 [1:05:33<1:15:00, 15.73s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.551558195067354, 'Train_Acc': 0.9389578947368421, 'val_Acc': 0.8534975802903652, 'test_Acc': 0.6888893296853625, 'class_Acc_0': 0.736235119047619, 'class_Acc_1': nan, 'class_Acc_2': 0.6327012496367335, 'class_Acc_3': 0.6378864100320792, 'class_Acc_4': 0.45915492957746484, 'class_Acc_5': 0.6396494548232515, 'class_Acc_6': 0.032, 'class_Acc_7': 0.17903225806451611, 'class_Acc_8': 0.6019282604188264, 'class_Acc_9': 0.5666666666666667, 'Unlab_loss(mb)': array(-5230.731, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1073    -7795.806152   0.938958    -5230.730957  ...  0.688889  0.853498  5.551558\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  44%|█████████████▎                | 221/500 [1:07:40<1:11:32, 15.38s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.526660199743367, 'Train_Acc': 0.931658947368421, 'val_Acc': 0.8482182138143423, 'test_Acc': 0.6885213406292751, 'class_Acc_0': 0.6277901785714285, 'class_Acc_1': nan, 'class_Acc_2': 0.5750871839581517, 'class_Acc_3': 0.6847659667541557, 'class_Acc_4': 0.40633802816901404, 'class_Acc_5': 0.6607765006829178, 'class_Acc_6': 0.016, 'class_Acc_7': 0.2451612903225807, 'class_Acc_8': 0.6880157578270786, 'class_Acc_9': 0.6041666666666666, 'Unlab_loss(mb)': array(-5700.0366, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1105    -8156.950195   0.931659    -5700.036621  ...  0.688521  0.848218  5.52666\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  45%|█████████████▌                | 227/500 [1:09:35<1:12:31, 15.94s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.525228540943838, 'Train_Acc': 0.9446336842105263, 'val_Acc': 0.8548174219093708, 'test_Acc': 0.6652214774281805, 'class_Acc_0': 0.7094494047619048, 'class_Acc_1': nan, 'class_Acc_2': 0.56393490264458, 'class_Acc_3': 0.6632946923301255, 'class_Acc_4': 0.4415492957746479, 'class_Acc_5': 0.5987727735722388, 'class_Acc_6': 0.02, 'class_Acc_7': 0.2790322580645161, 'class_Acc_8': 0.7221646278250053, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-5352.1772, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1137    -7951.358398   0.944634    -5352.177246  ...  0.665221  0.854817  5.525229\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  47%|█████████████▉                | 233/500 [1:11:27<1:10:17, 15.79s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.4723858432393, 'Train_Acc': 0.9399178947368422, 'val_Acc': 0.8482182138143423, 'test_Acc': 0.6431176470588235, 'class_Acc_0': 0.7239583333333334, 'class_Acc_1': nan, 'class_Acc_2': 0.5580136588201106, 'class_Acc_3': 0.7859069699620881, 'class_Acc_4': 0.523943661971831, 'class_Acc_5': 0.5063763108549205, 'class_Acc_6': 0.011999999999999999, 'class_Acc_7': 0.1629032258064516, 'class_Acc_8': 0.6847812564793697, 'class_Acc_9': 0.5833333333333333, 'Unlab_loss(mb)': array(-5658.696, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1169    -8131.253418   0.939918    -5658.695801  ...  0.643118  0.848218  5.472386\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  48%|██████████████▍               | 240/500 [1:13:35<1:07:21, 15.55s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.456256728710715, 'Train_Acc': 0.9452778947368421, 'val_Acc': 0.8556973163220414, 'test_Acc': 0.6566495212038304, 'class_Acc_0': 0.7194940476190476, 'class_Acc_1': nan, 'class_Acc_2': 0.5117698343504795, 'class_Acc_3': 0.6556029454651502, 'class_Acc_4': 0.4556338028169014, 'class_Acc_5': 0.5679937264161863, 'class_Acc_6': 0.016, 'class_Acc_7': 0.2951612903225807, 'class_Acc_8': 0.7151565415716359, 'class_Acc_9': 0.6041666666666666, 'Unlab_loss(mb)': array(-5575.0903, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1201    -8234.716797   0.945278    -5575.090332  ...   0.65665  0.855697  5.456257\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  49%|██████████████▊               | 246/500 [1:15:28<1:07:08, 15.86s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.4276237875338005, 'Train_Acc': 0.9456750877192983, 'val_Acc': 0.8543774747030356, 'test_Acc': 0.6679734610123119, 'class_Acc_0': 0.6350446428571429, 'class_Acc_1': nan, 'class_Acc_2': 0.5800639349026445, 'class_Acc_3': 0.681321084864392, 'class_Acc_4': 0.5345070422535212, 'class_Acc_5': 0.6071066856494663, 'class_Acc_6': 0.02, 'class_Acc_7': 0.2790322580645161, 'class_Acc_8': 0.6406593406593407, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-5503.687, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1233    -8189.318359   0.945675    -5503.687012  ...  0.667973  0.854377  5.427624\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  51%|███████████████▏              | 253/500 [1:17:35<1:03:18, 15.38s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.404164730232367, 'Train_Acc': 0.9485094736842106, 'val_Acc': 0.8534975802903652, 'test_Acc': 0.6546335157318741, 'class_Acc_0': 0.6450892857142857, 'class_Acc_1': nan, 'class_Acc_2': 0.525283347863993, 'class_Acc_3': 0.7003317293671625, 'class_Acc_4': 0.5274647887323944, 'class_Acc_5': 0.6006059448572818, 'class_Acc_6': 0.023999999999999997, 'class_Acc_7': 0.24677419354838712, 'class_Acc_8': 0.5849471283433548, 'class_Acc_9': 0.6041666666666666, 'Unlab_loss(mb)': array(-5960.019, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1265    -8545.109375   0.948509    -5960.019043  ...  0.654634  0.853498  5.404165\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  52%|███████████████▌              | 259/500 [1:19:28<1:03:38, 15.84s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.38880580446259, 'Train_Acc': 0.9447221052631579, 'val_Acc': 0.8556973163220414, 'test_Acc': 0.6655254445964432, 'class_Acc_0': 0.6434151785714285, 'class_Acc_1': nan, 'class_Acc_2': 0.5769761697181052, 'class_Acc_3': 0.6329651501895596, 'class_Acc_4': 0.42042253521126766, 'class_Acc_5': 0.6238338310530824, 'class_Acc_6': 0.027999999999999994, 'class_Acc_7': 0.3451612903225807, 'class_Acc_8': 0.6285299606054323, 'class_Acc_9': 0.6166666666666667, 'Unlab_loss(mb)': array(-5636.7017, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1297    -8378.357422   0.944722     -5636.70166  ...  0.665525  0.855697  5.388806\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  53%|███████████████▉              | 265/500 [1:21:20<1:01:51, 15.80s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.355384778230539, 'Train_Acc': 0.9495922807017544, 'val_Acc': 0.8565772107347118, 'test_Acc': 0.6475415868673051, 'class_Acc_0': 0.7367931547619048, 'class_Acc_1': nan, 'class_Acc_2': 0.5288433594885208, 'class_Acc_3': 0.691965587634879, 'class_Acc_4': 0.4309859154929578, 'class_Acc_5': 0.5457468111211425, 'class_Acc_6': 0.016, 'class_Acc_7': 0.2290322580645161, 'class_Acc_8': 0.7213560024880779, 'class_Acc_9': 0.5458333333333333, 'Unlab_loss(mb)': array(-5926.875, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1329    -8582.592773   0.949592       -5926.875  ...  0.647542  0.856577  5.355385\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  54%|█████████████████▍              | 272/500 [1:23:26<57:48, 15.21s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.360613138871885, 'Train_Acc': 0.9463522807017544, 'val_Acc': 0.8556973163220414, 'test_Acc': 0.662673461012312, 'class_Acc_0': 0.6871279761904762, 'class_Acc_1': nan, 'class_Acc_2': 0.49066405114792216, 'class_Acc_3': 0.6842738407699038, 'class_Acc_4': 0.40985915492957736, 'class_Acc_5': 0.6240913720860244, 'class_Acc_6': 0.02, 'class_Acc_7': 0.2290322580645161, 'class_Acc_8': 0.7218950860460295, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-5765.813, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1361    -8548.922852   0.946352    -5765.812988  ...  0.662673  0.855697  5.360613\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  56%|█████████████████▊              | 278/500 [1:25:21<58:20, 15.77s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.32639304180257, 'Train_Acc': 0.9491522807017544, 'val_Acc': 0.8578970523537176, 'test_Acc': 0.6660614227086182, 'class_Acc_0': 0.7111235119047619, 'class_Acc_1': nan, 'class_Acc_2': 0.5625181633246149, 'class_Acc_3': 0.6055883639545057, 'class_Acc_4': 0.5133802816901408, 'class_Acc_5': 0.6361712040187976, 'class_Acc_6': 0.027999999999999994, 'class_Acc_7': 0.2451612903225807, 'class_Acc_8': 0.6333817126269956, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-5717.567, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1393    -8511.505859   0.949152    -5717.566895  ...  0.666061  0.857897  5.326393\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  57%|██████████████████▏             | 285/500 [1:27:27<54:09, 15.11s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.299918742473132, 'Train_Acc': 0.9516666666666667, 'val_Acc': 0.8574571051473823, 'test_Acc': 0.6567734610123119, 'class_Acc_0': 0.7066592261904762, 'class_Acc_1': nan, 'class_Acc_2': 0.5674949142691078, 'class_Acc_3': 0.6524679206765821, 'class_Acc_4': 0.42042253521126766, 'class_Acc_5': 0.6167485589277032, 'class_Acc_6': 0.023999999999999997, 'class_Acc_7': 0.1629032258064516, 'class_Acc_8': 0.6231391250259175, 'class_Acc_9': 0.5666666666666667, 'Unlab_loss(mb)': array(-5895.1035, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1426       -8718.875   0.951667    -5895.103516  ...  0.656773  0.857457  5.299919\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  58%|██████████████████▌             | 291/500 [1:29:20<55:00, 15.79s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.284130577358508, 'Train_Acc': 0.9526680701754386, 'val_Acc': 0.8556973163220414, 'test_Acc': 0.6577054719562244, 'class_Acc_0': 0.6166294642857143, 'class_Acc_1': nan, 'class_Acc_2': 0.5670226678291195, 'class_Acc_3': 0.627551764362788, 'class_Acc_4': 0.4345070422535212, 'class_Acc_5': 0.6021815751093825, 'class_Acc_6': 0.016, 'class_Acc_7': 0.1629032258064516, 'class_Acc_8': 0.6783122537839519, 'class_Acc_9': 0.5833333333333333, 'Unlab_loss(mb)': array(-5807.6567, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1458    -8684.958984   0.952668    -5807.656738  ...  0.657705  0.855697  5.284131\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  60%|███████████████████             | 298/500 [1:31:27<51:46, 15.38s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.274202891220203, 'Train_Acc': 0.9531894736842106, 'val_Acc': 0.8583369995600528, 'test_Acc': 0.6427455540355677, 'class_Acc_0': 0.7111235119047619, 'class_Acc_1': nan, 'class_Acc_2': 0.5122420807904678, 'class_Acc_3': 0.5855934674832314, 'class_Acc_4': 0.5380281690140845, 'class_Acc_5': 0.5956909623353475, 'class_Acc_6': 0.027999999999999994, 'class_Acc_7': 0.2451612903225807, 'class_Acc_8': 0.5849471283433548, 'class_Acc_9': 0.55, 'Unlab_loss(mb)': array(-6234.1606, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1490    -9043.240234   0.953189    -6234.160645  ...  0.642746  0.858337  5.274203\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  61%|███████████████████▍            | 304/500 [1:33:20<52:05, 15.95s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.244137586802823, 'Train_Acc': 0.9577768421052631, 'val_Acc': 0.857017157941047, 'test_Acc': 0.6419975376196989, 'class_Acc_0': 0.6943824404761905, 'class_Acc_1': nan, 'class_Acc_2': 0.5148575995350189, 'class_Acc_3': 0.6768919510061243, 'class_Acc_4': 0.42042253521126766, 'class_Acc_5': 0.5740285783734982, 'class_Acc_6': 0.036, 'class_Acc_7': 0.17903225806451611, 'class_Acc_8': 0.6637569977192619, 'class_Acc_9': 0.5541666666666666, 'Unlab_loss(mb)': array(-5961.9683, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1522    -8891.001953   0.957777    -5961.968262  ...  0.641998  0.857017  5.244138\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  62%|███████████████████▊            | 310/500 [1:35:14<50:12, 15.85s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.229890973274045, 'Train_Acc': 0.9553824561403509, 'val_Acc': 0.8565772107347118, 'test_Acc': 0.6482894664842681, 'class_Acc_0': 0.6960565476190476, 'class_Acc_1': nan, 'class_Acc_2': 0.5634626562045916, 'class_Acc_3': 0.6270596383785361, 'class_Acc_4': 0.42042253521126766, 'class_Acc_5': 0.611367687570896, 'class_Acc_6': 0.027999999999999994, 'class_Acc_7': 0.19516129032258064, 'class_Acc_8': 0.6120879120879121, 'class_Acc_9': 0.5875, 'Unlab_loss(mb)': array(-6204.2173, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1554    -9109.651367   0.955382    -6204.217285  ...  0.648289  0.856577  5.229891\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  63%|████████████████████▎           | 317/500 [1:37:21<47:08, 15.45s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.226272494989523, 'Train_Acc': 0.9496378947368421, 'val_Acc': 0.8556973163220414, 'test_Acc': 0.6531254445964433, 'class_Acc_0': 0.701078869047619, 'class_Acc_1': nan, 'class_Acc_2': 0.5409401336820692, 'class_Acc_3': 0.6060804899387576, 'class_Acc_4': 0.29577464788732394, 'class_Acc_5': 0.6441781257957728, 'class_Acc_6': 0.023999999999999997, 'class_Acc_7': 0.2951612903225807, 'class_Acc_8': 0.6093924942981547, 'class_Acc_9': 0.6041666666666666, 'Unlab_loss(mb)': array(-6052.8193, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1586    -9004.193359   0.949638    -6052.819336  ...  0.653125  0.855697  5.226272\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  65%|████████████████████▋           | 323/500 [1:39:15<47:24, 16.07s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.19070010613302, 'Train_Acc': 0.9547880701754387, 'val_Acc': 0.8578970523537176, 'test_Acc': 0.6347295485636115, 'class_Acc_0': 0.6949404761904762, 'class_Acc_1': nan, 'class_Acc_2': 0.5072653298459749, 'class_Acc_3': 0.6378864100320792, 'class_Acc_4': 0.41690140845070417, 'class_Acc_5': 0.5879415815913142, 'class_Acc_6': 0.027999999999999994, 'class_Acc_7': 0.2951612903225807, 'class_Acc_8': 0.5666182873730043, 'class_Acc_9': 0.6083333333333334, 'Unlab_loss(mb)': array(-6084.326, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc  val_bpd\n","1617     -9060.43457   0.954788    -6084.326172  ...   0.63473  0.857897   5.1907\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  66%|█████████████████████           | 329/500 [1:41:07<45:28, 15.96s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.1920824540668935, 'Train_Acc': 0.9600568421052632, 'val_Acc': 0.8561372635283766, 'test_Acc': 0.6305735978112175, 'class_Acc_0': 0.6999627976190476, 'class_Acc_1': nan, 'class_Acc_2': 0.5293156059285091, 'class_Acc_3': 0.6603419364246136, 'class_Acc_4': 0.423943661971831, 'class_Acc_5': 0.5557258027177813, 'class_Acc_6': 0.023999999999999997, 'class_Acc_7': 0.21129032258064517, 'class_Acc_8': 0.6497408252125233, 'class_Acc_9': 0.6041666666666666, 'Unlab_loss(mb)': array(-6277.0264, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1649    -9190.683594   0.960057    -6277.026367  ...  0.630574  0.856137  5.192082\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  67%|█████████████████████▌          | 336/500 [1:43:13<42:16, 15.47s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.176229480385979, 'Train_Acc': 0.9555894736842105, 'val_Acc': 0.8574571051473823, 'test_Acc': 0.6455015047879616, 'class_Acc_0': 0.6882440476190476, 'class_Acc_1': nan, 'class_Acc_2': 0.5207788433594884, 'class_Acc_3': 0.6305045202682998, 'class_Acc_4': 0.42042253521126766, 'class_Acc_5': 0.6074336759497186, 'class_Acc_6': 0.036, 'class_Acc_7': 0.26129032258064516, 'class_Acc_8': 0.657287995023844, 'class_Acc_9': 0.6041666666666666, 'Unlab_loss(mb)': array(-6147.708, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1681    -9155.664062   0.955589    -6147.708008  ...  0.645502  0.857457  5.176229\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  68%|█████████████████████▉          | 342/500 [1:45:06<41:21, 15.70s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.160742346365499, 'Train_Acc': 0.9557452631578947, 'val_Acc': 0.8561372635283766, 'test_Acc': 0.651809439124487, 'class_Acc_0': 0.6015625, 'class_Acc_1': nan, 'class_Acc_2': 0.5463891310665504, 'class_Acc_3': 0.5811643336249636, 'class_Acc_4': 0.30985915492957744, 'class_Acc_5': 0.639847674607033, 'class_Acc_6': 0.027999999999999994, 'class_Acc_7': 0.27741935483870966, 'class_Acc_8': 0.6540534936761353, 'class_Acc_9': 0.5875, 'Unlab_loss(mb)': array(-6070.6665, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1713     -9120.65918   0.955745    -6070.666504  ...  0.651809  0.856137  5.160742\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  70%|██████████████████████▎         | 349/500 [1:47:13<38:41, 15.38s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.153130862031121, 'Train_Acc': 0.9562694736842106, 'val_Acc': 0.8574571051473823, 'test_Acc': 0.6362295485636115, 'class_Acc_0': 0.6954985119047619, 'class_Acc_1': nan, 'class_Acc_2': 0.5127143272304563, 'class_Acc_3': 0.600667104111986, 'class_Acc_4': 0.30985915492957744, 'class_Acc_5': 0.6036284348450125, 'class_Acc_6': 0.036, 'class_Acc_7': 0.26129032258064516, 'class_Acc_8': 0.6510885341074021, 'class_Acc_9': 0.5708333333333333, 'Unlab_loss(mb)': array(-6489.347, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1745    -9439.607422   0.956269    -6489.347168  ...   0.63623  0.857457  5.153131\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  71%|██████████████████████▋         | 355/500 [1:49:01<34:41, 14.36s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.1358586746739165, 'Train_Acc': 0.9610224561403509, 'val_Acc': 0.858776946766388, 'test_Acc': 0.6323455540355677, 'class_Acc_0': 0.6065848214285714, 'class_Acc_1': nan, 'class_Acc_2': 0.5082098227259517, 'class_Acc_3': 0.6250911344415282, 'class_Acc_4': 0.4309859154929578, 'class_Acc_5': 0.5819067296340023, 'class_Acc_6': 0.02, 'class_Acc_7': 0.2451612903225807, 'class_Acc_8': 0.6871241965581588, 'class_Acc_9': 0.6041666666666666, 'Unlab_loss(mb)': array(-6395.2974, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1779     -9338.31543   0.961022    -6395.297363  ...  0.632346  0.858777  5.135859\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  73%|███████████████████████▎        | 364/500 [1:50:59<25:31, 11.26s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.1138486523818125, 'Train_Acc': 0.9543508771929824, 'val_Acc': 0.858776946766388, 'test_Acc': 0.6385815321477428, 'class_Acc_0': 0.7083333333333333, 'class_Acc_1': nan, 'class_Acc_2': 0.48710403952339437, 'class_Acc_3': 0.5747666958296879, 'class_Acc_4': 0.3028169014084507, 'class_Acc_5': 0.6301363520614858, 'class_Acc_6': 0.02, 'class_Acc_7': 0.2290322580645161, 'class_Acc_8': 0.6459672403068629, 'class_Acc_9': 0.5833333333333333, 'Unlab_loss(mb)': array(-6279.289, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1821    -9349.259766   0.954351    -6279.289062  ...  0.638582  0.858777  5.113849\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  74%|███████████████████████▊        | 372/500 [1:52:44<23:53, 11.20s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.11853811570564, 'Train_Acc': 0.9599382456140351, 'val_Acc': 0.8600967883853937, 'test_Acc': 0.6448854993160056, 'class_Acc_0': 0.6954985119047619, 'class_Acc_1': nan, 'class_Acc_2': 0.5378523684975298, 'class_Acc_3': 0.5727981918926801, 'class_Acc_4': 0.40985915492957736, 'class_Acc_5': 0.6352596823853508, 'class_Acc_6': 0.027999999999999994, 'class_Acc_7': 0.19516129032258064, 'class_Acc_8': 0.6150528716566452, 'class_Acc_9': 0.5458333333333333, 'Unlab_loss(mb)': array(-6164.271, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1863    -9293.521484   0.959938    -6164.270996  ...  0.644885  0.860097  5.118538\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  76%|████████████████████████▎       | 380/500 [1:54:32<22:59, 11.50s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.093589165820474, 'Train_Acc': 0.9591838596491228, 'val_Acc': 0.8592168939727233, 'test_Acc': 0.6311935704514364, 'class_Acc_0': 0.6932663690476191, 'class_Acc_1': nan, 'class_Acc_2': 0.5077375762859634, 'class_Acc_3': 0.6465624088655585, 'class_Acc_4': 0.40985915492957736, 'class_Acc_5': 0.5853849804384563, 'class_Acc_6': 0.032, 'class_Acc_7': 0.22741935483870965, 'class_Acc_8': 0.5695832469417376, 'class_Acc_9': 0.6041666666666666, 'Unlab_loss(mb)': array(-6485.95, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1904    -9450.256836   0.959184    -6485.950195  ...  0.631194  0.859217  5.093589\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  78%|████████████████████████▉       | 389/500 [1:56:29<20:40, 11.18s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.072985677267779, 'Train_Acc': 0.9597438596491228, 'val_Acc': 0.8592168939727233, 'test_Acc': 0.6309775649794801, 'class_Acc_0': 0.687686011904762, 'class_Acc_1': nan, 'class_Acc_2': 0.47547951176983433, 'class_Acc_3': 0.5782115777194518, 'class_Acc_4': 0.41690140845070417, 'class_Acc_5': 0.609465067018543, 'class_Acc_6': 0.027999999999999994, 'class_Acc_7': 0.21129032258064517, 'class_Acc_8': 0.6112792867509849, 'class_Acc_9': 0.5666666666666667, 'Unlab_loss(mb)': array(-6356.8574, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1946    -9421.632812   0.959744    -6356.857422  ...  0.630978  0.859217  5.072986\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  79%|█████████████████████████▍      | 397/500 [1:58:15<19:18, 11.25s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.073165544520599, 'Train_Acc': 0.959819649122807, 'val_Acc': 0.8592168939727233, 'test_Acc': 0.6283615595075239, 'class_Acc_0': 0.6865699404761905, 'class_Acc_1': nan, 'class_Acc_2': 0.5086820691659402, 'class_Acc_3': 0.5660906969962087, 'class_Acc_4': 0.3992957746478873, 'class_Acc_5': 0.6146477185915689, 'class_Acc_6': 0.027999999999999994, 'class_Acc_7': 0.22741935483870965, 'class_Acc_8': 0.5214182044370724, 'class_Acc_9': 0.5458333333333333, 'Unlab_loss(mb)': array(-6255.208, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","1988    -9416.871094    0.95982    -6255.208008  ...  0.628362  0.859217  5.073166\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  81%|█████████████████████████▉      | 405/500 [2:00:02<17:52, 11.29s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.0551520504830405, 'Train_Acc': 0.9567150877192984, 'val_Acc': 0.8596568411790585, 'test_Acc': 0.6245415868673051, 'class_Acc_0': 0.6921502976190476, 'class_Acc_1': nan, 'class_Acc_2': 0.4925530369078756, 'class_Acc_3': 0.5836249635462234, 'class_Acc_4': 0.40985915492957736, 'class_Acc_5': 0.6072354561659374, 'class_Acc_6': 0.036, 'class_Acc_7': 0.21129032258064517, 'class_Acc_8': 0.5184532448683391, 'class_Acc_9': 0.5333333333333334, 'Unlab_loss(mb)': array(-6557.5713, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2029    -9633.048828   0.956715    -6557.571289  ...  0.624542  0.859657  5.055152\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  83%|██████████████████████████▍     | 414/500 [2:01:59<15:53, 11.09s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.0428144718960635, 'Train_Acc': 0.9618968421052632, 'val_Acc': 0.858776946766388, 'test_Acc': 0.6268615595075239, 'class_Acc_0': 0.6021205357142857, 'class_Acc_1': nan, 'class_Acc_2': 0.4875762859633827, 'class_Acc_3': 0.5626458151064451, 'class_Acc_4': 0.41690140845070417, 'class_Acc_5': 0.6162927981109798, 'class_Acc_6': 0.032, 'class_Acc_7': 0.22741935483870965, 'class_Acc_8': 0.5552975326560232, 'class_Acc_9': 0.5833333333333333, 'Unlab_loss(mb)': array(-6713.0933, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2070    -9790.191406   0.961897    -6713.093262  ...  0.626862  0.858777  5.042814\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  84%|███████████████████████████     | 422/500 [2:03:44<14:26, 11.11s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.03788244607594, 'Train_Acc': 0.9611024561403508, 'val_Acc': 0.8592168939727233, 'test_Acc': 0.6258615595075239, 'class_Acc_0': 0.6809895833333333, 'class_Acc_1': nan, 'class_Acc_2': 0.5176910781749492, 'class_Acc_3': 0.6041119860017498, 'class_Acc_4': 0.42042253521126766, 'class_Acc_5': 0.5924702525638355, 'class_Acc_6': 0.032, 'class_Acc_7': 0.22741935483870965, 'class_Acc_8': 0.5585320340037321, 'class_Acc_9': 0.5833333333333333, 'Unlab_loss(mb)': array(-6423.539, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2111      -9599.4375   0.961102    -6423.539062  ...  0.625862  0.859217  5.037882\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  86%|███████████████████████████▌    | 430/500 [2:05:33<13:07, 11.26s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.027951472546593, 'Train_Acc': 0.9630154385964913, 'val_Acc': 0.858776946766388, 'test_Acc': 0.621141586867305, 'class_Acc_0': 0.6793154761904762, 'class_Acc_1': nan, 'class_Acc_2': 0.49160854402789883, 'class_Acc_3': 0.6036198600174978, 'class_Acc_4': 0.41690140845070417, 'class_Acc_5': 0.5931936824316504, 'class_Acc_6': 0.032, 'class_Acc_7': 0.21129032258064517, 'class_Acc_8': 0.5942981546755133, 'class_Acc_9': 0.5791666666666666, 'Unlab_loss(mb)': array(-6420.87, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2152    -9616.666992   0.963015    -6420.870117  ...  0.621142  0.858777  5.027951\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  88%|████████████████████████████    | 439/500 [2:07:23<09:30,  9.35s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.025989134907154, 'Train_Acc': 0.9614224561403508, 'val_Acc': 0.8600967883853937, 'test_Acc': 0.6254295485636114, 'class_Acc_0': 0.6804315476190476, 'class_Acc_1': nan, 'class_Acc_2': 0.49160854402789883, 'class_Acc_3': 0.5982064741907261, 'class_Acc_4': 0.42042253521126766, 'class_Acc_5': 0.5981781142208948, 'class_Acc_6': 0.032, 'class_Acc_7': 0.22741935483870965, 'class_Acc_8': 0.5959154053493676, 'class_Acc_9': 0.5833333333333333, 'Unlab_loss(mb)': array(-6451.77, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2196    -9657.683594   0.961422     -6451.77002  ...   0.62543  0.860097  5.025989\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  92%|█████████████████████████████▎  | 458/500 [2:08:59<03:04,  4.40s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.011765533115682, 'Train_Acc': 0.9585522807017544, 'val_Acc': 0.8600967883853937, 'test_Acc': 0.6236455540355677, 'class_Acc_0': 0.6837797619047619, 'class_Acc_1': nan, 'class_Acc_2': 0.4795117698343505, 'class_Acc_3': 0.5767351997666958, 'class_Acc_4': 0.41690140845070417, 'class_Acc_5': 0.6098615065861055, 'class_Acc_6': 0.032, 'class_Acc_7': 0.25967741935483873, 'class_Acc_8': 0.5880986937590711, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-6647.4404, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2294    -9855.935547   0.958552     -6647.44043  ...  0.623646  0.860097  5.011766\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  96%|██████████████████████████████▌ | 478/500 [2:10:39<01:37,  4.43s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.008022368785146, 'Train_Acc': 0.9609838596491227, 'val_Acc': 0.8596568411790585, 'test_Acc': 0.6216775649794802, 'class_Acc_0': 0.679873511904762, 'class_Acc_1': nan, 'class_Acc_2': 0.475007265329846, 'class_Acc_3': 0.5982064741907261, 'class_Acc_4': 0.41690140845070417, 'class_Acc_5': 0.6037572053614834, 'class_Acc_6': 0.032, 'class_Acc_7': 0.22741935483870965, 'class_Acc_8': 0.5894464026539499, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-6483.7007, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2391    -9733.578125   0.960984    -6483.700684  ...  0.621678  0.859657  5.008022\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train:  99%|███████████████████████████████▊| 497/500 [2:12:11<00:13,  4.41s/it]/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.006572864148524, 'Train_Acc': 0.9604266666666668, 'val_Acc': 0.8592168939727233, 'test_Acc': 0.6227455540355676, 'class_Acc_0': 0.6787574404761905, 'class_Acc_1': nan, 'class_Acc_2': 0.4920807904678873, 'class_Acc_3': 0.5791958296879557, 'class_Acc_4': 0.41690140845070417, 'class_Acc_5': 0.6040841956617358, 'class_Acc_6': 0.032, 'class_Acc_7': 0.22741935483870965, 'class_Acc_8': 0.5894464026539499, 'class_Acc_9': 0.6, 'Unlab_loss(mb)': array(-6464.858, dtype=float32)}\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2487    -9716.089844   0.960427     -6464.85791  ...  0.622746  0.859217  5.006573\n","\n","[1 rows x 17 columns]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  mixture_log_probs = torch.logsumexp(all_log_probs + torch.log(F.softmax(self.weights)), dim=1)\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","train: 100%|████████████████████████████████| 500/500 [2:12:34<00:00, 15.91s/it]\n","/home/anunay18021/SingleCellClassification/flowgmm/flow_ssl/distributions.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  log_probs_weighted = log_probs + torch.log(F.softmax(self.weights))\n","/home/anunay18021/SingleCellClassification/flowgmm/experiments/train_flows/train_semisup_flowgmm_tabular.py:90: RuntimeWarning: invalid value encountered in double_scalars\n","  class_wise_acc.append(lambda mb:  (torch.mul(self.model.prior.classify(self.model(mb[0]))\n","{'val_bpd': 5.005890730506957, 'Train_Acc': 0.9599080701754387, 'val_Acc': 0.8596568411790585, 'test_Acc': 0.622061559507524, 'class_Acc_0': 0.6781994047619048, 'class_Acc_1': nan, 'class_Acc_2': 0.48804853240337104, 'class_Acc_3': 0.5787037037037037, 'class_Acc_4': 0.41690140845070417, 'class_Acc_5': 0.6046094057457695, 'class_Acc_6': 0.032, 'class_Acc_7': 0.22741935483870965, 'class_Acc_8': 0.5897159444329256, 'class_Acc_9': 0.6}\n","/home/anunay18021/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:265: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","      Minibatch_Loss  Train_Acc  Unlab_loss(mb)  ...  test_Acc   val_Acc   val_bpd\n","2499             NaN   0.959908             NaN  ...  0.622062  0.859657  5.005891\n","\n","[1 rows x 17 columns]\n"]}],"source":["!python3 experiments/train_flows/flowgmm_tabular_new.py --num_classes 10 --metric_name \"inDrops\" --trainer_config \"{'unlab_weight':.6}\" --net_config \"{'k':1024,'coupling_layers':7,'nperlayer':1}\" --network RealNVPTabularWPrior --trainer SemiFlow --num_epochs 500 --dataset AG_News --lr 3e-4 --train 200"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["with open(\"/home/anunay18021/SingleCellClassification/tmp/metrics_\" + batch_name + \".pkl\", \"rb\") as f:\n","  D = pickle.load(f)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["rev = list(mapping.keys())\n","new_D = {}\n","for i in D:\n","  try:\n","    new_D[reverse_mapping[int(i.split(\"_\")[-1])]] = D[i]\n","  except:\n","    continue"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["plt.rcParams[\"figure.figsize\"] = (20,5.5)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 2000x550 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.bar(range(len(new_D)), list(new_D.values()))\n","plt.xticks(range(len(new_D)), list(new_D.keys()))\n","plt.show()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["classes_labeled = {}\n","for i in D:\n","  try:\n","        classes_labeled[reverse_mapping[int(i.split(\"_\")[-1])]] = D[i]\n","  except:\n","        classes_labeled[i] = D[i]"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["df = pd.DataFrame(columns = list(classes_labeled.keys()))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_344570/3840281218.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  df.append(classes_labeled, ignore_index = True)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>val_bpd</th>\n","      <th>Train_Acc</th>\n","      <th>val_Acc</th>\n","      <th>test_Acc</th>\n","      <th>B cell</th>\n","      <th>Unassigned</th>\n","      <th>CD16+ monocyte</th>\n","      <th>CD4+ T cell</th>\n","      <th>Natural killer cell</th>\n","      <th>Cytotoxic T cell</th>\n","      <th>Dendritic cell</th>\n","      <th>Plasmacytoid dendritic cell</th>\n","      <th>CD14+ monocyte</th>\n","      <th>Megakaryocyte</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.005891</td>\n","      <td>0.959908</td>\n","      <td>0.859657</td>\n","      <td>0.622062</td>\n","      <td>0.678199</td>\n","      <td>NaN</td>\n","      <td>0.488049</td>\n","      <td>0.578704</td>\n","      <td>0.416901</td>\n","      <td>0.604609</td>\n","      <td>0.032</td>\n","      <td>0.227419</td>\n","      <td>0.589716</td>\n","      <td>0.6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    val_bpd  Train_Acc   val_Acc  test_Acc    B cell  Unassigned  \\\n","0  5.005891   0.959908  0.859657  0.622062  0.678199         NaN   \n","\n","   CD16+ monocyte  CD4+ T cell  Natural killer cell  Cytotoxic T cell  \\\n","0        0.488049     0.578704             0.416901          0.604609   \n","\n","   Dendritic cell  Plasmacytoid dendritic cell  CD14+ monocyte  Megakaryocyte  \n","0           0.032                     0.227419        0.589716            0.6  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df.append(classes_labeled, ignore_index = True)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1fTsVaFW9rVur8hpaEbz5dsxiGXSEy9Sk","timestamp":1679851239019}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
